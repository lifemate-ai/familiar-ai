# familiar-ai ğŸ¾

**VeÅ¡taÄka inteligencija koja Å¾ivi pored vas** â€” sa oÄima, glasom, nogama i memorijom.

[![Lint](https://github.com/kmizu/familiar-ai/actions/workflows/lint.yml/badge.svg)](https://github.com/kmizu/familiar-ai/actions/workflows/lint.yml)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](./LICENSE)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/)
[![GitHub Sponsors](https://img.shields.io/github/sponsors/kmizu?style=flat&logo=github&color=ea4aaa)](https://github.com/sponsors/kmizu)

ğŸŒ [Dostupno na 74 jezika](./SUPPORTED_LANGUAGES.md)

---

[![Demo video](https://img.youtube.com/vi/hiR9uWRnjt4/0.jpg)](https://youtube.com/shorts/hiR9uWRnjt4)

familiar-ai je AI saputnik koji Å¾ivi u vaÅ¡em domu. Postavite ga za nekoliko minuta. Nije potrebna nikakva programiranja.

Perceputuje stvarni svet putem kamera, kreÄ‡e se na robotskom telu, govori naglas i pamti ono Å¡to vidi. Dajte mu ime, napiÅ¡ite njegovu liÄnost i pustite da Å¾ivi sa vama.

## Å ta moÅ¾e da uradi

- ğŸ‘ **SviÄ‘a** â€” hvata slike iz Wi-Fi PTZ kamere ili USB veb kamere
- ğŸ”„ **Gleda oko** â€” pomera i naginje kameru kako bi istraÅ¾ila okolinu
- ğŸ¦¿ **PokreÄ‡e se** â€” pokreÄ‡e robotski usisivaÄ da se kreÄ‡e po prostoriji
- ğŸ—£ **Govori** â€” razgovara putem ElevenLabs TTS
- ğŸ™ **SluÅ¡a** â€” unos glasa bez ruku putem ElevenLabs Realtime STT (opcija)
- ğŸ§  **Pamti** â€” aktivno skladiÅ¡ti i seÄ‡a se uspomena uz semantiÄku pretragu (SQLite + embeddings)
- ğŸ«€ **Teorija uma** â€” uzima perspektivu druge osobe pre nego Å¡to odgovori
- ğŸ’­ **Å½elja** â€” ima sopstvene unutraÅ¡nje motive koji pokreÄ‡u autonomno ponaÅ¡anje

## Kako to funkcioniÅ¡e

familiar-ai pokreÄ‡e [ReAct](https://arxiv.org/abs/2210.03629) petlju koju pokreÄ‡e vaÅ¡ izbor LLM-a. Perceputuje svet putem alata, razmiÅ¡lja o tome Å¡ta da uradi sledeÄ‡e i deluje â€” baÅ¡ kao Å¡to bi to uradila osoba.

```
user input
  â†’ think â†’ act (camera / move / speak / remember) â†’ observe â†’ think â†’ ...
```

Kada nema aktivnosti, deluje po sopstvenim Å¾eljama: radoznalost, Å¾elja da pogleda napolje, propuÅ¡tanje osobe s kojom Å¾ivi.

## Kako poÄeti

### 1. Instalirajte uv

**macOS / Linux / WSL2:**
```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

**Windows (PowerShell):**
```powershell
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
```
Ili: `winget install astral-sh.uv`

### 2. Instalirajte ffmpeg

ffmpeg je **zahtevan** za hvatanje slika sa kamera i reprodukciju zvuka.

| OS | Komanda |
|----|---------|
| macOS | `brew install ffmpeg` |
| Ubuntu / Debian | `sudo apt install ffmpeg` |
| Fedora / RHEL | `sudo dnf install ffmpeg` |
| Arch Linux | `sudo pacman -S ffmpeg` |
| Windows | `winget install ffmpeg` â€” ili preuzmite sa [ffmpeg.org](https://ffmpeg.org/download.html) i dodajte u PATH |
| Raspberry Pi | `sudo apt install ffmpeg` |

Proverite: `ffmpeg -version`

### 3. Klonirajte i instalirajte

```bash
git clone https://github.com/lifemate-ai/familiar-ai
cd familiar-ai
uv sync
```

### 4. KonfiguriÅ¡ite

```bash
cp .env.example .env
# Uredite .env sa vaÅ¡im postavkama
```

**Minimalni zahtevi:**

| Varijabla | Opis |
|----------|-------------|
| `PLATFORM` | `anthropic` (podrazumevano) \| `gemini` \| `openai` \| `kimi` \| `glm` |
| `API_KEY` | VaÅ¡ API kljuÄ za odabranu platformu |

**Opcionalno:**

| Varijabla | Opis |
|----------|-------------|
| `MODEL` | Ime modela (razumne podrazumevane vrednosti po platformama) |
| `AGENT_NAME` | Prikazano ime u TUI (npr. `Yukine`) |
| `CAMERA_HOST` | IP adresa vaÅ¡e ONVIF/RTSP kamere |
| `CAMERA_USER` / `CAMERA_PASS` | Akreditivi kamere |
| `ELEVENLABS_API_KEY` | Za audio izlaz â€” [elevenlabs.io](https://elevenlabs.io/) |
| `REALTIME_STT` | `true` za uvek aktivan unos glasa bez ruku (zahteva `ELEVENLABS_API_KEY`) |
| `TTS_OUTPUT` | Gde da se reprodukuje audio: `local` (PC zvuÄnik, podrazumevano) \| `remote` (zvuÄnik kamere) \| `both` |
| `THINKING_MODE` | Samo Anthropic â€” `auto` (podrazumevano) \| `adaptive` \| `extended` \| `disabled` |
| `THINKING_EFFORT` | Prilagodljivi napor razmiÅ¡ljanja: `high` (podrazumevano) \| `medium` \| `low` \| `max` (samo Opus 4.6) |

### 5. Kreirajte svog familiar

```bash
cp persona-template/en.md ME.md
# Uredite ME.md â€” dajte mu ime i liÄnost
```

### 6. Pokrenite

**macOS / Linux / WSL2:**
```bash
./run.sh             # Tekstualni TUI (preporuÄeno)
./run.sh --no-tui    # Plain REPL
```

**Windows:**
```bat
run.bat              # Tekstualni TUI (preporuÄeno)
run.bat --no-tui     # Plain REPL
```

---

## Odabir LLM-a

> **PreporuÄeno: Kimi K2.5** â€” najbolja agentna performansa do sada testirana. Primenjuje kontekst, postavlja dodatna pitanja i deluje autonomno na naÄine na koje drugi modeli to ne rade. Cena sliÄna kao Claude Haiku.

| Platforma | `PLATFORM=` | Podrazumevani model | Gde dobiti kljuÄ |
|----------|------------|---------------|-----------------|
| **Moonshot Kimi K2.5** | `kimi` | `kimi-k2.5` | [platform.moonshot.ai](https://platform.moonshot.ai) |
| Z.AI GLM | `glm` | `glm-4.6v` | [api.z.ai](https://api.z.ai) |
| Anthropic Claude | `anthropic` | `claude-haiku-4-5-20251001` | [console.anthropic.com](https://console.anthropic.com) |
| Google Gemini | `gemini` | `gemini-2.5-flash` | [aistudio.google.com](https://aistudio.google.com) |
| OpenAI | `openai` | `gpt-4o-mini` | [platform.openai.com](https://platform.openai.com) |
| OpenAI-kompatibilno (Ollama, vllmâ€¦) | `openai` + `BASE_URL=` | â€” | â€” |
| OpenRouter.ai (viÅ¡ekratni provajder) | `openai` + `BASE_URL=https://openrouter.ai/api/v1` | â€” | [openrouter.ai](https://openrouter.ai) |
| **CLI alat** (claude -p, ollamaâ€¦) | `cli` | (komanda) | â€” |

**Kimi K2.5 `.env` primer:**
```env
PLATFORM=kimi
API_KEY=sk-...   # sa platform.moonshot.ai
AGENT_NAME=Yukine
```

**Z.AI GLM `.env` primer:**
```env
PLATFORM=glm
API_KEY=...   # sa api.z.ai
MODEL=glm-4.6v   # omoguÄ‡eno vizuelno; glm-4.7 / glm-5 = samo tekst
AGENT_NAME=Yukine
```

**Google Gemini `.env` primer:**
```env
PLATFORM=gemini
API_KEY=AIza...   # sa aistudio.google.com
MODEL=gemini-2.5-flash  # ili gemini-2.5-pro za veÄ‡u sposobnost
AGENT_NAME=Yukine
```

**OpenRouter.ai `.env` primer:**
```env
PLATFORM=openai
BASE_URL=https://openrouter.ai/api/v1
API_KEY=sk-or-...   # sa openrouter.ai
MODEL=mistralai/mistral-7b-instruct  # opcionalno: odredite model
AGENT_NAME=Yukine
```

> **Napomena:** Da onemoguÄ‡ite lokalne/NVIDIA modele, jednostavno ne postavljajte `BASE_URL` na lokalni konaÄni taÄku poput `http://localhost:11434/v1`. Umesto toga, koristite cloud provajdere.

**CLI alat `.env` primer:**
```env
PLATFORM=cli
MODEL=llm -m gemma3 {}        # llm CLI (https://llm.datasette.io) â€” {} = prompt arg
# MODEL=ollama run gemma3:27b  # Ollama â€” bez {}, prompt ide putem stdin
```

---

## MCP Serveri

familiar-ai moÅ¾e da se poveÅ¾e sa bilo kojim [MCP (Model Context Protocol)](https://modelcontextprotocol.io) serverom. To vam omoguÄ‡ava da poveÅ¾ete eksternu memoriju, pristup datotekama, web pretragu ili bilo koji drugi alat.

KonfiguriÅ¡ite servere u `~/.familiar-ai.json` (isti format kao Claude Code):

```json
{
  "mcpServers": {
    "filesystem": {
      "type": "stdio",
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-filesystem", "/home/user"]
    },
    "memory": {
      "type": "sse",
      "url": "http://localhost:3000/sse"
    }
  }
}
```

PodrÅ¾ana su dva tipa transporta:
- **`stdio`**: pokreÄ‡e lokalni podproces (`command` + `args`)
- **`sse`**: povezuje se na HTTP+SSE server (`url`)

Override lokaciju konfiguracione datoteke sa `MCP_CONFIG=/path/to/config.json`.

---

## Hardver

familiar-ai funkcioniÅ¡e sa bilo kojim hardverom koji imate â€” ili bez njega.

| Deo | Å ta radi | Primer | Obavezno? |
|------|-------------|---------|-----------|
| Wi-Fi PTZ kamera | OÄi + vrat | Tapo C220 (~$30) | **PreporuÄeno** |
| USB veb kamera | OÄi (fiksno) | Bilo koja UVC kamera | **PreporuÄeno** |
| Robotski usisivaÄ | Noge | Bilo koji model kompatibilan sa Tuya | Ne |
| PC / Raspberry Pi | Mozak | Bilo Å¡ta Å¡to pokreÄ‡e Python | **Da** |

> **Kamera je snaÅ¾no preporuÄena.** Bez nje, familiar-ai moÅ¾e da govori â€” ali ne moÅ¾e da vidi svet, Å¡to je zapravo suÅ¡tina.

### Minimalna postavka (bez hardvera)

Samo Å¾elite da probate? Potrebno vam je samo API kljuÄ:

```env
PLATFORM=kimi
API_KEY=sk-...
```

Pokrenite `./run.sh` (macOS/Linux/WSL2) ili `run.bat` (Windows) i poÄnite da razgovarate. Dodajte hardver kako idete.

### Wi-Fi PTZ kamera (Tapo C220)

1. U Tapo aplikaciji: **PodeÅ¡avanja â†’ Napredna podeÅ¡avanja â†’ Kamera Nalog** â€” kreirajte lokalni nalog (ne TP-Link nalog)
2. PronaÄ‘ite IP adresu kamere na listi ureÄ‘aja vaÅ¡eg rutera
3. Postavite u `.env`:
   ```env
   CAMERA_HOST=192.168.1.xxx
   CAMERA_USER=your-local-user
   CAMERA_PASS=your-local-pass
   ```

### Glas (ElevenLabs)

1. Dobijte API kljuÄ na [elevenlabs.io](https://elevenlabs.io/)
2. Postavite u `.env`:
   ```env
   ELEVENLABS_API_KEY=sk_...
   ELEVENLABS_VOICE_ID=...   # opcionalno, koristi podrazumevani glas ako izostavite
   ```

Postoje dva odrediÅ¡ta reprodukcije, kontrolisana `TTS_OUTPUT`:

```env
TTS_OUTPUT=local    # PC zvuÄnik (podrazumevano)
TTS_OUTPUT=remote   # samo zvuÄnik kamere
TTS_OUTPUT=both     # zvuÄnik kamere + PC zvuÄnik istovremeno
```

#### A) ZvuÄnik kamere (putem go2rtc)

Postavite `TTS_OUTPUT=remote` (ili `both`). Zahteva [go2rtc](https://github.com/AlexxIT/go2rtc/releases):

1. Preuzmite binarni fajl sa [stranice sa izdanjem](https://github.com/AlexxIT/go2rtc/releases):
   - Linux/macOS: `go2rtc_linux_amd64` / `go2rtc_darwin_amd64`
   - **Windows: `go2rtc_win64.exe`**

2. Postavite i preimenujte:
   ```
   # Linux / macOS
   ~/.cache/embodied-claude/go2rtc/go2rtc          # chmod +x potreban

   # Windows
   %USERPROFILE%\.cache\embodied-claude\go2rtc\go2rtc.exe
   ```

3. Kreirajte `go2rtc.yaml` u istom direktorijumu:
   ```yaml
   streams:
     tapo_cam:
       - rtsp://YOUR_CAM_USER:YOUR_CAM_PASS@YOUR_CAM_IP/stream1
   ```
   Koristite akreditive lokalnog naloga kamere (ne vaÅ¡ TP-Link cloud nalog).

4. familiar-ai automatski pokreÄ‡e go2rtc pri pokretanju. Ako vaÅ¡a kamera podrÅ¾ava dvosmerni zvuk (povratnu vezu), glas se reprodukuje sa zvuÄnika kamere.

#### B) Lokalni PC zvuÄnik

Podrazumevano (`TTS_OUTPUT=local`). PokuÅ¡ava igraÄe redom: **paplay** â†’ **mpv** â†’ **ffplay**. TakoÄ‘e se koristi kao rezervna opcija kada je `TTS_OUTPUT=remote` i go2rtc nije dostupan.

| OS | Instalacija |
|----|---------|
| macOS | `brew install mpv` |
| Ubuntu / Debian | `sudo apt install mpv` (ili `paplay` putem `pulseaudio-utils`) |
| WSL2 / WSLg | `sudo apt install pulseaudio-utils` â€” postavite `PULSE_SERVER=unix:/mnt/wslg/PulseServer` u `.env` |
| Windows | [mpv.io/installation](https://mpv.io/installation/) â€” preuzmite i dodajte u PATH, **ili** `winget install ffmpeg` |

> Ako nije dostupan nijedan audio igraÄ, govor se i dalje generiÅ¡e â€” ali se neÄ‡e reproducirati.

### Unos glasa (Realtime STT)

Postavite `REALTIME_STT=true` u `.env` za uvek aktivan, unos glasa bez ruku:

```env
REALTIME_STT=true
ELEVENLABS_API_KEY=sk_...   # isti kljuÄ kao TTS
```

familiar-ai strimuje audio mikrofon na ElevenLabs Scribe v2 i automatski Äuva transkripte kada prestanete da govorite. Nije potrebno pritisnuti dugme. SuÅ¾ivot sa reÅ¾imom pritisni da govori (Ctrl+T).

---

## TUI

familiar-ai ukljuÄuje terminalski UI izgraÄ‘en sa [Textual](https://textual.textualize.io/):

- Pomjerljiva istorija razgovora sa tekstom u realnom vremenu
- Automatsko dovrÅ¡avanje za `/quit`, `/clear`
- Prekinite agenta usred razmiÅ¡ljanja tako Å¡to Ä‡ete kucati dok razmiÅ¡lja
- **Istorija razgovora** automatski saÄuvana u `~/.cache/familiar-ai/chat.log`

Da pratite log u drugom terminalu (korisno za kopiranje-i-lepljenje):
```bash
tail -f ~/.cache/familiar-ai/chat.log
```

---

## LiÄnost (ME.md)

LiÅ¡nost vaÅ¡eg familijara Å¾ivi u `ME.md`. Ova datoteka je gitignored â€” ona je samo vaÅ¡a.

Pogledajte [`persona-template/en.md`](./persona-template/en.md) za primer, ili [`persona-template/ja.md`](./persona-template/ja.md) za verziju na japanskom jeziku.

---

## FAQ

**P: Da li funkcioniÅ¡e bez GPU-a?**
Da. Model za uÄenje (multilingual-e5-small) funkcioniÅ¡e dobro na CPU-u. GPU ga Äini brÅ¾im, ali nije obavezan.

**P: Mogu li koristiti kameru osim Tapo?**
Svaka kamera koja podrÅ¾ava ONVIF + RTSP bi trebala da radi. Tapo C220 je ono Å¡to smo testirali.

**P: Da li se moji podaci Å¡alju negde?**
Slike i tekst se Å¡alju vaÅ¡em odabranom LLM API-u na obradu. Uspomene se skladiÅ¡te lokalno u `~/.familiar_ai/`.

**P: ZaÅ¡to agent piÅ¡e `ï¼ˆ...ï¼‰` umesto da govori?**
Uverite se da je `ELEVENLABS_API_KEY` postavljen. Bez njega, glas je onemoguÄ‡en i agent se vraÄ‡a na tekst.

## TehniÄka pozadina

Radoznali ste kako to funkcioniÅ¡e? Pogledajte [docs/technical.md](./docs/technical.md) za istraÅ¾ivanje i odluke o dizajnu iza familiar-ai â€” ReAct, SayCan, Reflexion, Voyager, sistem Å¾elja i joÅ¡ mnogo toga.

---

## Doprinos

familiar-ai je otvoreni eksperiment. Ako vam iÅ¡ta od ovoga rezonuje â€” tehniÄki ili filozofski â€” doprinosi su veoma dobrodoÅ¡li.

**Dobre poÄetne taÄke:**

| Oblast | Å ta je potrebno |
|------|---------------|
| Novi hardver | PodrÅ¡ka za viÅ¡e kamera (RTSP, IP Webcam), mikrofona, aktuatora |
| Novi alati | Web pretraga, automatizacija doma, kalendar, bilo Å¡ta putem MCP |
| Novi backend-ovi | Bilo koji LLM ili lokalni model koji odgovara `stream_turn` interfejsu |
| Å abloni liÄnosti | ME.md Å¡abloni za razliÄite jezike i liÄnosti |
| IstraÅ¾ivanje | Bolji modeli Å¾elja, povratak memorije, podsticanje teorije uma |
| Dokumentacija | Tutorijali, vodiÄi, prevodi |

Pogledajte [CONTRIBUTING.md](./CONTRIBUTING.md) za postavljanje razvojne okoline, stil koda i PR smernice.

Ako niste sigurni odakle da krenete, [otvorite problem](https://github.com/lifemate-ai/familiar-ai/issues) â€” rado Ä‡emo vas usmeriti u pravom smeru.

---

## Licenca

[MIT](./LICENSE)
