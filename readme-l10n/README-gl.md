# familiar-ai üêæ

**Unha IA que vive xunto a ti** ‚Äî con ollos, voz, pernas e memoria.

[![Lint](https://github.com/kmizu/familiar-ai/actions/workflows/lint.yml/badge.svg)](https://github.com/kmizu/familiar-ai/actions/workflows/lint.yml)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](./LICENSE)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/)
[![GitHub Sponsors](https://img.shields.io/github/sponsors/kmizu?style=flat&logo=github&color=ea4aaa)](https://github.com/sponsors/kmizu)

üåç [Dispon√≠bel en 74 linguas](./SUPPORTED_LANGUAGES.md)

---

[![Demo video](https://img.youtube.com/vi/hiR9uWRnjt4/0.jpg)](https://youtube.com/shorts/hiR9uWRnjt4)

familiar-ai √© un compa√±eiro de IA que vive na t√∫a casa. 
Config√∫rao en minutos. Non se require programaci√≥n.

Percibe o mundo real a trav√©s de c√°maras, m√≥vese nun corpo robot, fala en voz alta e lembra o que ve. D√°le un nome, escribe a s√∫a personalidade e d√©ixao vivir contigo.

## O que pode facer

- üëÅ **Ver** ‚Äî captura imaxes dende unha c√°mara PTZ Wi-Fi ou webcam USB
- üîÑ **Mirar arredor** ‚Äî panor√°mica e inclina a c√°mara para explorar o seu arredor
- ü¶ø **Mover** ‚Äî xira un aspirador robot para percorrer a habitaci√≥n
- üó£ **Falar** ‚Äî conversa a trav√©s de ElevenLabs TTS
- üéô **Escoitar** ‚Äî entrada de voz sen mans a trav√©s de ElevenLabs Realtime STT (optativo)
- üß† **Lembrar** ‚Äî almacena e recupera activamente recordos cunha busca sem√°ntica (SQLite + embeddings)
- ü´Ä **Teor√≠a da mente** ‚Äî toma a perspectiva da outra persoa antes de responder
- üí≠ **Desexo** ‚Äî ten os seus propios impulsos internos que desencadenan comportamento aut√≥nomo

## Como funciona

familiar-ai executa un loop [ReAct](https://arxiv.org/abs/2210.03629) impulsado pola t√∫a escolha de LLM. Percibe o mundo a trav√©s de ferramentas, pensa en que facer a continuaci√≥n e act√∫a ‚Äî como far√≠a unha persoa.

```
user input
  ‚Üí think ‚Üí act (camera / move / speak / remember) ‚Üí observe ‚Üí think ‚Üí ...
```

Cando est√° inactivo, act√∫a segundo os seus propios desexos: curiosidade, desexo de mirar f√≥ra, a echo da persoa coa que vive.

## Comezando

### 1. Instala uv

**macOS / Linux / WSL2:**
```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

**Windows (PowerShell):**
```powershell
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
```
Ou: `winget install astral-sh.uv`

### 2. Instala ffmpeg

ffmpeg √© **requirido** para capturar imaxes da c√°mara e reproduci√≥n de audio.

| OS | Comando |
|----|---------|
| macOS | `brew install ffmpeg` |
| Ubuntu / Debian | `sudo apt install ffmpeg` |
| Fedora / RHEL | `sudo dnf install ffmpeg` |
| Arch Linux | `sudo pacman -S ffmpeg` |
| Windows | `winget install ffmpeg` ‚Äî ou descarga dende [ffmpeg.org](https://ffmpeg.org/download.html) e eng√°deo ao PATH |
| Raspberry Pi | `sudo apt install ffmpeg` |

Verifica: `ffmpeg -version`

### 3. Clona e instala

```bash
git clone https://github.com/lifemate-ai/familiar-ai
cd familiar-ai
uv sync
```

### 4. Configura

```bash
cp .env.example .env
# Edita .env cos teus par√°metros
```

**M√≠nimo requirido:**

| Variable | Descrici√≥n |
|----------|-------------|
| `PLATFORM` | `anthropic` (por defecto) \| `gemini` \| `openai` \| `kimi` \| `glm` |
| `API_KEY` | A tua clave de API para a plataforma escollida |

**Opcional:**

| Variable | Descrici√≥n |
|----------|-------------|
| `MODEL` | Nome do modelo (valores por defecto para cada plataforma) |
| `AGENT_NAME` | Nome que se amosa na TUI (por exemplo `Yukine`) |
| `CAMERA_HOST` | Direcci√≥n IP da t√∫a c√°mara ONVIF/RTSP |
| `CAMERA_USER` / `CAMERA_PASS` | Credenciais da c√°mara |
| `ELEVENLABS_API_KEY` | Para a sa√≠da de voz ‚Äî [elevenlabs.io](https://elevenlabs.io/) |
| `REALTIME_STT` | `true` para habilitar a entrada de voz sen mans (requiere `ELEVENLABS_API_KEY`) |
| `TTS_OUTPUT` | Onde reproducir audio: `local` (altofalante do PC, por defecto) \| `remote` (altofalante da c√°mara) \| `both` |
| `THINKING_MODE` | S√≥ Anthropic ‚Äî `auto` (por defecto) \| `adaptive` \| `extended` \| `disabled` |
| `THINKING_EFFORT` | Esforzo de pensamento adaptativo: `high` (por defecto) \| `medium` \| `low` \| `max` (s√≥ Opus 4.6) |

### 5. Crea o teu familiar

```bash
cp persona-template/en.md ME.md
# Edita ME.md ‚Äî d√°selle un nome e personalidade
```

### 6. Executa

**macOS / Linux / WSL2:**
```bash
./run.sh             # TUI textual (recomendado)
./run.sh --no-tui    # REPL plano
```

**Windows:**
```bat
run.bat              # TUI textual (recomendado)
run.bat --no-tui     # REPL plano
```

---

## Escollendo un LLM

> **Recomendado: Kimi K2.5** ‚Äî a mellor rendibilidade de axente probada ata agora. Nota o contexto, fai preguntas de seguimento e act√∫a de maneira aut√≥noma onde outros modelos non o fan. Prezo similar a Claude Haiku.

| Plataforma | `PLATFORM=` | Modelo por defecto | Onde conseguir a clave |
|----------|------------|---------------|-----------------|
| **Moonshot Kimi K2.5** | `kimi` | `kimi-k2.5` | [platform.moonshot.ai](https://platform.moonshot.ai) |
| Z.AI GLM | `glm` | `glm-4.6v` | [api.z.ai](https://api.z.ai) |
| Anthropic Claude | `anthropic` | `claude-haiku-4-5-20251001` | [console.anthropic.com](https://console.anthropic.com) |
| Google Gemini | `gemini` | `gemini-2.5-flash` | [aistudio.google.com](https://aistudio.google.com) |
| OpenAI | `openai` | `gpt-4o-mini` | [platform.openai.com](https://platform.openai.com) |
| OpenAI-compatible (Ollama, vllm‚Ä¶) | `openai` + `BASE_URL=` | ‚Äî | ‚Äî |
| OpenRouter.ai (multi-provider) | `openai` + `BASE_URL=https://openrouter.ai/api/v1` | ‚Äî | [openrouter.ai](https://openrouter.ai) |
| **CLI tool** (claude -p, ollama‚Ä¶) | `cli` | (o comando) | ‚Äî |

**Exemplo de `.env` para Kimi K2.5:**
```env
PLATFORM=kimi
API_KEY=sk-...   # de platform.moonshot.ai
AGENT_NAME=Yukine
```

**Exemplo de `.env` para Z.AI GLM:**
```env
PLATFORM=glm
API_KEY=...   # de api.z.ai
MODEL=glm-4.6v   # habilitado para visi√≥n; glm-4.7 / glm-5 = s√≥ texto
AGENT_NAME=Yukine
```

**Exemplo de `.env` para Google Gemini:**
```env
PLATFORM=gemini
API_KEY=AIza...   # de aistudio.google.com
MODEL=gemini-2.5-flash  # ou gemini-2.5-pro para maior capacidade
AGENT_NAME=Yukine
```

**Exemplo de `.env` para OpenRouter.ai:**
```env
PLATFORM=openai
BASE_URL=https://openrouter.ai/api/v1
API_KEY=sk-or-...   # de openrouter.ai
MODEL=mistralai/mistral-7b-instruct  # opcional: especifica o modelo
AGENT_NAME=Yukine
```

> **Nota:** Para desactivar modelos locais/NVIDIA, simplemente non configures `BASE_URL` para un punto final local como `http://localhost:11434/v1`. Usa provedores en nube en lugar diso.

**Exemplo de `.env` para CLI tool:**
```env
PLATFORM=cli
MODEL=llm -m gemma3 {}        # llm CLI (https://llm.datasette.io) ‚Äî {} = argumento de prompt
# MODEL=ollama run gemma3:27b  # Ollama ‚Äî sen {}, o prompt vai por stdin
```

---

## Servidores MCP

familiar-ai pode conectarse a calquera servidor [MCP (Model Context Protocol)](https://modelcontextprotocol.io). Isto perm√≠telle conectar memoria externa, acceso a sistema de ficheiros, busca en web, ou calquera outra ferramenta.

Configura servidores en `~/.familiar-ai.json` (mesmo formato que Claude Code):

```json
{
  "mcpServers": {
    "filesystem": {
      "type": "stdio",
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-filesystem", "/home/user"]
    },
    "memory": {
      "type": "sse",
      "url": "http://localhost:3000/sse"
    }
  }
}
```

D√∫as tipos de transporte son soportados:
- **`stdio`**: lanza un subprocesso local (`command` + `args`)
- **`sse`**: con√©ctase a un servidor HTTP+SSE (`url`)

Override a ubicaci√≥n do ficheiro de configuraci√≥n con `MCP_CONFIG=/path/to/config.json`.

---

## Hardware

familiar-ai funciona co que queiras ‚Äî ou sen nada.

| Parte | O que fai | Exemplo | Necesario? |
|------|-------------|---------|-----------|
| C√°mara PTZ Wi-Fi | Ollos + pescozo | Tapo C220 (~$30) | **Recomendado** |
| Webcam USB | Ollos (fixo) | Calquera c√°mara UVC | **Recomendado** |
| Aspirador robot | pernas | Calquera modelo compatible con Tuya | Non |
| PC / Raspberry Pi | Cerebro | Calquera que execute Python | **Si** |

> **Recom√©ndase fortemente unha c√°mara.** Sen unha, familiar-ai pode falar ‚Äî pero non pode ver o mundo, que √© un pouco o bote da cuesti√≥n.

### Configuraci√≥n m√≠nima (sen hardware)

Queres s√≥ probalo? S√≥ necesitas unha clave de API:

```env
PLATFORM=kimi
API_KEY=sk-...
```

Executa `./run.sh` (macOS/Linux/WSL2) ou `run.bat` (Windows) e comeza a charlar. Engade hardware conforme avanzas.

### C√°mara PTZ Wi-Fi (Tapo C220)

1. Na app de Tapo: **Configuraci√≥n ‚Üí Avanzada ‚Üí Conta da C√°mara** ‚Äî crea unha conta local (non a conta de TP-Link)
2. Atopa a IP da c√°mara na lista de dispositivos do teu router
3. Establece en `.env`:
   ```env
   CAMERA_HOST=192.168.1.xxx
   CAMERA_USER=your-local-user
   CAMERA_PASS=your-local-pass
   ```

### Voz (ElevenLabs)

1. Obt√©n unha clave de API en [elevenlabs.io](https://elevenlabs.io/)
2. Establece en `.env`:
   ```env
   ELEVENLABS_API_KEY=sk_...
   ELEVENLABS_VOICE_ID=...   # opcional, usa a voz por defecto se se omite
   ```

Hai dous destinos de reproduci√≥n, controlados por `TTS_OUTPUT`:

```env
TTS_OUTPUT=local    # Altavoz do PC (por defecto)
TTS_OUTPUT=remote   # s√≥ altavoz da c√°mara
TTS_OUTPUT=both     # altavoz da c√°mara + altavoz do PC simultaneamente
```

#### A) Altavoz da c√°mara (a trav√©s de go2rtc)

Establece `TTS_OUTPUT=remote` (ou `both`). Require [go2rtc](https://github.com/AlexxIT/go2rtc/releases):

1. Descarga o binario da [p√°xina de lanzamentos](https://github.com/AlexxIT/go2rtc/releases):
   - Linux/macOS: `go2rtc_linux_amd64` / `go2rtc_darwin_amd64`
   - **Windows: `go2rtc_win64.exe`**

2. Col√≥cao e ren√≥mrao:
   ```
   # Linux / macOS
   ~/.cache/embodied-claude/go2rtc/go2rtc          # chmod +x necesario

   # Windows
   %USERPROFILE%\.cache\embodied-claude\go2rtc\go2rtc.exe
   ```

3. Crea `go2rtc.yaml` na mesma carpeta:
   ```yaml
   streams:
     tapo_cam:
       - rtsp://YOUR_CAM_USER:YOUR_CAM_PASS@YOUR_CAM_IP/stream1
   ```
   Usa as credenciais da conta local da c√°mara (non a t√∫a conta en nube de TP-Link).

4. familiar-ai inicia go2rtc automaticamente ao lanzarse. Se a t√∫a c√°mara soporta audio bidireccional (canle de volta), a voz reproduce dende o altavoz da c√°mara.

#### B) Altavoz do PC local

O por defecto (`TTS_OUTPUT=local`). Intenta reprodutores en orde: **paplay** ‚Üí **mpv** ‚Üí **ffplay**. Tam√©n se usa como un fallback cando `TTS_OUTPUT=remote` e go2rtc non est√° dispo√±ible.

| OS | Instala |
|----|---------|
| macOS | `brew install mpv` |
| Ubuntu / Debian | `sudo apt install mpv` (ou `paplay` a trav√©s de `pulseaudio-utils`) |
| WSL2 / WSLg | `sudo apt install pulseaudio-utils` ‚Äî establece `PULSE_SERVER=unix:/mnt/wslg/PulseServer` en `.env` |
| Windows | [mpv.io/installation](https://mpv.io/installation/) ‚Äî descarga e eng√°deo ao PATH, **ou** `winget install ffmpeg` |

> Se non hai ning√∫n reprodutor de audio dispo√±ible, a fala a√≠nda se xera ‚Äî simplemente non se reproducir√°.

### Entrada de voz (Realtime STT)

Establece `REALTIME_STT=true` en `.env` para entrada de voz sempre activa e sen mans:

```env
REALTIME_STT=true
ELEVENLABS_API_KEY=sk_...   # mesma clave que TTS
```

familiar-ai transmite audio do micr√≥fono a ElevenLabs Scribe v2 e auto-confirma transcrici√≥ns cando pares de falar. Non se require presi√≥n de bot√≥n. Coexiste co modo de pulsar para falar (Ctrl+T).

---

## TUI

familiar-ai incl√∫e unha interface de terminal construida con [Textual](https://textual.textualize.io/):

- Historial de conversaci√≥n desprazable con texto en streaming en vivo
- Completado de tabulaci√≥n para `/quit`, `/clear`
- Interrompe ao axente a medio pensamento escribindo mentres est√° pensando
- **Log de conversaci√≥n** auto-desgravado en `~/.cache/familiar-ai/chat.log`

Para seguir o log en outra terminal (√∫til para copiar e pegar):
```bash
tail -f ~/.cache/familiar-ai/chat.log
```

---

## Persona (ME.md)

A personalidade do teu familiar vive en `ME.md`. Este ficheiro est√° ignorado por git ‚Äî √© s√≥ teu.

V√©xase [`persona-template/en.md`](./persona-template/en.md) para un exemplo, ou [`persona-template/ja.md`](./persona-template/ja.md) para unha versi√≥n en xapon√©s.

---

## FAQ

**Q: Funciona sen GPU?**
Si. O modelo de embedding (multilingual-e5-small) funciona ben en CPU. Unha GPU faina m√°is r√°pida pero non √© necesaria.

**Q: Podo usar unha c√°mara que non sexa Tapo?**
Calquera c√°mara que soporte ONVIF + RTSP deber√≠a funcionar. Tapo C220 √© o que probamos.

**Q: Se env√≠an os meus datos a alg√∫n lugar?**
As imaxes e o texto env√≠ase √° API do LLM escollido para procesamento. Os recordos almac√©nanse localmente en `~/.familiar_ai/`.

**Q: Por que o axente escribe `Ôºà...Ôºâ` en lugar de falar?**
Aseg√∫rate de que `ELEVENLABS_API_KEY` est√° configurado. Sen el, a voz est√° desactivada e o axente recorre ao texto.

## Antecedentes t√©cnicos

Curioso sobre como funciona? Vexa [docs/technical.md](./docs/technical.md) para as investigaci√≥ns e decisi√≥ns de dese√±o detr√°s de familiar-ai ‚Äî ReAct, SayCan, Reflexion, Voyager, o sistema de desexo, e m√°is.

---

## Contribu√≠ndo

familiar-ai √© un experimento aberto. Se algo diso resoa contigo ‚Äî t√©cnica ou filos√≥ficamente ‚Äî as contribuci√≥ns son moi benvidas.

**Boas formas de comezar:**

| √Årea | O que se necesita |
|------|---------------|
| Novo hardware | Soporte para m√°is c√°maras (RTSP, IP Webcam), micr√≥fonos, actuadores |
| Novas ferramentas | Busca en web, automatizaci√≥n do fogar, calendario, calquera cousa a trav√©s de MCP |
| Novos backends | Calquera LLM ou modelo local que se axuste √° interface `stream_turn` |
| Plantillas de persona | Plantillas de ME.md para diferentes linguas e personalidades |
| Investigaci√≥n | Mellores modelos de desexo, recuperaci√≥n de memoria, incitaci√≥n √° teor√≠a da mente |
| Documentaci√≥n | Tutoriais, gu√≠as, traduci√≥ns |

V√©xase [CONTRIBUTING.md](./CONTRIBUTING.md) para a configuraci√≥n do dev, estilo de c√≥digo, e gu√≠as de PR.

Se non est√°s seguro por onde comezar, [abre un problema](https://github.com/lifemate-ai/familiar-ai/issues) ‚Äî encantado de sinalarche na direcci√≥n correcta.

---

## Licenza

[MIT](./LICENSE)
