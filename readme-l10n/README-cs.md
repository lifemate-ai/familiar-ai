# familiar-ai üêæ

**Umƒõl√° inteligence, kter√° ≈æije po boku v√°s** ‚Äî s oƒçima, hlasem, nohama a pamƒõt√≠.

[![Lint](https://github.com/kmizu/familiar-ai/actions/workflows/lint.yml/badge.svg)](https://github.com/kmizu/familiar-ai/actions/workflows/lint.yml)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](./LICENSE)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/)
[![GitHub Sponsors](https://img.shields.io/github/sponsors/kmizu?style=flat&logo=github&color=ea4aaa)](https://github.com/sponsors/kmizu)

[‚Üí English README](../README.md)

---

[![Demo video](https://img.youtube.com/vi/hiR9uWRnjt4/0.jpg)](https://youtube.com/shorts/hiR9uWRnjt4)

familiar-ai je AI spoleƒçn√≠k, kter√Ω bydl√≠ ve va≈°em domovƒõ. Nastav√≠te ho za p√°r minut. Nen√≠ pot≈ôeba k√≥dov√°n√≠.

Vn√≠m√° re√°ln√Ω svƒõt skrze kamery, pohybuje se na tƒõle robota, mluv√≠ nahlas a pamatuje si, co vid√≠. Dejte mu jm√©no, napi≈°te jeho osobnost a nechte ho ≈æ√≠t s v√°mi.

## Co v≈°echno um√≠

- üëÅ **Vidƒõt** ‚Äî zachycuje obr√°zky z Wi-Fi PTZ kamery nebo USB webkamery
- üîÑ **Prohl√≠≈æet si okol√≠** ‚Äî ot√°ƒç√≠ a nakl√°n√≠ kameru, aby prozkoumala okol√≠
- ü¶ø **Pohybovat se** ‚Äî ≈ô√≠d√≠ robota-vysavaƒçe, kter√Ω se potuluje po m√≠stnosti
- üó£ **Mluvit** ‚Äî hovo≈ô√≠ skrze TTS ElevenLabs
- üéô **Poslouchat** ‚Äî bezdr√°tov√Ω hlasov√Ω vstup p≈ôes Realtime STT od ElevenLabs (opt-in)
- üß† **Pamƒõ≈•** ‚Äî aktivnƒõ ukl√°d√° a vybavuje si vzpom√≠nky s pomoc√≠ s√©mantick√©ho vyhled√°v√°n√≠ (SQLite + embeddings)
- ü´Ä **Teorie mysli** ‚Äî bere v √∫vahu perspektivu druh√© osoby p≈ôed odpovƒõd√≠
- üí≠ **Touha** ‚Äî m√° sv√© vlastn√≠ vnit≈ôn√≠ podnƒõty, kter√© spou≈°tƒõj√≠ autonomn√≠ chov√°n√≠

## Jak to funguje

familiar-ai bƒõ≈æ√≠ na [ReAct](https://arxiv.org/abs/2210.03629) smyƒçce, kter√Ω je poh√°nƒõn v√°mi vybran√Ωm LLM. Vn√≠m√° svƒõt skrze n√°stroje, p≈ôem√Ω≈°l√≠, co udƒõlat d√°l, a jedn√° ‚Äî jako by to byla osoba.

```
user input
  ‚Üí think ‚Üí act (camera / move / speak / remember) ‚Üí observe ‚Üí think ‚Üí ...
```

Kdy≈æ je v neƒçinnosti, jedn√° podle sv√Ωch vlastn√≠ch p≈ô√°n√≠: zvƒõdavosti, chtƒõn√≠ se pod√≠vat ven, stesk po osobƒõ, se kterou ≈æije.

## Jak zaƒç√≠t

### 1. Nainstalujte uv

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

### 2. Nainstalujte ffmpeg

ffmpeg je **vy≈æadov√°n** pro zachycen√≠ obr√°zk≈Ø z kamery a p≈ôehr√°v√°n√≠ zvuku.

| OS | P≈ô√≠kaz |
|----|---------|
| macOS | `brew install ffmpeg` |
| Ubuntu / Debian | `sudo apt install ffmpeg` |
| Fedora / RHEL | `sudo dnf install ffmpeg` |
| Arch Linux | `sudo pacman -S ffmpeg` |
| Windows | `winget install ffmpeg` ‚Äî nebo st√°hnƒõte ze [ffmpeg.org](https://ffmpeg.org/download.html) a p≈ôidejte do PATH |
| Raspberry Pi | `sudo apt install ffmpeg` |

Ovƒõ≈ôte: `ffmpeg -version`

### 3. Klonujte a nainstalujte

```bash
git clone https://github.com/lifemate-ai/familiar-ai
cd familiar-ai
uv sync
```

### 4. Nakonfigurujte

```bash
cp .env.example .env
# Upravit .env podle va≈°ich nastaven√≠
```

**Minim√°ln√≠ po≈æadov√°no:**

| Promƒõnn√° | Popis |
|----------|-------------|
| `PLATFORM` | `anthropic` (v√Ωchoz√≠) \| `gemini` \| `openai` \| `kimi` \| `glm` |
| `API_KEY` | V√°≈° API kl√≠ƒç pro vybranou platformu |

**Voliteln√©:**

| Promƒõnn√° | Popis |
|----------|-------------|
| `MODEL` | N√°zev modelu (rozumn√© v√Ωchoz√≠ hodnoty podle platformy) |
| `AGENT_NAME` | Zobrazovan√© jm√©no v TUI (nap≈ô. `Yukine`) |
| `CAMERA_HOST` | IP adresa va≈°√≠ ONVIF/RTSP kamery |
| `CAMERA_USER` / `CAMERA_PASS` | P≈ôihla≈°ovac√≠ √∫daje kamery |
| `ELEVENLABS_API_KEY` | Pro v√Ωstup hlasu ‚Äî [elevenlabs.io](https://elevenlabs.io/) |
| `REALTIME_STT` | `true` pro aktivaci neust√°l√©ho bezdr√°tov√©ho hlasov√©ho vstupu (vy≈æaduje `ELEVENLABS_API_KEY`) |
| `TTS_OUTPUT` | Kde p≈ôehr√°vat zvuk: `local` (PC reproduktor, v√Ωchoz√≠) \| `remote` (reproduktor kamery) \| `both` |
| `THINKING_MODE` | Pouze Anthropic ‚Äî `auto` (v√Ωchoz√≠) \| `adaptive` \| `extended` \| `disabled` |
| `THINKING_EFFORT` | Adaptivn√≠ √∫sil√≠ o my≈°len√≠: `high` (v√Ωchoz√≠) \| `medium` \| `low` \| `max` (pouze Opus 4.6) |

### 5. Vytvo≈ôte sv√©ho spoleƒçn√≠ka

```bash
cp persona-template/en.md ME.md
# Upravit ME.md ‚Äî dejte mu jm√©no a osobnost
```

### 6. Spus≈•te

```bash
./run.sh             # Textov√© TUI (doporuƒçeno)
./run.sh --no-tui    # Jednoduch√Ω REPL
```

---

## V√Ωbƒõr LLM

> **Doporuƒçeno: Kimi K2.5** ‚Äî nejlep≈°√≠ agentn√≠ v√Ωkon, kter√Ω jsme dosud testovali. V≈°√≠m√° si kontextu, klade n√°sledn√© ot√°zky a jedn√° autonomnƒõ zp≈Øsoby, kter√© jin√© modely nemaj√≠. Cena je podobn√° jako u Claude Haiku.

| Platforma | `PLATFORM=` | V√Ωchoz√≠ model | Kde z√≠skat kl√≠ƒç |
|----------|------------|---------------|-----------------|
| **Moonshot Kimi K2.5** | `kimi` | `kimi-k2.5` | [platform.moonshot.ai](https://platform.moonshot.ai) |
| Z.AI GLM | `glm` | `glm-4.6v` | [api.z.ai](https://api.z.ai) |
| Anthropic Claude | `anthropic` | `claude-haiku-4-5-20251001` | [console.anthropic.com](https://console.anthropic.com) |
| Google Gemini | `gemini` | `gemini-2.5-flash` | [aistudio.google.com](https://aistudio.google.com) |
| OpenAI | `openai` | `gpt-4o-mini` | [platform.openai.com](https://platform.openai.com) |
| OpenAI-kompatibiln√≠ (Ollama, vllm‚Ä¶) | `openai` + `BASE_URL=` | ‚Äî | ‚Äî |
| OpenRouter.ai (multi-provider) | `openai` + `BASE_URL=https://openrouter.ai/api/v1` | ‚Äî | [openrouter.ai](https://openrouter.ai) |
| **CLI n√°stroj** (claude -p, ollama‚Ä¶) | `cli` | (p≈ô√≠kaz) | ‚Äî |

**P≈ô√≠klad `.env` pro Kimi K2.5:**
```env
PLATFORM=kimi
API_KEY=sk-...   # z platform.moonshot.ai
AGENT_NAME=Yukine
```

**P≈ô√≠klad `.env` pro Z.AI GLM:**
```env
PLATFORM=glm
API_KEY=...   # z api.z.ai
MODEL=glm-4.6v   # s mo≈ænost√≠ vidƒõn√≠; glm-4.7 / glm-5 = pouze text
AGENT_NAME=Yukine
```

**P≈ô√≠klad `.env` pro Google Gemini:**
```env
PLATFORM=gemini
API_KEY=AIza...   # z aistudio.google.com
MODEL=gemini-2.5-flash  # nebo gemini-2.5-pro pro vy≈°≈°√≠ schopnosti
AGENT_NAME=Yukine
```

**P≈ô√≠klad `.env` pro OpenRouter.ai:**
```env
PLATFORM=openai
BASE_URL=https://openrouter.ai/api/v1
API_KEY=sk-or-...   # z openrouter.ai
MODEL=mistralai/mistral-7b-instruct  # voliteln√©: specifikujte model
AGENT_NAME=Yukine
```

> **Pozn√°mka:** Chcete-li zak√°zat m√≠stn√≠/NVIDIA modely, jednodu≈°e nenastavte `BASE_URL` na m√≠stn√≠ koncov√Ω bod, jako je `http://localhost:11434/v1`. Pou≈æijte m√≠sto toho cloudov√© poskytovatele.

**P≈ô√≠klad `.env` pro CLI n√°stroj:**
```env
PLATFORM=cli
MODEL=llm -m gemma3 {}        # llm CLI (https://llm.datasette.io) ‚Äî {} = argument prompt
# MODEL=ollama run gemma3:27b  # Ollama ‚Äî ≈æ√°dn√© {}, prompt jde p≈ôes stdin
```

---

## MCP Servery

familiar-ai se m≈Ø≈æe p≈ôipojit k jak√©mukoli [MCP (Model Context Protocol)](https://modelcontextprotocol.io) serveru. To v√°m umo≈æn√≠ zapojit extern√≠ pamƒõ≈•, p≈ô√≠stup k souborov√©mu syst√©mu, webov√© vyhled√°v√°n√≠ nebo jak√Ωkoli jin√Ω n√°stroj.

Nakonfigurujte servery v `~/.familiar-ai.json` (stejn√Ω form√°t jako Claude Code):

```json
{
  "mcpServers": {
    "filesystem": {
      "type": "stdio",
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-filesystem", "/home/user"]
    },
    "memory": {
      "type": "sse",
      "url": "http://localhost:3000/sse"
    }
  }
}
```

Jsou podporov√°ny dva typy p≈ôenosu:
- **`stdio`**: spustit m√≠stn√≠ podproces (`command` + `args`)
- **`sse`**: p≈ôipojit se k HTTP+SSE serveru (`url`)

P≈ôepi≈°te um√≠stƒõn√≠ konfiguraƒçn√≠ho souboru pomoc√≠ `MCP_CONFIG=/path/to/config.json`.

---

## Hardware

familiar-ai funguje s jak√Ωmkoli hardwarem, kter√Ω m√°te ‚Äî nebo tak√© bez nƒõj.

| ƒå√°st | Co dƒõl√° | P≈ô√≠klad | Po≈æadov√°no? |
|------|-------------|---------|-----------|
| Wi-Fi PTZ kamera | Oƒçi + krk | Tapo C220 (~$30) | **Doporuƒçeno** |
| USB webkamera | Oƒçi (pevn√©) | Jak√°koli UVC kamera | **Doporuƒçeno** |
| Robotick√Ω vysavaƒç | Nohy | Jak√Ωkoli model kompatibiln√≠ s Tuya | Ne |
| PC / Raspberry Pi | Mozek | Cokoli, co podporuje Python | **Ano** |

> **Kamera je d≈Øraznƒõ doporuƒçena.** Bez n√≠ m≈Ø≈æe familiar-ai st√°le mluvit, ale nem≈Ø≈æe vidƒõt svƒõt, co≈æ je vlastnƒõ cel√Ω √∫ƒçel.

### Minim√°ln√≠ nastaven√≠ (bez hardware)

Chcete si to jen vyzkou≈°et? Pot≈ôebujete pouze API kl√≠ƒç:

```env
PLATFORM=kimi
API_KEY=sk-...
```

Spus≈•te `./run.sh` a zaƒçnƒõte chatovat. Hardware p≈ôidejte postupnƒõ.

### Wi-Fi PTZ kamera (Tapo C220)

1. V aplikaci Tapo: **Nastaven√≠ ‚Üí Pokroƒçil√© ‚Üí √öƒçet kamery** ‚Äî vytvo≈ôte m√≠stn√≠ √∫ƒçet (ne √∫ƒçet TP-Link)
2. Najdƒõte IP adresu kamery v seznamu za≈ô√≠zen√≠ va≈°eho routeru
3. Nastavte v `.env`:
   ```env
   CAMERA_HOST=192.168.1.xxx
   CAMERA_USER=your-local-user
   CAMERA_PASS=your-local-pass
   ```

### Hlas (ElevenLabs)

1. Z√≠skejte API kl√≠ƒç na [elevenlabs.io](https://elevenlabs.io/)
2. Nastavte v `.env`:
   ```env
   ELEVENLABS_API_KEY=sk_...
   ELEVENLABS_VOICE_ID=...   # voliteln√©, pou≈æ√≠v√° v√Ωchoz√≠ hlas, pokud nen√≠ uvedeno
   ```

Existuj√≠ dvƒõ c√≠lov√© destinace pro p≈ôehr√°v√°n√≠, kter√© jsou ≈ô√≠zeny `TTS_OUTPUT`:

```env
TTS_OUTPUT=local    # PC reproduktor (v√Ωchoz√≠)
TTS_OUTPUT=remote   # pouze reproduktor kamery
TTS_OUTPUT=both     # reproduktor kamery + PC reproduktor souƒçasnƒõ
```

#### A) Reproduktor kamery (p≈ôes go2rtc)

Nastavte `TTS_OUTPUT=remote` (nebo `both`). Vy≈æaduje [go2rtc](https://github.com/AlexxIT/go2rtc/releases):

1. St√°hnƒõte bin√°rn√≠ soubor z [str√°nky s vyd√°n√≠mi](https://github.com/AlexxIT/go2rtc/releases):
   - Linux/macOS: `go2rtc_linux_amd64` / `go2rtc_darwin_amd64`
   - **Windows: `go2rtc_win64.exe`**

2. Um√≠stƒõte a p≈ôejmenujte ho:
   ```
   # Linux / macOS
   ~/.cache/embodied-claude/go2rtc/go2rtc          # chmod +x vy≈æadov√°no

   # Windows
   %USERPROFILE%\.cache\embodied-claude\go2rtc\go2rtc.exe
   ```

3. Vytvo≈ôte `go2rtc.yaml` ve stejn√©m adres√°≈ôi:
   ```yaml
   streams:
     tapo_cam:
       - rtsp://YOUR_CAM_USER:YOUR_CAM_PASS@YOUR_CAM_IP/stream1
   ```
   Pou≈æijte p≈ôihla≈°ovac√≠ √∫daje m√≠stn√≠ho √∫ƒçtu kamery (ne sv≈Øj √∫ƒçet TP-Link cloud).

4. familiar-ai automaticky spust√≠ go2rtc p≈ôi spu≈°tƒõn√≠. Pokud va≈°e kamera podporuje obousmƒõrn√Ω zvuk (zpƒõtn√Ω kan√°l), hlas se p≈ôehr√°v√° z reproduktoru kamery.

#### B) M√≠stn√≠ PC reproduktor

V√Ωchoz√≠ (`TTS_OUTPUT=local`). Zkou≈°√≠ p≈ôehr√°vaƒçe v po≈ôad√≠: **paplay** ‚Üí **mpv** ‚Üí **ffplay**. Tak√© se pou≈æ√≠v√° jako z√°loha, kdy≈æ je `TTS_OUTPUT=remote` a go2rtc nen√≠ k dispozici.

| OS | Instalace |
|----|---------|
| macOS | `brew install mpv` |
| Ubuntu / Debian | `sudo apt install mpv` (nebo `paplay` p≈ôes `pulseaudio-utils`) |
| WSL2 / WSLg | `sudo apt install pulseaudio-utils` ‚Äî nastavte `PULSE_SERVER=unix:/mnt/wslg/PulseServer` v `.env` |
| Windows | [mpv.io/installation](https://mpv.io/installation/) ‚Äî st√°hnƒõte a p≈ôidejte do PATH, **nebo** `winget install ffmpeg` |

> Pokud nen√≠ k dispozici ≈æ√°dn√Ω p≈ôehr√°vaƒç zvuku, ≈ôeƒç se st√°le generuje ‚Äî ale nebude p≈ôehr√°na.

### Hlasov√Ω vstup (Realtime STT)

Nastavte `REALTIME_STT=true` v `.env` pro neust√°l√Ω, bezdr√°tov√Ω hlasov√Ω vstup:

```env
REALTIME_STT=true
ELEVENLABS_API_KEY=sk_...   # stejn√Ω kl√≠ƒç jako pro TTS
```

familiar-ai streamuje zvuk z mikrofonu do ElevenLabs Scribe v2 a automaticky ukl√°d√° p≈ôepisy, kdy≈æ p≈ôestanete mluvit. Nen√≠ pot≈ôeba stisknout ≈æ√°dn√© tlaƒç√≠tko. Souƒçasnƒõ koexistuje s re≈æimem stisknut√≠ pro mluven√≠ (Ctrl+T).

---

## TUI

familiar-ai zahrnuje termin√°lov√© u≈æivatelsk√© rozhran√≠ vytvo≈ôen√© s [Textual](https://textual.textualize.io/):

- Poskytuje rolovac√≠ historii konverzace se ≈æiv√Ωm streamov√°n√≠m textu
- Dopl≈àov√°n√≠ tabul√°tor≈Ø pro `/quit`, `/clear`
- P≈ôeru≈°en√≠ agenta uprost≈ôed my≈°lenky t√≠m, ≈æe bƒõhem jeho p≈ôem√Ω≈°len√≠ nap√≠≈°ete
- **Z√°znam konverzace** automaticky ulo≈æen do `~/.cache/familiar-ai/chat.log`

Chcete-li sledovat z√°znam v jin√©m termin√°lu (u≈æiteƒçn√© pro kop√≠rov√°n√≠ a vlo≈æen√≠):
```bash
tail -f ~/.cache/familiar-ai/chat.log
```

---

## Osobnost (ME.md)

Osobnost va≈°eho spoleƒçn√≠ka ≈æije v `ME.md`. Tento soubor je gitignored ‚Äî je pouze v√°≈°.

Pod√≠vejte se na [`persona-template/en.md`](./persona-template/en.md) pro p≈ô√≠klad, nebo [`persona-template/ja.md`](./persona-template/ja.md) pro japonskou verzi.

---

## ƒåasto kladen√© ot√°zky

**Q: Funguje to bez GPU?**
Ano. Model vkl√°d√°n√≠ (multilingual-e5-small) bƒõ≈æ√≠ v po≈ô√°dku na CPU. GPU zrychluje jeho v√Ωkon, ale nen√≠ nutn√©.

**Q: Mohu pou≈æ√≠t jinou kameru ne≈æ Tapo?**
Jak√°koli kamera, kter√° podporuje ONVIF + RTSP, by mƒõla fungovat. Tapo C220 je to, co jsme testovali.

**Q: Odes√≠laj√≠ se moje data nƒõkam?**
Obr√°zky a texty se odes√≠laj√≠ na v√°mi vybran√Ω LLM API k zpracov√°n√≠. Vzpom√≠nky jsou ukl√°d√°ny lok√°lnƒõ v `~/.familiar_ai/`.

**Q: Proƒç agent p√≠≈°e `Ôºà...Ôºâ` m√≠sto mluven√≠?**
Ujistƒõte se, ≈æe je nastavena `ELEVENLABS_API_KEY`. Bez nƒõj je hlas deaktivov√°n a agent p≈ôech√°z√≠ na text.

## Technick√© pozad√≠

Zaj√≠m√° v√°s, jak to funguje? Pod√≠vejte se na [docs/technical.md](./docs/technical.md) pro v√Ωzkum a designov√© rozhodnut√≠ za familiar-ai ‚Äî ReAct, SayCan, Reflexion, Voyager, syst√©m p≈ô√°n√≠ a dal≈°√≠.

---

## P≈ôisp√≠v√°n√≠

familiar-ai je otev≈ôen√Ω experiment. Pokud v√°m nƒõco z toho rezonuje ‚Äî technicky nebo filozoficky ‚Äî p≈ô√≠spƒõvky jsou velmi v√≠t√°ny.

**Dobr√© m√≠sta, kde zaƒç√≠t:**

| Oblast | Co je pot≈ôeba |
|------|---------------|
| Nov√Ω hardware | Podpora pro v√≠ce kamer (RTSP, IP Webcam), mikrofony, akƒçn√≠ ƒçleny |
| Nov√© n√°stroje | Webov√© vyhled√°v√°n√≠, automatizace dom√°cnosti, kalend√°≈ô, cokoliv p≈ôes MCP |
| Nov√© backendy | Jak√Ωkoli LLM nebo m√≠stn√≠ model, kter√Ω vyhovuje rozhran√≠ `stream_turn` |
| ≈†ablony osobnosti | ≈†ablony ME.md pro r≈Øzn√© jazyky a osobnosti |
| V√Ωzkum | Lep≈°√≠ modely p≈ô√°n√≠, z√≠sk√°v√°n√≠ pamƒõti, podnƒõcov√°n√≠ teorie mysli |
| Dokumentace | Tutori√°ly, n√°vody, p≈ôeklady |

Pod√≠vejte se na [CONTRIBUTING.md](./CONTRIBUTING.md) pro nastaven√≠ v√Ωvoje, styl k√≥du a pokyny k PR.

Pokud si nejste jisti, kde zaƒç√≠t, [otev≈ôete probl√©m](https://github.com/lifemate-ai/familiar-ai/issues) ‚Äî r√°di v√°m uk√°≈æeme spr√°vn√Ωm smƒõrem.

---

## Licence

[MIT](./LICENSE)
