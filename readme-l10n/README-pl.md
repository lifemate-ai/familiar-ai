# familiar-ai ğŸ¾

**Sztuczna inteligencja, ktÃ³ra Å¼yje obok ciebie** â€” ma oczy, gÅ‚os, nogi i pamiÄ™Ä‡.

[![Lint](https://github.com/kmizu/familiar-ai/actions/workflows/lint.yml/badge.svg)](https://github.com/kmizu/familiar-ai/actions/workflows/lint.yml)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](./LICENSE)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/)
[![GitHub Sponsors](https://img.shields.io/github/sponsors/kmizu?style=flat&logo=github&color=ea4aaa)](https://github.com/sponsors/kmizu)

[â†’ English README](../README.md)

---

[![Demo video](https://img.youtube.com/vi/hiR9uWRnjt4/0.jpg)](https://youtube.com/shorts/hiR9uWRnjt4)

familiar-ai to towarzysz AI, ktÃ³ry mieszka w twoim domu. Skonfiguruj go w kilka minut. Nie wymaga programowania.

Postrzega prawdziwy Å›wiat przez kamery, porusza siÄ™ na robotycznym ciele, mÃ³wi na gÅ‚os i pamiÄ™ta, co widzi. Nadaj mu imiÄ™, opisz jego osobowoÅ›Ä‡ i pozwÃ³l mu mieszkaÄ‡ z tobÄ….

## Co potrafi

- ğŸ‘ **WidzieÄ‡** â€” rejestruje obrazy z kamery Wi-Fi PTZ lub kamery USB
- ğŸ”„ **RozglÄ…daÄ‡ siÄ™** â€” obraca i przechyla kamerÄ™, aby zbadaÄ‡ otoczenie
- ğŸ¦¿ **PoruszaÄ‡ siÄ™** â€” prowadzi robota odkurzacza po pokoju
- ğŸ—£ **MÃ³wiÄ‡** â€” rozmawia za pomocÄ… ElevenLabs TTS
- ğŸ™ **SÅ‚uchaÄ‡** â€” bezprzewodowe wejÅ›cie gÅ‚osowe za pomocÄ… ElevenLabs Realtime STT (opcjonalne)
- ğŸ§  **PamiÄ™taÄ‡** â€” aktywnie przechowuje i przypomina sobie wspomnienia z semantycznym wyszukiwaniem (SQLite + embeddingi)
- ğŸ«€ **Teoria umysÅ‚u** â€” przyjmuje perspektywÄ™ drugiej osoby przed odpowiedziÄ…
- ğŸ’­ **Pragnienie** â€” ma swoje wewnÄ™trzne potrzeby, ktÃ³re wyzwalajÄ… autonomiczne zachowanie

## Jak to dziaÅ‚a

familiar-ai uruchamia pÄ™tlÄ™ [ReAct](https://arxiv.org/abs/2210.03629) zasilanÄ… przez wybrany model LLM. Postrzega Å›wiat przez narzÄ™dzia, myÅ›li o tym, co zrobiÄ‡ nastÄ™pnie, i dziaÅ‚a â€” tak jak zrobiÅ‚by to czÅ‚owiek.

```
user input
  â†’ think â†’ act (kamera / ruch / mÃ³wienie / pamiÄ™tanie) â†’ obserwuj â†’ myÅ›l â†’ ...
```

Gdy jest bezczynny, dziaÅ‚a zgodnie z wÅ‚asnymi pragnieniami: ciekawoÅ›ciÄ…, chÄ™ciÄ… spojrzenia na zewnÄ…trz, tÄ™sknotÄ… za osobÄ…, z ktÃ³rÄ… mieszka.

## Jak zaczÄ…Ä‡

### 1. Zainstaluj uv

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

### 2. Zainstaluj ffmpeg

ffmpeg jest **wymagany** do rejestracji obrazu z kamery i odtwarzania dÅºwiÄ™ku.

| OS | Komenda |
|----|---------|
| macOS | `brew install ffmpeg` |
| Ubuntu / Debian | `sudo apt install ffmpeg` |
| Fedora / RHEL | `sudo dnf install ffmpeg` |
| Arch Linux | `sudo pacman -S ffmpeg` |
| Windows | `winget install ffmpeg` â€” lub pobierz z [ffmpeg.org](https://ffmpeg.org/download.html) i dodaj do PATH |
| Raspberry Pi | `sudo apt install ffmpeg` |

Zweryfikuj: `ffmpeg -version`

### 3. Sklonuj i zainstaluj

```bash
git clone https://github.com/lifemate-ai/familiar-ai
cd familiar-ai
uv sync
```

### 4. Skonfiguruj

```bash
cp .env.example .env
# Edytuj .env swoimi ustawieniami
```

**Minimalne wymagania:**

| Zmienna | Opis |
|---------|------|
| `PLATFORM` | `anthropic` (domyÅ›lnie) \| `gemini` \| `openai` \| `kimi` \| `glm` |
| `API_KEY` | TwÃ³j klucz API dla wybranej platformy |

**Opcjonalnie:**

| Zmienna | Opis |
|---------|------|
| `MODEL` | Nazwa modelu (rozsÄ…dne domyÅ›lne dla kaÅ¼dej platformy) |
| `AGENT_NAME` | WyÅ›wietlana nazwa w TUI (np. `Yukine`) |
| `CAMERA_HOST` | Adres IP twojej kamery ONVIF/RTSP |
| `CAMERA_USER` / `CAMERA_PASS` | PoÅ›wiadczenia kamery |
| `ELEVENLABS_API_KEY` | Do wyjÅ›cia gÅ‚osowego â€” [elevenlabs.io](https://elevenlabs.io/) |
| `REALTIME_STT` | `true`, aby wÅ‚Ä…czyÄ‡ zawsze aktywne wejÅ›cie gÅ‚osowe (wymaga `ELEVENLABS_API_KEY`) |
| `TTS_OUTPUT` | Gdzie odtwarzaÄ‡ dÅºwiÄ™k: `local` (gÅ‚oÅ›nik komputera, domyÅ›lnie) \| `remote` (gÅ‚oÅ›nik kamery) \| `both` |
| `THINKING_MODE` | Tylko Anthropic â€” `auto` (domyÅ›lnie) \| `adaptive` \| `extended` \| `disabled` |
| `THINKING_EFFORT` | Adaptacyjny wysiÅ‚ek myÅ›lenia: `high` (domyÅ›lnie) \| `medium` \| `low` \| `max` (tylko Opus 4.6) |

### 5. StwÃ³rz swojego towarzysza

```bash
cp persona-template/en.md ME.md
# Edytuj ME.md â€” nadaj mu imiÄ™ i osobowoÅ›Ä‡
```

### 6. Uruchom

```bash
./run.sh             # Tekstowe TUI (zalecane)
./run.sh --no-tui    # Prosty REPL
```

---

## WybÃ³r LLM

> **Zalecane: Kimi K2.5** â€” najlepsza wydajnoÅ›Ä‡ agentÃ³w testowanych do tej pory. ZauwaÅ¼a kontekst, zadaje pytania dodatkowe i dziaÅ‚a autonomicznie w sposÃ³b, w jaki inne modele tego nie robiÄ…. Cenowo porÃ³wnywalne z Claude Haiku.

| Platforma | `PLATFORM=` | DomyÅ›lny model | Gdzie uzyskaÄ‡ klucz |
|-----------|-------------|----------------|---------------------|
| **Moonshot Kimi K2.5** | `kimi` | `kimi-k2.5` | [platform.moonshot.ai](https://platform.moonshot.ai) |
| Z.AI GLM | `glm` | `glm-4.6v` | [api.z.ai](https://api.z.ai) |
| Anthropic Claude | `anthropic` | `claude-haiku-4-5-20251001` | [console.anthropic.com](https://console.anthropic.com) |
| Google Gemini | `gemini` | `gemini-2.5-flash` | [aistudio.google.com](https://aistudio.google.com) |
| OpenAI | `openai` | `gpt-4o-mini` | [platform.openai.com](https://platform.openai.com) |
| Kompatybilne z OpenAI (Ollama, vllmâ€¦) | `openai` + `BASE_URL=` | â€” | â€” |
| OpenRouter.ai (multi-provider) | `openai` + `BASE_URL=https://openrouter.ai/api/v1` | â€” | [openrouter.ai](https://openrouter.ai) |
| **NarzÄ™dzie CLI** (claude -p, ollamaâ€¦) | `cli` | (komenda) | â€” |

**PrzykÅ‚ad `.env` dla Kimi K2.5:**
```env
PLATFORM=kimi
API_KEY=sk-...   # z platform.moonshot.ai
AGENT_NAME=Yukine
```

**PrzykÅ‚ad `.env` dla Z.AI GLM:**
```env
PLATFORM=glm
API_KEY=...   # z api.z.ai
MODEL=glm-4.6v   # z wÅ‚Ä…czonÄ… wizjÄ…; glm-4.7 / glm-5 = tylko tekst
AGENT_NAME=Yukine
```

**PrzykÅ‚ad `.env` dla Google Gemini:**
```env
PLATFORM=gemini
API_KEY=AIza...   # z aistudio.google.com
MODEL=gemini-2.5-flash  # lub gemini-2.5-pro dla wyÅ¼szej wydajnoÅ›ci
AGENT_NAME=Yukine
```

**PrzykÅ‚ad `.env` dla OpenRouter.ai:**
```env
PLATFORM=openai
BASE_URL=https://openrouter.ai/api/v1
API_KEY=sk-or-...   # z openrouter.ai
MODEL=mistralai/mistral-7b-instruct  # opcjonalnie: okreÅ›l model
AGENT_NAME=Yukine
```

> **Uwaga:** Aby wyÅ‚Ä…czyÄ‡ lokalne modele/NVIDIA, po prostu nie ustawiaj `BASE_URL` na lokalny punkt koÅ„cowy, jak `http://localhost:11434/v1`. UÅ¼yj dostawcÃ³w chmurowych zamiast tego.

**PrzykÅ‚ad `.env` dla narzÄ™dzia CLI:**
```env
PLATFORM=cli
MODEL=llm -m gemma3 {}        # llm CLI (https://llm.datasette.io) â€” {} = argument prompt
# MODEL=ollama run gemma3:27b  # Ollama â€” bez {}, prompt przechodzi przez stdin
```

---

## Serwery MCP

familiar-ai moÅ¼e Å‚Ä…czyÄ‡ siÄ™ z kaÅ¼dym serwerem [MCP (Model Context Protocol)](https://modelcontextprotocol.io). UmoÅ¼liwia to podÅ‚Ä…czenie zewnÄ™trznej pamiÄ™ci, dostÄ™pu do systemu plikÃ³w, wyszukiwania w sieci lub jakiegokolwiek innego narzÄ™dzia.

Skonfiguruj serwery w `~/.familiar-ai.json` (ten sam format co Claude Code):

```json
{
  "mcpServers": {
    "filesystem": {
      "type": "stdio",
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-filesystem", "/home/user"]
    },
    "memory": {
      "type": "sse",
      "url": "http://localhost:3000/sse"
    }
  }
}
```

ObsÅ‚ugiwane sÄ… dwa typy transportu:
- **`stdio`**: uruchom lokalny podproces (`command` + `args`)
- **`sse`**: poÅ‚Ä…cz siÄ™ z serwerem HTTP+SSE (`url`)

ZmieÅ„ lokalizacjÄ™ pliku konfiguracyjnego za pomocÄ… `MCP_CONFIG=/path/to/config.json`.

---

## SprzÄ™t

familiar-ai dziaÅ‚a z dowolnym sprzÄ™tem, ktÃ³ry masz â€” lub wcale nie.

| CzÄ™Å›Ä‡ | Co robi | PrzykÅ‚ad | Wymagane? |
|-------|---------|----------|-----------|
| Kamera Wi-Fi PTZ | Oczy + szyja | Tapo C220 (~$30) | **Zalecane** |
| Kamera USB | Oczy (staÅ‚e) | Dowolna kamera UVC | **Zalecane** |
| Robot odkurzacz | Nogi | Dowolny model komplementarny Tuya | Nie |
| PC / Raspberry Pi | MÃ³zg | Cokolwiek, co uruchamia Pythona | **Tak** |

> **Kamera jest zdecydowanie zalecana.** Bez niej familiar-ai wciÄ…Å¼ moÅ¼e mÃ³wiÄ‡ â€” ale nie widzi Å›wiata, co jest caÅ‚kiem istotnym punktem.

### Minimalna konfiguracja (bez sprzÄ™tu)

Chcesz tylko sprÃ³bowaÄ‡? Potrzebujesz tylko klucza API:

```env
PLATFORM=kimi
API_KEY=sk-...
```

Uruchom `./run.sh` i zacznij rozmawiaÄ‡. Dodaj sprzÄ™t, gdy bÄ™dziesz gotowy.

### Kamera Wi-Fi PTZ (Tapo C220)

1. W aplikacji Tapo: **Ustawienia â†’ Zaawansowane â†’ Konto kamery** â€” utwÃ³rz lokalne konto (nie TP-Link)
2. ZnajdÅº adres IP kamery na liÅ›cie urzÄ…dzeÅ„ twojego routera
3. Ustaw w `.env`:
   ```env
   CAMERA_HOST=192.168.1.xxx
   CAMERA_USER=your-local-user
   CAMERA_PASS=your-local-pass
   ```

### GÅ‚os (ElevenLabs)

1. ZdobÄ…dÅº klucz API na [elevenlabs.io](https://elevenlabs.io/)
2. Ustaw w `.env`:
   ```env
   ELEVENLABS_API_KEY=sk_...
   ELEVENLABS_VOICE_ID=...   # opcjonalnie, uÅ¼ywa domyÅ›lnego gÅ‚osu, jeÅ›li pominiÄ™te
   ```

IstniejÄ… dwa miejsca docelowe odtwarzania, sterowane przez `TTS_OUTPUT`:

```env
TTS_OUTPUT=local    # GÅ‚oÅ›nik komputera (domyÅ›lnie)
TTS_OUTPUT=remote   # tylko gÅ‚oÅ›nik kamery
TTS_OUTPUT=both     # gÅ‚oÅ›nik kamery + gÅ‚oÅ›nik komputera jednoczeÅ›nie
```

#### A) GÅ‚oÅ›nik kamery (przez go2rtc)

Ustaw `TTS_OUTPUT=remote` (lub `both`). Wymaga [go2rtc](https://github.com/AlexxIT/go2rtc/releases):

1. Pobierz plik binarny z [strony wydaÅ„](https://github.com/AlexxIT/go2rtc/releases):
   - Linux/macOS: `go2rtc_linux_amd64` / `go2rtc_darwin_amd64`
   - **Windows: `go2rtc_win64.exe`**

2. UmieÅ›Ä‡ i zmieÅ„ nazwÄ™:
   ```
   # Linux / macOS
   ~/.cache/embodied-claude/go2rtc/go2rtc          # wymagana zmiana uprawnieÅ„ chmod +x

   # Windows
   %USERPROFILE%\.cache\embodied-claude\go2rtc\go2rtc.exe
   ```

3. StwÃ³rz `go2rtc.yaml` w tym samym katalogu:
   ```yaml
   streams:
     tapo_cam:
       - rtsp://YOUR_CAM_USER:YOUR_CAM_PASS@YOUR_CAM_IP/stream1
   ```
   UÅ¼yj poÅ›wiadczeÅ„ lokalnego konta kamery (nie swojego konta w chmurze TP-Link).

4. familiar-ai automatycznie uruchomi go2rtc podczas startu. JeÅ›li twoja kamera obsÅ‚uguje dwukierunkowy dÅºwiÄ™k (kanaÅ‚ zwrotny), gÅ‚os bÄ™dzie odtwarzany z gÅ‚oÅ›nika kamery.

#### B) GÅ‚oÅ›nik lokalny PC

DomyÅ›lne ustawienie (`TTS_OUTPUT=local`). PrÃ³buj odtwarzaczy w kolejnoÅ›ci: **paplay** â†’ **mpv** â†’ **ffplay**. UÅ¼ywane rÃ³wnieÅ¼ jako fallback, gdy `TTS_OUTPUT=remote` i go2rtc jest niedostÄ™pny.

| OS | Instalacja |
|----|------------|
| macOS | `brew install mpv` |
| Ubuntu / Debian | `sudo apt install mpv` (lub `paplay` za pomocÄ… `pulseaudio-utils`) |
| WSL2 / WSLg | `sudo apt install pulseaudio-utils` â€” ustaw `PULSE_SERVER=unix:/mnt/wslg/PulseServer` w `.env` |
| Windows | [mpv.io/installation](https://mpv.io/installation/) â€” pobierz i dodaj do PATH, **lub** `winget install ffmpeg` |

> JeÅ›li Å¼aden odtwarzacz audio nie jest dostÄ™pny, mowa i tak zostanie wygenerowana â€” po prostu nie bÄ™dzie odtwarzana.

### WejÅ›cie gÅ‚osowe (Realtime STT)

Ustaw `REALTIME_STT=true` w `.env`, aby wÅ‚Ä…czyÄ‡ zawsze aktywne, bezprzewodowe wejÅ›cie gÅ‚osowe:

```env
REALTIME_STT=true
ELEVENLABS_API_KEY=sk_...   # ten sam klucz co TTS
```

familiar-ai przesyÅ‚a dÅºwiÄ™k z mikrofonu do ElevenLabs Scribe v2 i automatycznie zapisuje transkrypcje, gdy przestajesz mÃ³wiÄ‡. Nie wymaga naciÅ›niÄ™cia przycisku. Koegzystuje z trybem push-to-talk (Ctrl+T).

---

## TUI

familiar-ai zawiera interfejs terminalowy zbudowany z [Textual](https://textual.textualize.io/):

- Przewijalna historia rozmowy z tekstem na Å¼ywo
- AutouzupeÅ‚nianie dla `/quit`, `/clear`
- Przerywanie agenta w trakcie myÅ›lenia, piszÄ…c, gdy myÅ›li
- **Dziennik rozmÃ³w** automatycznie zapisywany w `~/.cache/familiar-ai/chat.log`

Aby Å›ledziÄ‡ dziennik w innym terminalu (przydatne do kopiowania-wklejania):
```bash
tail -f ~/.cache/familiar-ai/chat.log
```

---

## Persona (ME.md)

OsobowoÅ›Ä‡ twojego towarzysza znajduje siÄ™ w `ME.md`. Ten plik jest ignorowany przez git â€” jest tylko twÃ³j.

Zobacz [`persona-template/en.md`](./persona-template/en.md) jako przykÅ‚ad lub [`persona-template/ja.md`](./persona-template/ja.md) dla japoÅ„skiej wersji.

---

## FAQ

**Q: Czy dziaÅ‚a bez GPU?**
Tak. Model embeddingowy (multilingual-e5-small) dziaÅ‚a dobrze na CPU. GPU przyspiesza, ale nie jest wymagane.

**Q: Czy mogÄ™ uÅ¼yÄ‡ innej kamery niÅ¼ Tapo?**
Dowolna kamera, ktÃ³ra obsÅ‚uguje ONVIF + RTSP, powinna dziaÅ‚aÄ‡. Tapo C220 to ta, ktÃ³rÄ… testowaliÅ›my.

**Q: Czy moje dane sÄ… wysyÅ‚ane gdziekolwiek?**
Obrazy i tekst sÄ… wysyÅ‚ane do wybranego API LLM w celu przetwarzania. Wspomnienia sÄ… przechowywane lokalnie w `~/.familiar_ai/`.

**Q: Dlaczego agent pisze `ï¼ˆ...ï¼‰` zamiast mÃ³wiÄ‡?**
Upewnij siÄ™, Å¼e `ELEVENLABS_API_KEY` jest ustawiony. Bez niego gÅ‚os jest wyÅ‚Ä…czony i agent wraca do tekstu.

## TÅ‚o techniczne

Ciekawy, jak to dziaÅ‚a? Zobacz [docs/technical.md](./docs/technical.md) dla badaÅ„ i decyzji projektowych dotyczÄ…cych familiar-ai â€” ReAct, SayCan, Reflexion, Voyager, system pragnieÅ„ i inne.

---

## WkÅ‚ad

familiar-ai to otwarty eksperyment. JeÅ›li ktÃ³reÅ› z tego rezonuje z tobÄ… â€” technicznie lub filozoficznie â€” wkÅ‚ady sÄ… bardzo mile widziane.

**Dobre miejsca na poczÄ…tek:**

| Obszar | Co jest potrzebne |
|--------|------------------|
| Nowy sprzÄ™t | Wsparcie dla wiÄ™kszej iloÅ›ci kamer (RTSP, IP Webcam), mikrofonÃ³w, aktuatorÃ³w |
| Nowe narzÄ™dzia | Wyszukiwanie w sieci, automatyzacja domowa, kalendarz, cokolwiek przez MCP |
| Nowe backendy | Dowolny LLM lub lokalny model, ktÃ³ry pasuje do interfejsu `stream_turn` |
| Szablony osobowoÅ›ci | Szablony ME.md dla rÃ³Å¼nych jÄ™zykÃ³w i osobowoÅ›ci |
| Badania | Lepsze modele pragnieÅ„, odzyskiwanie pamiÄ™ci, promptowanie teorii umysÅ‚u |
| Dokumentacja | Samouczki, przewodniki, tÅ‚umaczenia |

Zobacz [CONTRIBUTING.md](./CONTRIBUTING.md) dla zestawu dewelopera, stylu kodu i wytycznych PR.

JeÅ›li nie wiesz, od czego zaczÄ…Ä‡, [otwÃ³rz zgÅ‚oszenie](https://github.com/lifemate-ai/familiar-ai/issues) â€” chÄ™tnie wskaÅ¼Ä™ ci wÅ‚aÅ›ciwy kierunek.

---

## Licencja

[MIT](./LICENSE)
