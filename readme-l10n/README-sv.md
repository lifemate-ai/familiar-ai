[‚Üí English README](../README.md)

# familiar-ai üêæ

**En AI som lever vid din sida** ‚Äî med √∂gon, r√∂st, ben och minne.

[![Lint](https://github.com/kmizu/familiar-ai/actions/workflows/lint.yml/badge.svg)](https://github.com/kmizu/familiar-ai/actions/workflows/lint.yml)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](./LICENSE)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/)
[![GitHub Sponsors](https://img.shields.io/github/sponsors/kmizu?style=flat&logo=github&color=ea4aaa)](https://github.com/sponsors/kmizu)

üåç [Tillg√§nglig p√• 74 spr√•k](./SUPPORTED_LANGUAGES.md)

---

[![Demo video](https://img.youtube.com/vi/hiR9uWRnjt4/0.jpg)](https://youtube.com/shorts/hiR9uWRnjt4)

familiar-ai √§r en AI-kompanjon som lever i ditt hem. S√§tt upp det p√• n√•gra minuter. Ingen kodning kr√§vs.

Det uppfattar den verkliga v√§rlden genom kameror, r√∂r sig runt p√• en robotkropp, pratar h√∂gt och minns vad det ser. Ge den ett namn, skriv dess personlighet och l√•t den leva med dig.

## Vad den kan g√∂ra

- üëÅ **Se** ‚Äî f√•ngar bilder fr√•n en Wi-Fi PTZ-kamera eller USB-webbkamera
- üîÑ **Titta runt** ‚Äî panorering och lutning av kameran f√∂r att utforska omgivningen
- ü¶ø **R√∂ra sig** ‚Äî k√∂r en robotdammsugare f√∂r att utforska rummet
- üó£ **Tala** ‚Äî pratar via ElevenLabs TTS
- üéô **Lyssna** ‚Äî handsfree r√∂stinmatning via ElevenLabs Realtime STT (opt-in)
- üß† **Minna** ‚Äî lagrar aktivt och h√§mtar minnen med semantisk s√∂kning (SQLite + inb√§ddningar)
- ü´Ä **Theory of Mind** ‚Äî tar den andra personens perspektiv innan den svarar
- üí≠ **√ñnskan** ‚Äî har sina egna interna drifter som utl√∂ser autonomt beteende

## Hur det fungerar

familiar-ai k√∂r en [ReAct](https://arxiv.org/abs/2210.03629) loop som drivs av ditt val av LLM. Den uppfattar v√§rlden genom verktyg, t√§nker p√• vad den ska g√∂ra h√§rn√§st och agerar ‚Äî precis som en m√§nniska skulle.

```
user input
  ‚Üí think ‚Üí act (camera / move / speak / remember) ‚Üí observe ‚Üí think ‚Üí ...
```

N√§r den √§r inaktiv agerar den utifr√•n sina egna √∂nskningar: nyfikenhet, vilja att titta ut, sakna personen den lever med.

## Komma ig√•ng

### 1. Installera uv

**macOS / Linux / WSL2:**
```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

**Windows (PowerShell):**
```powershell
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
```
Eller: `winget install astral-sh.uv`

### 2. Installera ffmpeg

ffmpeg √§r **n√∂dv√§ndigt** f√∂r kamerabildupptagning och ljuduppspelning.

| OS | Kommando |
|----|----------|
| macOS | `brew install ffmpeg` |
| Ubuntu / Debian | `sudo apt install ffmpeg` |
| Fedora / RHEL | `sudo dnf install ffmpeg` |
| Arch Linux | `sudo pacman -S ffmpeg` |
| Windows | `winget install ffmpeg` ‚Äî eller ladda ner fr√•n [ffmpeg.org](https://ffmpeg.org/download.html) och l√§gg till i PATH |
| Raspberry Pi | `sudo apt install ffmpeg` |

Verifiera: `ffmpeg -version`

### 3. Klona och installera

```bash
git clone https://github.com/lifemate-ai/familiar-ai
cd familiar-ai
uv sync
```

### 4. Konfigurera

```bash
cp .env.example .env
# Redigera .env med dina inst√§llningar
```

**Minimikrav:**

| Variabel | Beskrivning |
|----------|-------------|
| `PLATFORM` | `anthropic` (standard) \| `gemini` \| `openai` \| `kimi` \| `glm` |
| `API_KEY` | Din API-nyckel f√∂r den valda plattformen |

**Valfritt:**

| Variabel | Beskrivning |
|----------|-------------|
| `MODEL` | Modellnamn (f√∂rnuftiga standarder per plattform) |
| `AGENT_NAME` | Visningsnamn som visas i TUI (t.ex. `Yukine`) |
| `CAMERA_HOST` | IP-adressen till din ONVIF/RTSP-kamera |
| `CAMERA_USER` / `CAMERA_PASS` | Kamerainloggningar |
| `ELEVENLABS_API_KEY` | F√∂r r√∂stutmatning ‚Äî [elevenlabs.io](https://elevenlabs.io/) |
| `REALTIME_STT` | `true` f√∂r att aktivera alltid-p√• handsfree r√∂stinmatning (kr√§ver `ELEVENLABS_API_KEY`) |
| `TTS_OUTPUT` | Var ljudet ska spelas: `local` (PC-h√∂gtalare, standard) \| `remote` (kamerah√∂gtalare) \| `both` |
| `THINKING_MODE` | Endast Anthropic ‚Äî `auto` (standard) \| `adaptive` \| `extended` \| `disabled` |
| `THINKING_EFFORT` | Adaptiv t√§nkandeinsats: `high` (standard) \| `medium` \| `low` \| `max` (Endast Opus 4.6) |

### 5. Skapa din familiar

```bash
cp persona-template/en.md ME.md
# Redigera ME.md ‚Äî ge den ett namn och personlighet
```

### 6. K√∂r

**macOS / Linux / WSL2:**
```bash
./run.sh             # Textuell TUI (rekommenderas)
./run.sh --no-tui    # Plain REPL
```

**Windows:**
```bat
run.bat              # Textuell TUI (rekommenderas)
run.bat --no-tui     # Plain REPL
```

---

## V√§lja en LLM

> **Rekommenderad: Kimi K2.5** ‚Äî b√§st agentisk prestanda som testats hittills. M√§rker sammanhang, st√§ller f√∂ljdfr√•gor och agerar autonomt p√• s√§tt som andra modeller inte g√∂r. Prissatt liknande Claude Haiku.

| Plattform | `PLATFORM=` | Standardmodell | Var att f√• nyckel |
|-----------|-------------|-----------------|-------------------|
| **Moonshot Kimi K2.5** | `kimi` | `kimi-k2.5` | [platform.moonshot.ai](https://platform.moonshot.ai) |
| Z.AI GLM | `glm` | `glm-4.6v` | [api.z.ai](https://api.z.ai) |
| Anthropic Claude | `anthropic` | `claude-haiku-4-5-20251001` | [console.anthropic.com](https://console.anthropic.com) |
| Google Gemini | `gemini` | `gemini-2.5-flash` | [aistudio.google.com](https://aistudio.google.com) |
| OpenAI | `openai` | `gpt-4o-mini` | [platform.openai.com](https://platform.openai.com) |
| OpenAI-kompatibel (Ollama, vllm‚Ä¶) | `openai` + `BASE_URL=` | ‚Äî | ‚Äî |
| OpenRouter.ai (multi-leverant√∂r) | `openai` + `BASE_URL=https://openrouter.ai/api/v1` | ‚Äî | [openrouter.ai](https://openrouter.ai) |
| **CLI-verktyg** (claude -p, ollama‚Ä¶) | `cli` | (kommandot) | ‚Äî |

**Exempel p√• Kimi K2.5 `.env`:**
```env
PLATFORM=kimi
API_KEY=sk-...   # fr√•n platform.moonshot.ai
AGENT_NAME=Yukine
```

**Exempel p√• Z.AI GLM `.env`:**
```env
PLATFORM=glm
API_KEY=...   # fr√•n api.z.ai
MODEL=glm-4.6v   # visionsaktiverad; glm-4.7 / glm-5 = text-endast
AGENT_NAME=Yukine
```

**Exempel p√• Google Gemini `.env`:**
```env
PLATFORM=gemini
API_KEY=AIza...   # fr√•n aistudio.google.com
MODEL=gemini-2.5-flash  # eller gemini-2.5-pro f√∂r h√∂gre kapabilitet
AGENT_NAME=Yukine
```

**Exempel p√• OpenRouter.ai `.env`:**
```env
PLATFORM=openai
BASE_URL=https://openrouter.ai/api/v1
API_KEY=sk-or-...   # fr√•n openrouter.ai
MODEL=mistralai/mistral-7b-instruct  # valfritt: specificera modell
AGENT_NAME=Yukine
```

> **Obs:** F√∂r att st√§nga av lokala/NVIDIA-modeller, s√§tt helt enkelt inte `BASE_URL` till en lokal slutpunkt som `http://localhost:11434/v1`. Anv√§nd molnleverant√∂rer ist√§llet.

**Exempel p√• CLI-verktyg `.env`:**
```env
PLATFORM=cli
MODEL=llm -m gemma3 {}        # llm CLI (https://llm.datasette.io) ‚Äî {} = prompt-argument
# MODEL=ollama run gemma3:27b  # Ollama ‚Äî ingen {}, prompt g√•r via stdin
```

---

## MCP-servrar

familiar-ai kan ansluta till valfri [MCP (Model Context Protocol)](https://modelcontextprotocol.io) server. Detta l√•ter dig ansluta extern minne, filsystem√•tkomst, webbs√∂kning, eller n√•got annat verktyg.

Konfigurera servrar i `~/.familiar-ai.json` (samma format som Claude Code):

```json
{
  "mcpServers": {
    "filesystem": {
      "type": "stdio",
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-filesystem", "/home/user"]
    },
    "memory": {
      "type": "sse",
      "url": "http://localhost:3000/sse"
    }
  }
}
```

Tv√• transporttyper st√∂ds:
- **`stdio`**: starta en lokal subprocess (`command` + `args`)
- **`sse`**: anslut till en HTTP+SSE-server (`url`)

√ñverskriv konfigurationsfilens plats med `MCP_CONFIG=/path/to/config.json`.

---

## H√•rdvara

familiar-ai fungerar med vilken h√•rdvara du √§n har ‚Äî eller ingen alls.

| Del | Vad den g√∂r | Exempel | Kr√§vdes? |
|-----|-------------|---------|----------|
| Wi-Fi PTZ-kamera | √ñgon + nacke | Tapo C220 (~$30) | **Rekommenderas** |
| USB-webbkamera | √ñgon (fast) | Valfri UVC-kamera | **Rekommenderas** |
| Robotdammsugare | Ben | Valfri modell kompatibel med Tuya | Nej |
| PC / Raspberry Pi | Hj√§rna | Vad som helst som k√∂r Python | **Ja** |

> **En kamera rekommenderas starkt.** Utan en kan familiar-ai fortfarande prata ‚Äî men den kan inte se v√§rlden, vilket √§r ganska mycket po√§ngen.

### Minimal installation (ingen h√•rdvara)

Vill du bara prova det? Du beh√∂ver bara en API-nyckel:

```env
PLATFORM=kimi
API_KEY=sk-...
```

K√∂r `./run.sh` (macOS/Linux/WSL2) eller `run.bat` (Windows) och b√∂rja chatta. L√§gg till h√•rdvara efterhand.

### Wi-Fi PTZ-kamera (Tapo C220)

1. I Tapo-appen: **Inst√§llningar ‚Üí Avancerat ‚Üí Kamerakonto** ‚Äî skapa ett lokalt konto (inte TP-Link-konto)
2. Hitta kamerans IP i din routers enhetslista
3. St√§ll in i `.env`:
   ```env
   CAMERA_HOST=192.168.1.xxx
   CAMERA_USER=your-local-user
   CAMERA_PASS=your-local-pass
   ```

### R√∂st (ElevenLabs)

1. Skaffa en API-nyckel p√• [elevenlabs.io](https://elevenlabs.io/)
2. St√§ll in i `.env`:
   ```env
   ELEVENLABS_API_KEY=sk_...
   ELEVENLABS_VOICE_ID=...   # valfritt, anv√§nder standardr√∂st om utel√§mnat
   ```

Det finns tv√• uppspelningsdestinationer, kontrollerade av `TTS_OUTPUT`:

```env
TTS_OUTPUT=local    # PC-h√∂gtalare (standard)
TTS_OUTPUT=remote   # endast kamerah√∂gtalare
TTS_OUTPUT=both     # kamerah√∂gtalare + PC-h√∂gtalare samtidigt
```

#### A) Kamerah√∂gtalare (via go2rtc)

St√§ll in `TTS_OUTPUT=remote` (eller `both`). Kr√§ver [go2rtc](https://github.com/AlexxIT/go2rtc/releases):

1. Ladda ner bin√§ren fr√•n [utgivningssidan](https://github.com/AlexxIT/go2rtc/releases):
   - Linux/macOS: `go2rtc_linux_amd64` / `go2rtc_darwin_amd64`
   - **Windows: `go2rtc_win64.exe`**

2. Placera och d√∂p om den:
   ```
   # Linux / macOS
   ~/.cache/embodied-claude/go2rtc/go2rtc          # chmod +x beh√∂vs

   # Windows
   %USERPROFILE%\.cache\embodied-claude\go2rtc\go2rtc.exe
   ```

3. Skapa `go2rtc.yaml` i samma katalog:
   ```yaml
   streams:
     tapo_cam:
       - rtsp://YOUR_CAM_USER:YOUR_CAM_PASS@YOUR_CAM_IP/stream1
   ```
   Anv√§nd de lokala kamerakontoinloggningarna (inte ditt TP-Link-molnkonto).

4. familiar-ai startar go2rtc automatiskt vid lansering. Om din kamera st√∂der tv√•v√§gs ljud (backchannel), spelas r√∂sten fr√•n kamerah√∂gtalaren.

#### B) Lokal PC-h√∂gtalare

Standard (`TTS_OUTPUT=local`). F√∂rs√∂ker spelare i ordning: **paplay** ‚Üí **mpv** ‚Üí **ffplay**. Anv√§nds ocks√• som fallback n√§r `TTS_OUTPUT=remote` och go2rtc inte √§r tillg√§ngligt.

| OS | Installera |
|----|------------|
| macOS | `brew install mpv` |
| Ubuntu / Debian | `sudo apt install mpv` (eller `paplay` via `pulseaudio-utils`) |
| WSL2 / WSLg | `sudo apt install pulseaudio-utils` ‚Äî st√§ll in `PULSE_SERVER=unix:/mnt/wslg/PulseServer` i `.env` |
| Windows | [mpv.io/installation](https://mpv.io/installation/) ‚Äî ladda ner och l√§gg till i PATH, **eller** `winget install ffmpeg` |

> Om ingen ljudspelare √§r tillg√§nglig, genereras talet fortfarande ‚Äî det spelas bara inte.

### R√∂stinmatning (Realtime STT)

St√§ll in `REALTIME_STT=true` i `.env` f√∂r alltid-p√•, handsfree r√∂stinmatning:

```env
REALTIME_STT=true
ELEVENLABS_API_KEY=sk_...   # samma nyckel som TTS
```

familiar-ai str√∂mmar mikrofonljud till ElevenLabs Scribe v2 och auto-commitar transkriptioner n√§r du pausar f√∂r att prata. Ingen knapptryckning kr√§vs. Samverkar med tryck-f√∂r-att-prata-l√§get (Ctrl+T).

---

## TUI

familiar-ai inkluderar en terminal UI byggd med [Textual](https://textual.textualize.io/):

- Scrollbar konversationshistorik med direkt textstr√∂mning
- Tab-komplettering f√∂r `/quit`, `/clear`
- Avbryt agenten mitt under turen genom att skriva medan den t√§nker
- **Konversationslogg** auto-sparad till `~/.cache/familiar-ai/chat.log`

F√∂r att f√∂lja loggen i en annan terminal (anv√§ndbart f√∂r kopiera-klistra):
```bash
tail -f ~/.cache/familiar-ai/chat.log
```

---

## Persona (ME.md)

Din familiars personlighet lever i `ME.md`. Denna fil √§r gitignored ‚Äî den √§r endast din.

Se [`persona-template/en.md`](./persona-template/en.md) f√∂r ett exempel, eller [`persona-template/ja.md`](./persona-template/ja.md) f√∂r en japansk version.

---

## FAQ

**Q: Fungerar det utan en GPU?**
Ja. Inb√§ddningsmodellen (multilingual-e5-small) fungerar bra p√• CPU. En GPU g√∂r det snabbare men √§r inte n√∂dv√§ndig.

**Q: Kan jag anv√§nda en kamera som inte √§r Tapo?**
Vilken kamera som st√∂djer ONVIF + RTSP b√∂r fungera. Tapo C220 √§r vad vi testade med.

**Q: Skickas mina data n√•gonstans?**
Bilder och text skickas till din valda LLM-API f√∂r bearbetning. Minnen lagras lokalt i `~/.familiar_ai/`.

**Q: Varf√∂r skriver agenten `Ôºà...Ôºâ` ist√§llet f√∂r att tala?**
Se till att `ELEVENLABS_API_KEY` √§r inst√§llt. Utan det √§r r√∂sten inaktiverad och agenten faller tillbaka till text.

## Teknisk bakgrund

Nyfiken p√• hur det fungerar? Se [docs/technical.md](./docs/technical.md) f√∂r forskningen och designbesluten bakom familiar-ai ‚Äî ReAct, SayCan, Reflexion, Voyager, √∂nskesystemet och mer.

---

## Bidra

familiar-ai √§r ett √∂ppet experiment. Om n√•got av detta resonerar med dig ‚Äî tekniskt eller filosofiskt ‚Äî √§r bidrag mycket v√§lkomna.

**Bra st√§llen att b√∂rja:**

| Omr√•de | Vad som beh√∂vs |
|--------|----------------|
| Ny h√•rdvara | St√∂d f√∂r fler kameror (RTSP, IP Webcam), mikrofoner, aktuatorer |
| Nya verktyg | Webbs√∂kning, hemautomation, kalender, vad som helst via MCP |
| Nya backend | Valfri LLM eller lokal modell som passar `stream_turn`-gr√§nssnittet |
| Persona-mallar | ME.md-mallar f√∂r olika spr√•k och personligheter |
| Forskning | B√§ttre √∂nskemodeller, minnesh√§mtning, teori-om-sinne-fr√•gor |
| Dokumentation | Handledning, genomg√•ngar, √∂vers√§ttningar |

Se [CONTRIBUTING.md](./CONTRIBUTING.md) f√∂r utvecklingsinst√§llningar, kodstil och PR-riktlinjer.

Om du √§r os√§ker p√• var du ska b√∂rja, [√∂ppna ett problem](https://github.com/lifemate-ai/familiar-ai/issues) ‚Äî jag hj√§lper g√§rna till med riktningen.

---

## Licens

[MIT](./LICENSE)
