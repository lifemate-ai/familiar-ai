# familiar-ai üêæ

**Un AI que vive a teu lado** ‚Äî con ollos, voz, patas e memoria.

[![Lint](https://github.com/kmizu/familiar-ai/actions/workflows/lint.yml/badge.svg)](https://github.com/kmizu/familiar-ai/actions/workflows/lint.yml)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](./LICENSE)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/)
[![GitHub Sponsors](https://img.shields.io/github/sponsors/kmizu?style=flat&logo=github&color=ea4aaa)](https://github.com/sponsors/kmizu)

[‚Üí English README](../README.md)

---

[![Demo video](https://img.youtube.com/vi/hiR9uWRnjt4/0.jpg)](https://youtube.com/shorts/hiR9uWRnjt4)

familiar-ai √© un compa√±ero AI que vive na t√∫a casa. Configureo en minutos. Non se require codificaci√≥n.

Percibe o mundo real a trav√©s de c√°maras, m√≥vese cun corpo rob√≥tico, fala en voz alta e lembra o que ve. D√°le un nome, escribe a s√∫a personalidade e d√©ixao vivir contigo.

## O que pode facer

- üëÅ **Ver** ‚Äî captura imaxes dunha c√°mara PTZ Wi-Fi ou webcam USB
- üîÑ **Mirar ao redor** ‚Äî move e inclina a c√°mara para explorar os seus arredores
- ü¶ø **Moverse** ‚Äî conduce un aspirador rob√≥tico para percorrer a habitaci√≥n
- üó£ **Falar** ‚Äî fala a trav√©s de ElevenLabs TTS
- üéô **Escoitar** ‚Äî entrada de voz sen mans a trav√©s de ElevenLabs Realtime STT (opcional)
- üß† **Lembrar** ‚Äî almacena e recupera activamente recordos con busca sem√°ntica (SQLite + embeddings)
- ü´Ä **Teor√≠a da mente** ‚Äî toma a perspectiva da outra persoa antes de responder
- üí≠ **Desexo** ‚Äî ten os seus propios impulsos internos que desencadean comportamento aut√≥nomo

## Como funciona

familiar-ai executa un loop [ReAct](https://arxiv.org/abs/2210.03629) impulsado pola t√∫a elecci√≥n de LLM. Percibe o mundo a trav√©s de ferramentas, pensa sobre o que facer a continuaci√≥n e act√∫a ‚Äî igual que far√≠a unha persoa.

```
user input
  ‚Üí think ‚Üí act (camera / move / speak / remember) ‚Üí observe ‚Üí think ‚Üí ...
```

Cando est√° inactiva, act√∫a segundo os seus propios desexos: curiosidade, querer mirar f√≥ra, echando de menos √° persoa coa que vive.

## Comezando

### 1. Instalar uv

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

### 2. Instalar ffmpeg

ffmpeg √© **requirido** para a captura de imaxes da c√°mara e a reproduci√≥n de audio.

| SO | Comando |
|----|---------|
| macOS | `brew install ffmpeg` |
| Ubuntu / Debian | `sudo apt install ffmpeg` |
| Fedora / RHEL | `sudo dnf install ffmpeg` |
| Arch Linux | `sudo pacman -S ffmpeg` |
| Windows | `winget install ffmpeg` ‚Äî ou descarga de [ffmpeg.org](https://ffmpeg.org/download.html) e engade √° PATH |
| Raspberry Pi | `sudo apt install ffmpeg` |

Verifica: `ffmpeg -version`

### 3. Clonar e instalar

```bash
git clone https://github.com/lifemate-ai/familiar-ai
cd familiar-ai
uv sync
```

### 4. Configurar

```bash
cp .env.example .env
# Edita .env coas t√∫as configuraci√≥ns
```

**M√≠nimo requerido:**

| Variable | Descrici√≥n |
|----------|-------------|
| `PLATFORM` | `anthropic` (por defecto) \| `gemini` \| `openai` \| `kimi` \| `glm` |
| `API_KEY` | A t√∫a clave API para a plataforma elixida |

**Opcional:**

| Variable | Descrici√≥n |
|----------|-------------|
| `MODEL` | Nome do modelo (valores por defecto sensatos por plataforma) |
| `AGENT_NAME` | Nome a mostrar na TUI (exemplo: `Yukine`) |
| `CAMERA_HOST` | Direcci√≥n IP da t√∫a c√°mara ONVIF/RTSP |
| `CAMERA_USER` / `CAMERA_PASS` | Credenciais da c√°mara |
| `ELEVENLABS_API_KEY` | Para a sa√≠da de voz ‚Äî [elevenlabs.io](https://elevenlabs.io/) |
| `REALTIME_STT` | `true` para activar a entrada de voz sempre activa sen mans (requere `ELEVENLABS_API_KEY`) |
| `TTS_OUTPUT` | Onde reproducir audio: `local` (altavoceiro do PC, por defecto) \| `remote` (altavoceiro da c√°mara) \| `both` |
| `THINKING_MODE` | S√≥ para Anthropomic ‚Äî `auto` (por defecto) \| `adaptive` \| `extended` \| `disabled` |
| `THINKING_EFFORT` | Esforzo de pensamento adaptativo: `high` (por defecto) \| `medium` \| `low` \| `max` (s√≥ Opus 4.6) |

### 5. Crea o teu familiar

```bash
cp persona-template/en.md ME.md
# Edita ME.md ‚Äî d√°slle un nome e personalidade
```

### 6. Executar

```bash
./run.sh             # TUI textual (recomendado)
./run.sh --no-tui    # REPL simple
```

---

## Elixindo un LLM

> **Recomendado: Kimi K2.5** ‚Äî o mellor rendemento agentic que probamos at√© agora. Nota o contexto, fai preguntas de seguimento e act√∫a de forma aut√≥noma de maneiras que outros modelos non fan. Prezo similar a Claude Haiku.

| Plataforma | `PLATFORM=` | Modelo por defecto | Onde conseguir a clave |
|------------|------------|-------------------|----------------------|
| **Moonshot Kimi K2.5** | `kimi` | `kimi-k2.5` | [platform.moonshot.ai](https://platform.moonshot.ai) |
| Z.AI GLM | `glm` | `glm-4.6v` | [api.z.ai](https://api.z.ai) |
| Anthropic Claude | `anthropic` | `claude-haiku-4-5-20251001` | [console.anthropic.com](https://console.anthropic.com) |
| Google Gemini | `gemini` | `gemini-2.5-flash` | [aistudio.google.com](https://aistudio.google.com) |
| OpenAI | `openai` | `gpt-4o-mini` | [platform.openai.com](https://platform.openai.com) |
| Compatible con OpenAI (Ollama, vllm‚Ä¶) | `openai` + `BASE_URL=` | ‚Äî | ‚Äî |
| OpenRouter.ai (multi-provedor) | `openai` + `BASE_URL=https://openrouter.ai/api/v1` | ‚Äî | [openrouter.ai](https://openrouter.ai) |
| **Ferramenta CLI** (claude -p, ollama‚Ä¶) | `cli` | (o comando) | ‚Äî |

**Exemplo de `.env` para Kimi K2.5:**
```env
PLATFORM=kimi
API_KEY=sk-...   # de platform.moonshot.ai
AGENT_NAME=Yukine
```

**Exemplo de `.env` para Z.AI GLM:**
```env
PLATFORM=glm
API_KEY=...   # de api.z.ai
MODEL=glm-4.6v   # habilitado para visi√≥n; glm-4.7 / glm-5 = s√≥ texto
AGENT_NAME=Yukine
```

**Exemplo de `.env` para Google Gemini:**
```env
PLATFORM=gemini
API_KEY=AIza...   # de aistudio.google.com
MODEL=gemini-2.5-flash  # ou gemini-2.5-pro para maior capacidade
AGENT_NAME=Yukine
```

**Exemplo de `.env` para OpenRouter.ai:**
```env
PLATFORM=openai
BASE_URL=https://openrouter.ai/api/v1
API_KEY=sk-or-...   # de openrouter.ai
MODEL=mistralai/mistral-7b-instruct  # opcional: especificar modelo
AGENT_NAME=Yukine
```

> **Nota:** Para desactivar modelos locais/NVIDIA, simplemente non establezas `BASE_URL` a un punto de extensi√≥n local como `http://localhost:11434/v1`. Usa provedores na nube en vez diso.

**Exemplo de `.env` para ferramenta CLI:**
```env
PLATFORM=cli
MODEL=llm -m gemma3 {}        # llm CLI (https://llm.datasette.io) ‚Äî {} = prompt arg
# MODEL=ollama run gemma3:27b  # Ollama ‚Äî sen {}, o prompt vai por stdin
```

---

## Servidores MCP

familiar-ai pode conectarse a calquera servidor [MCP (Model Context Protocol)](https://modelcontextprotocol.io). Isto perm√≠telle conectar memoria externa, acceso ao sistema de arquivos, b√∫squeda na web, ou calquera outra ferramenta.

Configura os servidores en `~/.familiar-ai.json` (mesmo formato que Claude Code):

```json
{
  "mcpServers": {
    "filesystem": {
      "type": "stdio",
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-filesystem", "/home/user"]
    },
    "memory": {
      "type": "sse",
      "url": "http://localhost:3000/sse"
    }
  }
}
```

D√∫as tipolox√≠as de transporte est√°n soportadas:
- **`stdio`**: lanzar un subprocesso local (`command` + `args`)
- **`sse`**: conectarse a un servidor HTTP+SSE (`url`)

Substit√∫e a localizaci√≥n do arquivo de configuraci√≥n con `MCP_CONFIG=/cami√±o/a/config.json`.

---

## Hardware

familiar-ai funciona co que queiras ‚Äî ou sen hardware algum.

| Parte | Que fai | Exemplo | Requerido? |
|-------|---------|---------|------------|
| C√°mara PTZ Wi-Fi | Ollos + pescozo | Tapo C220 (~$30) | **Recomendado** |
| Webcam USB | Ollos (fixo) | Calquera c√°mara UVC | **Recomendado** |
| Aspirador rob√≥tico | Pata | Calquera modelo compatible con Tuya | Non |
| PC / Raspberry Pi | Cerebro | Calquera cousa que execute Python | **Si** |

> **Recom√©ndase encarecidamente unha c√°mara.** Sen ela, familiar-ai pode seguir a falar ‚Äî pero non pode ver o mundo, que √© un pouco a toda a cuesti√≥n.

### Configuraci√≥n m√≠nima (sen hardware)

S√≥ queres probar? S√≥ necesitas unha chave API:

```env
PLATFORM=kimi
API_KEY=sk-...
```

Executa `./run.sh` e comeza a charlar. Engade hardware conforme avanzas.

### C√°mara PTZ Wi-Fi (Tapo C220)

1. Na aplicaci√≥n Tapo: **Configuraci√≥n ‚Üí Avanzado ‚Üí Conta da c√°mara** ‚Äî crea unha conta local (non unha conta TP-Link)
2. Atopa a IP da c√°mara na lista de dispositivos do teu router
3. Configura en `.env`:
   ```env
   CAMERA_HOST=192.168.1.xxx
   CAMERA_USER=your-local-user
   CAMERA_PASS=your-local-pass
   ```

### Voz (ElevenLabs)

1. Obt√©n unha clave API en [elevenlabs.io](https://elevenlabs.io/)
2. Configura en `.env`:
   ```env
   ELEVENLABS_API_KEY=sk_...
   ELEVENLABS_VOICE_ID=...   # opcional, usa a voz por defecto se se omite
   ```

Hai dous destinos de reproduci√≥n, controlados por `TTS_OUTPUT`:

```env
TTS_OUTPUT=local    # Altavoz do PC (por defecto)
TTS_OUTPUT=remote   # s√≥ altavoz da c√°mara
TTS_OUTPUT=both     # altavoz da c√°mara + altavoz do PC simultaneamente
```

#### A) Altavoz da c√°mara (a trav√©s de go2rtc)

Establece `TTS_OUTPUT=remote` (ou `both`). Require [go2rtc](https://github.com/AlexxIT/go2rtc/releases):

1. Descarga o binario da [p√°xina de lanzamentos](https://github.com/AlexxIT/go2rtc/releases):
   - Linux/macOS: `go2rtc_linux_amd64` / `go2rtc_darwin_amd64`
   - **Windows: `go2rtc_win64.exe`**

2. Col√≥cao e ren√≥mbrao:
   ```
   # Linux / macOS
   ~/.cache/embodied-claude/go2rtc/go2rtc          # chmod +x requerido

   # Windows
   %USERPROFILE%\.cache\embodied-claude\go2rtc\go2rtc.exe
   ```

3. Crea `go2rtc.yaml` no mesmo directorio:
   ```yaml
   streams:
     tapo_cam:
       - rtsp://YOUR_CAM_USER:YOUR_CAM_PASS@YOUR_CAM_IP/stream1
   ```
   Usa as credenciais da conta local da c√°mara (non a t√∫a conta en nube de TP-Link).

4. familiar-ai inicia go2rtc autom√°ticamente ao lanzarse. Se a t√∫a c√°mara admite audio bidireccional (canle de retroceso), a voz reproduce a partir do altavoz da c√°mara.

#### B) Altavoz local do PC

O por defecto (`TTS_OUTPUT=local`). Intenta reprodutores en orde: **paplay** ‚Üí **mpv** ‚Üí **ffplay**. Tam√©n se usa como alternativa cando `TTS_OUTPUT=remote` e go2rtc non est√° dispo√±ible.

| SO | Instalar |
|----|---------|
| macOS | `brew install mpv` |
| Ubuntu / Debian | `sudo apt install mpv` (ou `paplay` a trav√©s de `pulseaudio-utils`) |
| WSL2 / WSLg | `sudo apt install pulseaudio-utils` ‚Äî configurar `PULSE_SERVER=unix:/mnt/wslg/PulseServer` en `.env` |
| Windows | [mpv.io/installation](https://mpv.io/installation/) ‚Äî descarga e engade √° PATH, **ou** `winget install ffmpeg` |

> Se non est√° dispo√±ible ning√∫n reprodutor de audio, a voz segue xer√°ndose ‚Äî simplemente non se reproducir√°.

### Entrada de voz (Realtime STT)

Establece `REALTIME_STT=true` en `.env` para entrada de voz sempre activa e sen mans:

```env
REALTIME_STT=true
ELEVENLABS_API_KEY=sk_...   # mesma clave que TTS
```

familiar-ai transmite audio do micr√≥fono a ElevenLabs Scribe v2 e auto-comp√≥n transcrici√≥ns cando det√©s a t√∫a fala. Non se require pulsar bot√≥n. Coexiste co modo de presi√≥n para falar (Ctrl+T).

---

## TUI

familiar-ai incl√∫e unha UI de terminal constru√≠da con [Textual](https://textual.textualize.io/):

- Historial de conversaci√≥n desprazable con texto en directo
- Completado por tabulaci√≥n para `/quit`, `/clear`
- Interrompe ao axente no medio dunha volta escribindo mentres est√° pensando
- **Diario de conversaci√≥n** auto-gardado en `~/.cache/familiar-ai/chat.log`

Para seguir o diario noutro terminal (√∫til para copiar-pegar):
```bash
tail -f ~/.cache/familiar-ai/chat.log
```

---

## Persona (ME.md)

A personalidade do teu familiar vive en `ME.md`. Este arquivo est√° ignorado por git ‚Äî √© s√≥ teu.

Consulta [`persona-template/en.md`](./persona-template/en.md) para un exemplo, ou [`persona-template/ja.md`](./persona-template/ja.md) para unha versi√≥n en xapon√©s.

---

## FAQ

**P: Funciona sen GPU?**
Si. O modelo de embedding (multilingual-e5-small) funciona ben na CPU. Unha GPU faino m√°is r√°pido pero non √© necesaria.

**P: Podo usar unha c√°mara que non sexa Tapo?**
Calquera c√°mara que soporte ONVIF + RTSP deber√≠a funcionar. Probandose cunha Tapo C220.

**P: Os meus datos env√≠anse a alg√∫n sitio?**
Imaxes e texto env√≠anse √° API do LLM elixido para procesamento. Os recordos g√°rdanse localmente en `~/.familiar_ai/`.

**P: Por que o axente escribe `Ôºà...Ôºâ` en vez de falar?**
Aseg√∫rate de que `ELEVENLABS_API_KEY` est√° configurado. Sen el, a voz est√° desactivada e o axente volve ao texto.

## Antecedentes t√©cnicos

Tes curiosidade sobre como funciona? Consulta [docs/technical.md](./docs/technical.md) para as decisi√≥ns de investigaci√≥n e dese√±o detr√°s de familiar-ai ‚Äî ReAct, SayCan, Reflexion, Voyager, o sistema de desexo, e m√°is.

---

## Contribu√≠ndo

familiar-ai √© un experimento aberto. Se algo diso resoa contigo ‚Äî t√©cnica ou filos√≥ficamente ‚Äî as contribuci√≥ns son moi benvidas.

**Bons lugares para comezar:**

| √Årea | Que se necesita |
|------|-----------------|
| Novo hardware | Soporte para m√°is c√°maras (RTSP, IP Webcam), micr√≥fonos, actuadores |
| Novas ferramentas | B√∫squeda web, automatizaci√≥n do fogar, calendario, calquera cousa a trav√©s de MCP |
| Novos backends | Calquera LLM ou modelo local que se ajuste √° interface `stream_turn` |
| Plantillas de persona | Plantillas ME.md para diferentes linguas e personalidades |
| Investigaci√≥n | Mellores modelos de desexo, recuperaci√≥n de memoria, est√≠mulos de teor√≠a da mente |
| Documentaci√≥n | Tutoriais, gu√≠as, traduci√≥ns |

Consulta [CONTRIBUTING.md](./CONTRIBUTING.md) para a configuraci√≥n do dev, estilo de c√≥digo, e directrices de PR.

Se non est√°s seguro por onde empezar, [abre un problema](https://github.com/lifemate-ai/familiar-ai/issues) ‚Äî estou feliz de indicarte a direcci√≥n correcta.

---

## Licenza

[MIT](./LICENSE)
