# familiar-ai ğŸ¾

**Sztuczna inteligencja, ktÃ³ra Å¼yje obok ciebie** â€” z oczami, gÅ‚osem, nogami i pamiÄ™ciÄ….

[![Lint](https://github.com/kmizu/familiar-ai/actions/workflows/lint.yml/badge.svg)](https://github.com/kmizu/familiar-ai/actions/workflows/lint.yml)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](./LICENSE)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/)
[![GitHub Sponsors](https://img.shields.io/github/sponsors/kmizu?style=flat&logo=github&color=ea4aaa)](https://github.com/sponsors/kmizu)

ğŸŒ [DostÄ™pne w 74 jÄ™zykach](./SUPPORTED_LANGUAGES.md)

---

[![Demo video](https://img.youtube.com/vi/hiR9uWRnjt4/0.jpg)](https://youtube.com/shorts/hiR9uWRnjt4)

familiar-ai to towarzysz AI, ktÃ³ry Å¼yje w twoim domu.  
Skonfiguruj go w kilka minut. Nie wymaga kodowania.

Postrzega prawdziwy Å›wiat przez kamery, porusza siÄ™ na ciele robota, mÃ³wi na gÅ‚os i pamiÄ™ta, co widzi. Nadaj mu imiÄ™, napisz jego osobowoÅ›Ä‡ i pozwÃ³l mu Å¼yÄ‡ z tobÄ….

## Co potrafi

- ğŸ‘ **WidzieÄ‡** â€” rejestruje obrazy z kamery PTZ Wi-Fi lub kamery USB
- ğŸ”„ **RozglÄ…daÄ‡ siÄ™** â€” przesuwa i przechyla kamerÄ™, aby zbadaÄ‡ otoczenie
- ğŸ¦¿ **PoruszaÄ‡ siÄ™** â€” prowadzi robota-odkurzacza po pomieszczeniu
- ğŸ—£ **MÃ³wiÄ‡** â€” rozmawia za pomocÄ… ElevenLabs TTS
- ğŸ™ **SÅ‚uchaÄ‡** â€” bezprzewodowy input gÅ‚osowy za pomocÄ… ElevenLabs Realtime STT (opcja)
- ğŸ§  **PamiÄ™taÄ‡** â€” aktywnie przechowuje i przywoÅ‚uje wspomnienia z semantycznym wyszukiwaniem (SQLite + osadzenia)
- ğŸ«€ **Teoria umysÅ‚u** â€” przyjmuje perspektywÄ™ drugiej osoby przed udzieleniem odpowiedzi
- ğŸ’­ **Pragnienie** â€” ma swoje wÅ‚asne wewnÄ™trzne napiÄ™cia, ktÃ³re wyzwalajÄ… autonomiczne zachowanie

## Jak to dziaÅ‚a

familiar-ai uruchamia pÄ™tlÄ™ [ReAct](https://arxiv.org/abs/2210.03629) napÄ™dzanÄ… wybranÄ… przez ciebie LLM. Postrzega Å›wiat przez narzÄ™dzia, myÅ›li, co zrobiÄ‡ nastÄ™pnego, i dziaÅ‚a â€” tak jak robi to czÅ‚owiek.

```
user input
  â†’ think â†’ act (camera / move / speak / remember) â†’ observe â†’ think â†’ ...
```

Gdy jest bezczynny, dziaÅ‚a na swoich wÅ‚asnych pragnieniach: ciekawoÅ›ci, chÄ™ci spojrzenia na zewnÄ…trz, tÄ™sknoty za osobÄ…, z ktÃ³rÄ… mieszka.

## Jak zaczÄ…Ä‡

### 1. Zainstaluj uv

**macOS / Linux / WSL2:**
```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

**Windows (PowerShell):**
```powershell
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
```
Lub: `winget install astral-sh.uv`

### 2. Zainstaluj ffmpeg

ffmpeg jest **wymagany** do przechwytywania obrazÃ³w z kamery i odtwarzania dÅºwiÄ™ku.

| OS | Komenda |
|----|---------|
| macOS | `brew install ffmpeg` |
| Ubuntu / Debian | `sudo apt install ffmpeg` |
| Fedora / RHEL | `sudo dnf install ffmpeg` |
| Arch Linux | `sudo pacman -S ffmpeg` |
| Windows | `winget install ffmpeg` â€” lub pobierz z [ffmpeg.org](https://ffmpeg.org/download.html) i dodaj do PATH |
| Raspberry Pi | `sudo apt install ffmpeg` |

Zweryfikuj: `ffmpeg -version`

### 3. Sklonuj i zainstaluj

```bash
git clone https://github.com/lifemate-ai/familiar-ai
cd familiar-ai
uv sync
```

### 4. Skonfiguruj

```bash
cp .env.example .env
# Edytuj .env z wÅ‚asnymi ustawieniami
```

**Minimalne wymagane:**

| Zmienna | Opis |
|----------|-------------|
| `PLATFORM` | `anthropic` (domyÅ›lnie) \| `gemini` \| `openai` \| `kimi` \| `glm` |
| `API_KEY` | TwÃ³j klucz API dla wybranej platformy |

**Opcjonalne:**

| Zmienna | Opis |
|----------|-------------|
| `MODEL` | Nazwa modelu (sensowne domyÅ›lne dla kaÅ¼dej platformy) |
| `AGENT_NAME` | Nazwa wyÅ›wietlana w TUI (np. `Yukine`) |
| `CAMERA_HOST` | Adres IP twojej kamery ONVIF/RTSP |
| `CAMERA_USER` / `CAMERA_PASS` | PoÅ›wiadczenia kamery |
| `ELEVENLABS_API_KEY` | Do wyjÅ›cia gÅ‚osowego â€” [elevenlabs.io](https://elevenlabs.io/) |
| `REALTIME_STT` | `true`, aby wÅ‚Ä…czyÄ‡ zawsze aktywny bezprzewodowy input gÅ‚osowy (wymaga `ELEVENLABS_API_KEY`) |
| `TTS_OUTPUT` | Gdzie odtwarzaÄ‡ dÅºwiÄ™k: `local` (gÅ‚oÅ›nik PC, domyÅ›lnie) \| `remote` (gÅ‚oÅ›nik kamery) \| `both` |
| `THINKING_MODE` | Tylko Anthropic â€” `auto` (domyÅ›lnie) \| `adaptive` \| `extended` \| `disabled` |
| `THINKING_EFFORT` | Adaptacyjny wysiÅ‚ek myÅ›lowy: `high` (domyÅ›lnie) \| `medium` \| `low` \| `max` (tylko Opus 4.6) |

### 5. StwÃ³rz swojego familiara

```bash
cp persona-template/en.md ME.md
# Edytuj ME.md â€” nadaj mu imiÄ™ i osobowoÅ›Ä‡
```

### 6. Uruchom

**macOS / Linux / WSL2:**
```bash
./run.sh             # Tekstowy TUI (zalecane)
./run.sh --no-tui    # Prosty REPL
```

**Windows:**
```bat
run.bat              # Tekstowy TUI (zalecane)
run.bat --no-tui     # Prosty REPL
```

---

## WybÃ³r LLM

> **Zalecane: Kimi K2.5** â€” najlepsza wydajnoÅ›Ä‡ agentowa przetestowana do tej pory. ZauwaÅ¼a kontekst, zadaje pytania uzupeÅ‚niajÄ…ce i dziaÅ‚a autonomicznie w sposÃ³b, ktÃ³rego inne modele nie potrafiÄ…. Ceny zbliÅ¼one do Claude Haiku.

| Platforma | `PLATFORM=` | DomyÅ›lny model | Gdzie zdobyÄ‡ klucz |
|----------|------------|---------------|-----------------|
| **Moonshot Kimi K2.5** | `kimi` | `kimi-k2.5` | [platform.moonshot.ai](https://platform.moonshot.ai) |
| Z.AI GLM | `glm` | `glm-4.6v` | [api.z.ai](https://api.z.ai) |
| Anthropic Claude | `anthropic` | `claude-haiku-4-5-20251001` | [console.anthropic.com](https://console.anthropic.com) |
| Google Gemini | `gemini` | `gemini-2.5-flash` | [aistudio.google.com](https://aistudio.google.com) |
| OpenAI | `openai` | `gpt-4o-mini` | [platform.openai.com](https://platform.openai.com) |
| OpenAI-kompatybilny (Ollama, vllmâ€¦) | `openai` + `BASE_URL=` | â€” | â€” |
| OpenRouter.ai (multi-provider) | `openai` + `BASE_URL=https://openrouter.ai/api/v1` | â€” | [openrouter.ai](https://openrouter.ai) |
| **NarzÄ™dzie CLI** (claude -p, ollamaâ€¦) | `cli` | (komenda) | â€” |

**PrzykÅ‚ad `.env` dla Kimi K2.5:**
```env
PLATFORM=kimi
API_KEY=sk-...   # z platform.moonshot.ai
AGENT_NAME=Yukine
```

**PrzykÅ‚ad `.env` dla Z.AI GLM:**
```env
PLATFORM=glm
API_KEY=...   # z api.z.ai
MODEL=glm-4.6v   # z wÅ‚Ä…czonÄ… funkcjonalnoÅ›ciÄ… wizji; glm-4.7 / glm-5 = tylko tekst
AGENT_NAME=Yukine
```

**PrzykÅ‚ad `.env` dla Google Gemini:**
```env
PLATFORM=gemini
API_KEY=AIza...   # z aistudio.google.com
MODEL=gemini-2.5-flash  # lub gemini-2.5-pro dla wiÄ™kszych moÅ¼liwoÅ›ci
AGENT_NAME=Yukine
```

**PrzykÅ‚ad `.env` dla OpenRouter.ai:**
```env
PLATFORM=openai
BASE_URL=https://openrouter.ai/api/v1
API_KEY=sk-or-...   # z openrouter.ai
MODEL=mistralai/mistral-7b-instruct  # opcjonalnie: okreÅ›lenie modelu
AGENT_NAME=Yukine
```

> **Uwaga:** Aby wyÅ‚Ä…czyÄ‡ lokalne modele/NVIDIA, po prostu nie ustawiaj `BASE_URL` na lokalny punkt koÅ„cowy, jak `http://localhost:11434/v1`. UÅ¼yj zamiast tego dostawcÃ³w chmurowych.

**PrzykÅ‚ad `.env` dla narzÄ™dzia CLI:**
```env
PLATFORM=cli
MODEL=llm -m gemma3 {}        # llm CLI (https://llm.datasette.io) â€” {} = argument prompt
# MODEL=ollama run gemma3:27b  # Ollama â€” bez {}, prompt przechodzi przez stdin
```

---

## Serwery MCP

familiar-ai moÅ¼e Å‚Ä…czyÄ‡ siÄ™ z kaÅ¼dym serwerem [MCP (Model Context Protocol)](https://modelcontextprotocol.io). Pozwala to podÅ‚Ä…czyÄ‡ zewnÄ™trznÄ… pamiÄ™Ä‡, dostÄ™p do systemu plikÃ³w, wyszukiwanie w sieci lub kaÅ¼de inne narzÄ™dzie.

Skonfiguruj serwery w `~/.familiar-ai.json` (ten sam format co Claude Code):

```json
{
  "mcpServers": {
    "filesystem": {
      "type": "stdio",
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-filesystem", "/home/user"]
    },
    "memory": {
      "type": "sse",
      "url": "http://localhost:3000/sse"
    }
  }
}
```

ObsÅ‚ugiwane sÄ… dwa typy transportu:
- **`stdio`**: uruchom lokalny subprocess (`command` + `args`)
- **`sse`**: poÅ‚Ä…cz siÄ™ z serwerem HTTP+SSE (`url`)

MoÅ¼esz nadpisaÄ‡ lokalizacjÄ™ pliku konfiguracyjnego uÅ¼ywajÄ…c `MCP_CONFIG=/path/to/config.json`.

---

## SprzÄ™t

familiar-ai dziaÅ‚a z dowolnym sprzÄ™tem, jaki posiadasz â€” lub wcale.

| CzÄ™Å›Ä‡ | Co robi | PrzykÅ‚ad | Wymagane? |
|------|-------------|---------|-----------|
| Kamera PTZ Wi-Fi | Oczy + szyja | Tapo C220 (~30$) | **Zalecane** |
| Kamera USB | Oczy (staÅ‚e) | Dowolna kamera UVC | **Zalecane** |
| Odkurzacz robotyczny | Nogi | Dowolny model kompatybilny z Tuya | Nie |
| PC / Raspberry Pi | MÃ³zg | Cokolwiek, co uruchamia Pythona | **Tak** |

> **Kamera jest mocno zalecana.** Bez niej familiar-ai moÅ¼e nadal mÃ³wiÄ‡ â€” ale nie widzi Å›wiata, co jest doÅ›Ä‡ istotne.

### Minimalna konfiguracja (bez sprzÄ™tu)

Chcesz tylko sprÃ³bowaÄ‡? Potrzebujesz tylko klucza API:

```env
PLATFORM=kimi
API_KEY=sk-...
```

Uruchom `./run.sh` (macOS/Linux/WSL2) lub `run.bat` (Windows) i rozpocznij rozmowÄ™. Dodaj sprzÄ™t w miarÄ™ potrzeb.

### Kamera PTZ Wi-Fi (Tapo C220)

1. W aplikacji Tapo: **Ustawienia â†’ Zaawansowane â†’ Konto kamery** â€” stwÃ³rz lokalne konto (nie konto TP-Link)
2. ZnajdÅº adres IP kamery na liÅ›cie urzÄ…dzeÅ„ w routerze
3. Ustaw w `.env`:
   ```env
   CAMERA_HOST=192.168.1.xxx
   CAMERA_USER=your-local-user
   CAMERA_PASS=your-local-pass
   ```

### GÅ‚os (ElevenLabs)

1. ZdobÄ…dÅº klucz API na [elevenlabs.io](https://elevenlabs.io/)
2. Ustaw w `.env`:
   ```env
   ELEVENLABS_API_KEY=sk_...
   ELEVENLABS_VOICE_ID=...   # opcjonalnie, uÅ¼ywa domyÅ›lnego gÅ‚osu, jeÅ›li pominiÄ™te
   ```

SÄ… dwa cele odtwarzania, kontrolowane przez `TTS_OUTPUT`:

```env
TTS_OUTPUT=local    # gÅ‚oÅ›nik PC (domyÅ›lnie)
TTS_OUTPUT=remote   # tylko gÅ‚oÅ›nik kamery
TTS_OUTPUT=both     # gÅ‚oÅ›nik kamery + gÅ‚oÅ›nik PC jednoczeÅ›nie
```

#### A) GÅ‚oÅ›nik kamery (via go2rtc)

Ustaw `TTS_OUTPUT=remote` (lub `both`). Wymaga [go2rtc](https://github.com/AlexxIT/go2rtc/releases):

1. Pobierz binarkÄ™ z [strony wydaÅ„](https://github.com/AlexxIT/go2rtc/releases):
   - Linux/macOS: `go2rtc_linux_amd64` / `go2rtc_darwin_amd64`
   - **Windows: `go2rtc_win64.exe`**

2. UmieÅ›Ä‡ i zmieÅ„ nazwÄ™:
   ```
   # Linux / macOS
   ~/.cache/embodied-claude/go2rtc/go2rtc          # chmod +x wymagane

   # Windows
   %USERPROFILE%\.cache\embodied-claude\go2rtc\go2rtc.exe
   ```

3. StwÃ³rz `go2rtc.yaml` w tym samym katalogu:
   ```yaml
   streams:
     tapo_cam:
       - rtsp://YOUR_CAM_USER:YOUR_CAM_PASS@YOUR_CAM_IP/stream1
   ```
   UÅ¼yj lokalnych poÅ›wiadczeÅ„ dla kamery (nie swojego konta chmurowego TP-Link).

4. familiar-ai uruchamia go2rtc automatycznie przy uruchomieniu. JeÅ›li twoja kamera obsÅ‚uguje dwukierunkowy dÅºwiÄ™k (kanaÅ‚ zwrotny), gÅ‚os bÄ™dzie odtwarzany z gÅ‚oÅ›nika kamery.

#### B) GÅ‚oÅ›nik PC

DomyÅ›lne ustawienie (`TTS_OUTPUT=local`). PrÃ³buje odtwarzaczy w kolejnoÅ›ci: **paplay** â†’ **mpv** â†’ **ffplay**. Wykorzystywane rÃ³wnieÅ¼ jako zapasowe, gdy `TTS_OUTPUT=remote` i go2rtc jest niedostÄ™pny.

| OS | Instalacja |
|----|---------|
| macOS | `brew install mpv` |
| Ubuntu / Debian | `sudo apt install mpv` (lub `paplay` przez `pulseaudio-utils`) |
| WSL2 / WSLg | `sudo apt install pulseaudio-utils` â€” ustaw `PULSE_SERVER=unix:/mnt/wslg/PulseServer` w `.env` |
| Windows | [mpv.io/installation](https://mpv.io/installation/) â€” pobierz i dodaj do PATH, **lub** `winget install ffmpeg` |

> JeÅ›li Å¼aden odtwarzacz audio nie jest dostÄ™pny, mowa nadal jest generowana â€” po prostu nie bÄ™dzie odtwarzana.

### Input gÅ‚osowy (Realtime STT)

Ustaw `REALTIME_STT=true` w `.env`, aby mieÄ‡ zawsze aktywny, bezprzewodowy input gÅ‚osowy:

```env
REALTIME_STT=true
ELEVENLABS_API_KEY=sk_...   # ten sam klucz co dla TTS
```

familiar-ai przesyÅ‚a audio z mikrofonu do ElevenLabs Scribe v2 i automatycznie zobowiÄ…zuje do transkrypcji, gdy przestajesz mÃ³wiÄ‡. Nie jest wymagana Å¼adna reakcja na przycisk. Koegzystuje z trybem naciÅ›niÄ™cia do mÃ³wienia (Ctrl+T).

---

## TUI

familiar-ai zawiera interfejs terminala zbudowany przy uÅ¼yciu [Textual](https://textual.textualize.io/):

- Przewijalna historia rozmÃ³w z Å¼ywym przesyÅ‚aniem tekstu
- UzupeÅ‚nianie tabulatorÃ³w dla `/quit`, `/clear`
- Przerwij myÅ›lenie agenta, piszÄ…c, gdy myÅ›li
- **Dziennik rozmÃ³w** automatycznie zapisywany w `~/.cache/familiar-ai/chat.log`

Aby Å›ledziÄ‡ dziennik w innym terminalu (przydatne do kopiowania-wklejania):
```bash
tail -f ~/.cache/familiar-ai/chat.log
```

---

## OsobowoÅ›Ä‡ (ME.md)

OsobowoÅ›Ä‡ twojego familiara znajduje siÄ™ w `ME.md`. Ten plik jest ignorowany przez git â€” naleÅ¼y tylko do ciebie.

Zobacz [`persona-template/en.md`](./persona-template/en.md) jako przykÅ‚ad lub [`persona-template/ja.md`](./persona-template/ja.md) jako wersjÄ™ japoÅ„skÄ….

---

## FAQ

**Q: Czy dziaÅ‚a bez GPU?**  
Tak. Model osadzenia (multilingual-e5-small) dziaÅ‚a poprawnie na CPU. GPU przyspiesza dziaÅ‚anie, ale nie jest wymagane.

**Q: Czy mogÄ™ uÅ¼yÄ‡ kamery innej niÅ¼ Tapo?**  
KaÅ¼da kamera, ktÃ³ra obsÅ‚uguje ONVIF + RTSP, powinna dziaÅ‚aÄ‡. Tapo C220 to model, ktÃ³ry testowaliÅ›my.

**Q: Czy moje dane sÄ… wysyÅ‚ane gdziekolwiek?**  
Obrazy i tekst sÄ… wysyÅ‚ane do wybranego API LLM do przetwarzania. Wspomnienia sÄ… przechowywane lokalnie w `~/.familiar_ai/`.

**Q: Dlaczego agent pisze `ï¼ˆ...ï¼‰` zamiast mÃ³wiÄ‡?**  
Upewnij siÄ™, Å¼e `ELEVENLABS_API_KEY` jest ustawiony. Bez niego gÅ‚os jest wyÅ‚Ä…czony, a agent przechodzi na tekst.

## TÅ‚o techniczne

Ciekawe, jak to dziaÅ‚a? Zobacz [docs/technical.md](./docs/technical.md) dla badaÅ„ i decyzji projektowych stojÄ…cych za familiar-ai â€” ReAct, SayCan, Reflexion, Voyager, system pragnieÅ„ i inne.

---

## WkÅ‚ad

familiar-ai to otexperyment. JeÅ›li coÅ› z tego do ciebie przemawia â€” technicznie lub filozoficznie â€” wkÅ‚ad jest jak najbardziej mile widziany.

**Dobre miejsca do rozpoczÄ™cia:**

| Obszar | Co jest potrzebne |
|------|---------------|
| Nowy sprzÄ™t | ObsÅ‚uga wiÄ™kszej liczby kamer (RTSP, IP Webcam), mikrofonÃ³w, siÅ‚ownikÃ³w |
| Nowe narzÄ™dzia | Wyszukiwanie w sieci, automatyzacja domu, kalendarz, cokolwiek przez MCP |
| Nowe backendy | Jakikolwiek LLM lub lokalny model, ktÃ³ry pasuje do interfejsu `stream_turn` |
| Szablony osobowoÅ›ci | Szablony ME.md dla rÃ³Å¼nych jÄ™zykÃ³w i osobowoÅ›ci |
| Badania | Lepsze modele pragnieÅ„, odzyskiwanie pamiÄ™ci, stymulacja teorii umysÅ‚u |
| Dokumentacja | Samouczki, przewodniki, tÅ‚umaczenia |

Zobacz [CONTRIBUTING.md](./CONTRIBUTING.md) dla ustawieÅ„ deweloperskich, stylu kodu i wytycznych PR.

JeÅ›li nie jesteÅ› pewien, od czego zaczÄ…Ä‡, [otwÃ³rz zgÅ‚oszenie](https://github.com/lifemate-ai/familiar-ai/issues) â€” chÄ™tnie wskaÅ¼Ä™ wÅ‚aÅ›ciwy kierunek.

---

## Licencja

[MIT](./LICENSE)

[â†’ English README](../README.md)
