# familiar-ai ğŸ¾

**AI koji Å¾ivi uz vas** â€” s oÄima, glasom, nogama i memorijom.

[![Lint](https://github.com/kmizu/familiar-ai/actions/workflows/lint.yml/badge.svg)](https://github.com/kmizu/familiar-ai/actions/workflows/lint.yml)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](./LICENSE)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/)
[![GitHub Sponsors](https://img.shields.io/github/sponsors/kmizu?style=flat&logo=github&color=ea4aaa)](https://github.com/sponsors/kmizu)

ğŸŒ [Dostupno na 74 jezika](./SUPPORTED_LANGUAGES.md)

---

[![Demo video](https://img.youtube.com/vi/hiR9uWRnjt4/0.jpg)](https://youtube.com/shorts/hiR9uWRnjt4)

familiar-ai je AI pratitelj koji Å¾ivi u vaÅ¡em domu.
Postavite ga za nekoliko minuta. Nije potrebna nikakva kodiranja.

Perceptira stvarni svijet kroz kamere, kreÄ‡e se na robotskom tijelu, govori glasno i pamti Å¡to vidi. Dajte mu ime, napiÅ¡ite njegovu osobnost i neka Å¾ivi s vama.

## Å to moÅ¾e raditi

- ğŸ‘ **Vidjeti** â€” snima slike s Wi-Fi PTZ kamere ili USB web kamere
- ğŸ”„ **Gledati okolo** â€” pomiÄe i naginje kameru kako bi istraÅ¾io okolinu
- ğŸ¦¿ **Kretati se** â€” vozi robotski usisavaÄ po sobi
- ğŸ—£ **Govoriti** â€” govori putem ElevenLabs TTS-a
- ğŸ™ **SluÅ¡ati** â€” hands-free glasovni unos putem ElevenLabs Realtime STT (opcionalno)
- ğŸ§  **Pamtiti** â€” aktivno pohranjuje i prisjeÄ‡a se uspomena s semantiÄkom pretragom (SQLite + ugradnje)
- ğŸ«€ **Teorija uma** â€” uzima perspektivu druge osobe prije odgovora
- ğŸ’­ **Å½elja** â€” ima vlastite unutarnje porive koji pokreÄ‡u autonomno ponaÅ¡anje

## Kako to funkcionira

familiar-ai pokreÄ‡e [ReAct](https://arxiv.org/abs/2210.03629) petlju voÄ‘enu vaÅ¡im izborom LLM-a. Perceptira svijet kroz alate, razmiÅ¡lja o sljedeÄ‡em Å¡to treba uÄiniti i djeluje â€” baÅ¡ kao Å¡to bi to Äinila osoba.

```
user input
  â†’ think â†’ act (camera / move / speak / remember) â†’ observe â†’ think â†’ ...
```

Kada je neaktivan, djeluje prema vlastitim Å¾eljama: znatiÅ¾elja, Å¾elja da pogleda van, nedostajanje osobe s kojom Å¾ivi.

## PoÄetak rada

### 1. Instalirajte uv

**macOS / Linux / WSL2:**
```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

**Windows (PowerShell):**
```powershell
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
```
Ili: `winget install astral-sh.uv`

### 2. Instalirajte ffmpeg

ffmpeg je **potreban** za prikupljanje slika s kamere i reprodukciju audiozapisa.

| OS | Komanda |
|----|---------|
| macOS | `brew install ffmpeg` |
| Ubuntu / Debian | `sudo apt install ffmpeg` |
| Fedora / RHEL | `sudo dnf install ffmpeg` |
| Arch Linux | `sudo pacman -S ffmpeg` |
| Windows | `winget install ffmpeg` â€” ili preuzmite s [ffmpeg.org](https://ffmpeg.org/download.html) i dodajte u PATH |
| Raspberry Pi | `sudo apt install ffmpeg` |

Provjerite: `ffmpeg -version`

### 3. Klonirajte i instalirajte

```bash
git clone https://github.com/lifemate-ai/familiar-ai
cd familiar-ai
uv sync
```

### 4. Konfigurirajte

```bash
cp .env.example .env
# Uredite .env s vaÅ¡im postavkama
```

**Minimalno potrebno:**

| Varijabla | Opis |
|----------|-------------|
| `PLATFORM` | `anthropic` (zadano) \| `gemini` \| `openai` \| `kimi` \| `glm` |
| `API_KEY` | VaÅ¡ API kljuÄ za odabranu platformu |

**Opcionalno:**

| Varijabla | Opis |
|----------|-------------|
| `MODEL` | Ime modela (razumne zadatke prema platformi) |
| `AGENT_NAME` | Prikazano ime u TUI-ju (npr. `Yukine`) |
| `CAMERA_HOST` | IP adresa vaÅ¡e ONVIF/RTSP kamere |
| `CAMERA_USER` / `CAMERA_PASS` | Akreditivi kamere |
| `ELEVENLABS_API_KEY` | Za audio izlaz â€” [elevenlabs.io](https://elevenlabs.io/) |
| `REALTIME_STT` | `true` za omoguÄ‡avanje uvijek ukljuÄenog hands-free glasovnog unosa (potreban `ELEVENLABS_API_KEY`) |
| `TTS_OUTPUT` | Gdje reproducirati audio: `local` (PC zvuÄnik, zadano) \| `remote` (zvuÄnik kamere) \| `both` |
| `THINKING_MODE` | Samo za Anthropic â€” `auto` (zadano) \| `adaptive` \| `extended` \| `disabled` |
| `THINKING_EFFORT` | Adaptivni napor razmiÅ¡ljanja: `high` (zadano) \| `medium` \| `low` \| `max` (samo Opus 4.6) |

### 5. Stvorite svog familiar

```bash
cp persona-template/en.md ME.md
# Uredite ME.md â€” dajte mu ime i osobnost
```

### 6. Pokrenite

**macOS / Linux / WSL2:**
```bash
./run.sh             # Tekstualni TUI (preporuÄeno)
./run.sh --no-tui    # Plain REPL
```

**Windows:**
```bat
run.bat              # Tekstualni TUI (preporuÄeno)
run.bat --no-tui     # Plain REPL
```

---

## Odabir LLM-a

> **PreporuÄeno: Kimi K2.5** â€” najbolja agenta izvedba do sada testirana. PrimjeÄ‡uje kontekst, postavlja dodatna pitanja i djeluje autonomno na naÄine na koje drugi modeli ne rade. Cijenjen je sliÄno kao Claude Haiku.

| Platforma | `PLATFORM=` | Zadani model | Gdje dobiti kljuÄ |
|----------|------------|---------------|-----------------|
| **Moonshot Kimi K2.5** | `kimi` | `kimi-k2.5` | [platform.moonshot.ai](https://platform.moonshot.ai) |
| Z.AI GLM | `glm` | `glm-4.6v` | [api.z.ai](https://api.z.ai) |
| Anthropic Claude | `anthropic` | `claude-haiku-4-5-20251001` | [console.anthropic.com](https://console.anthropic.com) |
| Google Gemini | `gemini` | `gemini-2.5-flash` | [aistudio.google.com](https://aistudio.google.com) |
| OpenAI | `openai` | `gpt-4o-mini` | [platform.openai.com](https://platform.openai.com) |
| OpenAI-kompatibilan (Ollama, vllmâ€¦) | `openai` + `BASE_URL=` | â€” | â€” |
| OpenRouter.ai (multi-provajatelj) | `openai` + `BASE_URL=https://openrouter.ai/api/v1` | â€” | [openrouter.ai](https://openrouter.ai) |
| **CLI alat** (claude -p, ollamaâ€¦) | `cli` | (komanda) | â€” |

**Primjer `.env` za Kimi K2.5:**
```env
PLATFORM=kimi
API_KEY=sk-...   # s platform.moonshot.ai
AGENT_NAME=Yukine
```

**Primjer `.env` za Z.AI GLM:**
```env
PLATFORM=glm
API_KEY=...   # s api.z.ai
MODEL=glm-4.6v   # s podrÅ¡kom za viziju; glm-4.7 / glm-5 = samo tekst
AGENT_NAME=Yukine
```

**Primjer `.env` za Google Gemini:**
```env
PLATFORM=gemini
API_KEY=AIza...   # s aistudio.google.com
MODEL=gemini-2.5-flash  # ili gemini-2.5-pro za veÄ‡u sposobnost
AGENT_NAME=Yukine
```

**Primjer `.env` za OpenRouter.ai:**
```env
PLATFORM=openai
BASE_URL=https://openrouter.ai/api/v1
API_KEY=sk-or-...   # s openrouter.ai
MODEL=mistralai/mistral-7b-instruct  # opcionalno: odredite model
AGENT_NAME=Yukine
```

> **Napomena:** Da biste onemoguÄ‡ili lokalne/NVIDIA modele, jednostavno nemojte postaviti `BASE_URL` na lokalnu toÄku kao Å¡to je `http://localhost:11434/v1`. Umjesto toga koristite cloud pruÅ¾atelje.

**Primjer CLI alata `.env`:**
```env
PLATFORM=cli
MODEL=llm -m gemma3 {}        # llm CLI (https://llm.datasette.io) â€” {} = prompt arg
# MODEL=ollama run gemma3:27b  # Ollama â€” ne {}, prompt ide putem stdin
```

---

## MCP PosluÅ¾itelji

familiar-ai se moÅ¾e povezati s bilo kojim [MCP (Model Context Protocol)](https://modelcontextprotocol.io) posluÅ¾iteljem. Ovo vam omoguÄ‡uje da ukljuÄite vanjsku memoriju, pristup datoteÄnom sustavu, web pretraÅ¾ivanje ili bilo koji drugi alat.

Konfigurirajte posluÅ¾itelje u `~/.familiar-ai.json` (isti format kao Claude Code):

```json
{
  "mcpServers": {
    "filesystem": {
      "type": "stdio",
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-filesystem", "/home/user"]
    },
    "memory": {
      "type": "sse",
      "url": "http://localhost:3000/sse"
    }
  }
}
```

PodrÅ¾ani su dva tipa transporta:
- **`stdio`**: pokreÄ‡e lokalni podproces (`command` + `args`)
- **`sse`**: povezuje se s HTTP+SSE posluÅ¾iteljem (`url`)

PrepiÅ¡ite lokaciju konfiguracijske datoteke s `MCP_CONFIG=/path/to/config.json`.

---

## Hardver

familiar-ai radi s bilo kojim hardverom koji imate â€” ili Äak i bez njega.

| Dio | Å to radi | Primjer | Obavezno? |
|------|-------------|---------|-----------|
| Wi-Fi PTZ kamera | OÄi + vrata | Tapo C220 (~$30) | **PreporuÄeno** |
| USB web kamera | OÄi (fiksne) | Bilo koja UVC kamera | **PreporuÄeno** |
| Robotski usisavaÄ | Noge | Bilo koji model kompatibilan s Tuya | Ne |
| PC / Raspberry Pi | Mozak | Bilo Å¡to Å¡to pokreÄ‡e Python | **Da** |

> **Kamera je snaÅ¾no preporuÄena.** Bez nje, familiar-ai joÅ¡ uvijek moÅ¾e govoriti â€” ali ne moÅ¾e vidjeti svijet, Å¡to je priliÄno bitno.

### Minimalna postavka (bez hardvera)

Å½elite samo isprobati? Trebate samo API kljuÄ:

```env
PLATFORM=kimi
API_KEY=sk-...
```

Pokrenite `./run.sh` (macOS/Linux/WSL2) ili `run.bat` (Windows) i poÄnite Äavrljati. Dodajte hardver kako idete.

### Wi-Fi PTZ kamera (Tapo C220)

1. U Tapo aplikaciji: **Postavke â†’ Napredno â†’ RaÄun za kameru** â€” kreirajte lokalni raÄun (ne TP-Link raÄun)
2. PronaÄ‘ite IP kamere u popisu ureÄ‘aja vaÅ¡eg usmjerivaÄa
3. Postavite u `.env`:
   ```env
   CAMERA_HOST=192.168.1.xxx
   CAMERA_USER=your-local-user
   CAMERA_PASS=your-local-pass
   ```

### Glas (ElevenLabs)

1. Nabavite API kljuÄ na [elevenlabs.io](https://elevenlabs.io/)
2. Postavite u `.env`:
   ```env
   ELEVENLABS_API_KEY=sk_...
   ELEVENLABS_VOICE_ID=...   # opcionalno, koristi zadani glas ako je izostavljeno
   ```

Postoje dvije destinacije za reprodukciju, kontrolirane `TTS_OUTPUT`:

```env
TTS_OUTPUT=local    # PC zvuÄnik (zadano)
TTS_OUTPUT=remote   # samo zvuÄnik kamere
TTS_OUTPUT=both     # zvuÄnik kamere + PC zvuÄnik istovremeno
```

#### A) ZvuÄnik kamere (putem go2rtc)

Postavite `TTS_OUTPUT=remote` (ili `both`). Potrebno je [go2rtc](https://github.com/AlexxIT/go2rtc/releases):

1. Preuzmite binarnu datoteku s [stranice izdanja](https://github.com/AlexxIT/go2rtc/releases):
   - Linux/macOS: `go2rtc_linux_amd64` / `go2rtc_darwin_amd64`
   - **Windows: `go2rtc_win64.exe`**

2. Postavite i preimenujte:
   ```
   # Linux / macOS
   ~/.cache/embodied-claude/go2rtc/go2rtc          # chmod +x potrebno

   # Windows
   %USERPROFILE%\.cache\embodied-claude\go2rtc\go2rtc.exe
   ```

3. Kreirajte `go2rtc.yaml` u istom direktoriju:
   ```yaml
   streams:
     tapo_cam:
       - rtsp://YOUR_CAM_USER:YOUR_CAM_PASS@YOUR_CAM_IP/stream1
   ```
   Koristite akreditive lokalnog raÄuna kamere (ne svoj TP-Link cloud raÄun).

4. familiar-ai automatski pokreÄ‡e go2rtc pri pokretanju. Ako vaÅ¡a kamera podrÅ¾ava dvosmjerni audio (natrag kanal), glas se reproducira s zvuÄnika kamere.

#### B) Lokalne PC zvuÄnike

Zadano (`TTS_OUTPUT=local`). PokuÅ¡ava igraÄe redom: **paplay** â†’ **mpv** â†’ **ffplay**. TakoÄ‘er se koristi kao fallback kada je `TTS_OUTPUT=remote` i go2rtc nije dostupan.

| OS | Instalacija |
|----|---------|
| macOS | `brew install mpv` |
| Ubuntu / Debian | `sudo apt install mpv` (ili `paplay` putem `pulseaudio-utils`) |
| WSL2 / WSLg | `sudo apt install pulseaudio-utils` â€” postavite `PULSE_SERVER=unix:/mnt/wslg/PulseServer` u `.env` |
| Windows | [mpv.io/installation](https://mpv.io/installation/) â€” preuzmite i dodajte u PATH, **ili** `winget install ffmpeg` |

> Ako nijedan audio player nije dostupan, govor se joÅ¡ uvijek generira â€” samo se neÄ‡e reproducirati.

### Glasovni unos (Realtime STT)

Postavite `REALTIME_STT=true` u `.env` za uvijek aktivan, hands-free glasovni unos:

```env
REALTIME_STT=true
ELEVENLABS_API_KEY=sk_...   # isti kljuÄ kao TTS
```

familiar-ai prenosi audio sa mikrofona na ElevenLabs Scribe v2 i automatski pohranjuje transkripte kada prestanete govoriti. Nije potrebna nikakva tipka. Koegzistira s naÄinom pritiskanja za razgovor (Ctrl+T).

---

## TUI

familiar-ai ukljuÄuje terminal UI izgraÄ‘en s [Textual](https://textual.textualize.io/):

- Pomicalna povijest razgovora s tekstom u Å¾ivoj struji
- DovrÅ¡avanje kartica za `/quit`, `/clear`
- Prekidanje agenta tijekom razmiÅ¡ljanja tipkanjem dok razmiÅ¡lja
- **Dnevnik razgovora** automatski pohranjuje u `~/.cache/familiar-ai/chat.log`

Da pratite dnevnik u drugom terminalu (korisno za kopiranje) :
```bash
tail -f ~/.cache/familiar-ai/chat.log
```

---

## Persona (ME.md)

Osobnost vaÅ¡eg familiara Å¾ivi u `ME.md`. Ova datoteka je gitignored â€” samo je vaÅ¡a.

Pogledajte [`persona-template/en.md`](./persona-template/en.md) za primjer, ili [`persona-template/ja.md`](./persona-template/ja.md) za japansku verziju.

---

## ÄŒesto postavljana pitanja

**P: Radi li bez GPU-a?**
Da. Model ugradnje (multilingual-e5-small) dobro radi na CPU-u. GPU ga Äini brÅ¾im, ali nije potreban.

**P: Mogu li koristiti kameru osim Tapo?**
Bilo koja kamera koja podrÅ¾ava ONVIF + RTSP trebala bi raditi. Tapo C220 je ono s Äime smo testirali.

**P: Da li se moji podaci Å¡alju negdje?**
Slike i tekst Å¡alju se na vaÅ¡u odabranu LLM API za obradu. Uspomene se lokalno pohranjuju u `~/.familiar_ai/`.

**P: ZaÅ¡to agent piÅ¡e `ï¼ˆ...ï¼‰` umjesto da govori?**
Provjerite da je `ELEVENLABS_API_KEY` postavljen. Bez njega, glas je onemoguÄ‡en i agent se vraÄ‡a na tekst.

## TehniÄka pozadina

Zanima vas kako to radi? Pogledajte [docs/technical.md](./docs/technical.md) za istraÅ¾ivanje i dizajnerske odluke iza familiar-ai â€” ReAct, SayCan, Reflexion, Voyager, sustav Å¾elja i joÅ¡ mnogo toga.

---

## Sudjelovanje

familiar-ai je otvoreni eksperiment. Ako vam bilo Å¡to od ovoga rezonira â€” tehniÄki ili filozofski â€” doprinosi su vrlo dobrodoÅ¡li.

**Dobra mjesta za poÄetak:**

| PodruÄje | Å to je potrebno |
|------|---------------|
| Novi hardver | PodrÅ¡ka za viÅ¡e kamera (RTSP, IP Webcam), mikrofone, aktuatora |
| Novi alati | Web pretraÅ¾ivanje, automatizacija kuÄ‡anstva, kalendar, bilo Å¡to putem MCP-a |
| Nove pozadine | Bilo koji LLM ili lokalni model koji odgovara `stream_turn` suÄelju |
| PredloÅ¡ci osobnosti | ME.md predloÅ¡ci za razliÄite jezike i osobnosti |
| IstraÅ¾ivanje | Bolji modeli Å¾elja, dohvat memorije, poziv na teoriju uma |
| Dokumentacija | Tutorijali, upute, prijevodi |

Pogledajte [CONTRIBUTING.md](./CONTRIBUTING.md) za postavljanje razvojne sredine, stil kodiranja i smjernice za PR.

Ako niste sigurni gdje poÄeti, [otvorite problem](https://github.com/lifemate-ai/familiar-ai/issues) â€” rado Ä‡u vam ukazati na pravi put.

---

## Licenca

[MIT](./LICENSE)
