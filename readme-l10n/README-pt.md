# familiar-ai üêæ

**Uma IA que vive ao seu lado** ‚Äî com olhos, voz, pernas e mem√≥ria.

[![Lint](https://github.com/kmizu/familiar-ai/actions/workflows/lint.yml/badge.svg)](https://github.com/kmizu/familiar-ai/actions/workflows/lint.yml)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](./LICENSE)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/)
[![GitHub Sponsors](https://img.shields.io/github/sponsors/kmizu?style=flat&logo=github&color=ea4aaa)](https://github.com/sponsors/kmizu)

üåç [Dispon√≠vel em 74 idiomas](./SUPPORTED_LANGUAGES.md)

---

[![Demo video](https://img.youtube.com/vi/hiR9uWRnjt4/0.jpg)](https://youtube.com/shorts/hiR9uWRnjt4)

familiar-ai √© um companheiro de IA que vive na sua casa.
Configure-o em minutos. Sem necessidade de codifica√ß√£o.

Ele percebe o mundo real atrav√©s de c√¢meras, se move em um corpo rob√≥tico, fala em voz alta e se lembra do que v√™. D√™ um nome a ele, escreva sua personalidade e deixe-o viver com voc√™.

## O que ele pode fazer

- üëÅ **Ver** ‚Äî captura imagens de uma c√¢mera PTZ Wi-Fi ou webcam USB
- üîÑ **Olhar ao redor** ‚Äî faz panor√¢micas e inclina a c√¢mera para explorar os arredores
- ü¶ø **Mover** ‚Äî dirige um aspirador rob√¥ para perambular pelo ambiente
- üó£ **Falar** ‚Äî se comunica via ElevenLabs TTS
- üéô **Ouvir** ‚Äî entrada de voz sem as m√£os via ElevenLabs Realtime STT (opcional)
- üß† **Lembrar** ‚Äî armazena e recorda ativamente mem√≥rias com busca sem√¢ntica (SQLite + embeddings)
- ü´Ä **Teoria da Mente** ‚Äî assume a perspectiva da outra pessoa antes de responder
- üí≠ **Desejo** ‚Äî possui suas pr√≥prias motiva√ß√µes internas que acionam comportamentos aut√¥nomos

## Como funciona

familiar-ai executa um loop [ReAct](https://arxiv.org/abs/2210.03629) impulsionado pela sua escolha de LLM. Ele percebe o mundo atrav√©s de ferramentas, pensa sobre o que fazer em seguida e age ‚Äî assim como uma pessoa faria.

```
input do usu√°rio
  ‚Üí pensar ‚Üí agir (c√¢mera / mover / falar / lembrar) ‚Üí observar ‚Üí pensar ‚Üí ...
```

Quando est√° ocioso, ele age de acordo com seus pr√≥prios desejos: curiosidade, vontade de olhar para fora, saudade da pessoa com quem vive.

## Come√ßando

### 1. Instale o uv

**macOS / Linux / WSL2:**
```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

**Windows (PowerShell):**
```powershell
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
```
Ou: `winget install astral-sh.uv`

### 2. Instale o ffmpeg

ffmpeg √© **necess√°rio** para captura de imagem da c√¢mera e reprodu√ß√£o de √°udio.

| SO | Comando |
|----|---------|
| macOS | `brew install ffmpeg` |
| Ubuntu / Debian | `sudo apt install ffmpeg` |
| Fedora / RHEL | `sudo dnf install ffmpeg` |
| Arch Linux | `sudo pacman -S ffmpeg` |
| Windows | `winget install ffmpeg` ‚Äî ou fa√ßa o download em [ffmpeg.org](https://ffmpeg.org/download.html) e adicione ao PATH |
| Raspberry Pi | `sudo apt install ffmpeg` |

Verifique: `ffmpeg -version`

### 3. Clone e instale

```bash
git clone https://github.com/lifemate-ai/familiar-ai
cd familiar-ai
uv sync
```

### 4. Configure

```bash
cp .env.example .env
# Edite .env com suas configura√ß√µes
```

**M√≠nimo necess√°rio:**

| Vari√°vel | Descri√ß√£o |
|----------|-------------|
| `PLATFORM` | `anthropic` (padr√£o) \| `gemini` \| `openai` \| `kimi` \| `glm` |
| `API_KEY` | Sua chave de API para a plataforma escolhida |

**Opcional:**

| Vari√°vel | Descri√ß√£o |
|----------|-------------|
| `MODEL` | Nome do modelo (padr√µes sensatos por plataforma) |
| `AGENT_NAME` | Nome exibido na TUI (ex: `Yukine`) |
| `CAMERA_HOST` | Endere√ßo IP da sua c√¢mera ONVIF/RTSP |
| `CAMERA_USER` / `CAMERA_PASS` | Credenciais da c√¢mera |
| `ELEVENLABS_API_KEY` | Para sa√≠da de voz ‚Äî [elevenlabs.io](https://elevenlabs.io/) |
| `REALTIME_STT` | `true` para habilitar entrada de voz sem as m√£os sempre ativa (requer `ELEVENLABS_API_KEY`) |
| `TTS_OUTPUT` | Onde reproduzir √°udio: `local` (alto-falante do PC, padr√£o) \| `remote` (alto-falante da c√¢mera) \| `both` |
| `THINKING_MODE` | Apenas Anthropic ‚Äî `auto` (padr√£o) \| `adaptive` \| `extended` \| `disabled` |
| `THINKING_EFFORT` | Esfor√ßo de pensamento adaptativo: `high` (padr√£o) \| `medium` \| `low` \| `max` (apenas Opus 4.6) |

### 5. Crie seu familiar

```bash
cp persona-template/en.md ME.md
# Edite ME.md ‚Äî d√™ um nome e personalidade a ele
```

### 6. Execute

**macOS / Linux / WSL2:**
```bash
./run.sh             # TUI textual (recomendado)
./run.sh --no-tui    # REPL simples
```

**Windows:**
```bat
run.bat              # TUI textual (recomendado)
run.bat --no-tui     # REPL simples
```

---

## Escolhendo um LLM

> **Recomendado: Kimi K2.5** ‚Äî melhor desempenho agente testado at√© agora. Nota o contexto, faz perguntas de acompanhamento e age autonomamente de maneiras que outros modelos n√£o fazem. Pre√ßo semelhante ao Claude Haiku.

| Plataforma | `PLATFORM=` | Modelo padr√£o | Onde obter a chave |
|----------|------------|---------------|-----------------|
| **Moonshot Kimi K2.5** | `kimi` | `kimi-k2.5` | [platform.moonshot.ai](https://platform.moonshot.ai) |
| Z.AI GLM | `glm` | `glm-4.6v` | [api.z.ai](https://api.z.ai) |
| Anthropic Claude | `anthropic` | `claude-haiku-4-5-20251001` | [console.anthropic.com](https://console.anthropic.com) |
| Google Gemini | `gemini` | `gemini-2.5-flash` | [aistudio.google.com](https://aistudio.google.com) |
| OpenAI | `openai` | `gpt-4o-mini` | [platform.openai.com](https://platform.openai.com) |
| Compat√≠vel com OpenAI (Ollama, vllm‚Ä¶) | `openai` + `BASE_URL=` | ‚Äî | ‚Äî |
| OpenRouter.ai (multi-fornecedor) | `openai` + `BASE_URL=https://openrouter.ai/api/v1` | ‚Äî | [openrouter.ai](https://openrouter.ai) |
| **Ferramenta CLI** (claude -p, ollama‚Ä¶) | `cli` | (o comando) | ‚Äî |

**Exemplo de `.env` do Kimi K2.5:**
```env
PLATFORM=kimi
API_KEY=sk-...   # do platform.moonshot.ai
AGENT_NAME=Yukine
```

**Exemplo de `.env` do Z.AI GLM:**
```env
PLATFORM=glm
API_KEY=...   # do api.z.ai
MODEL=glm-4.6v   # habilitado para vis√£o; glm-4.7 / glm-5 = apenas texto
AGENT_NAME=Yukine
```

**Exemplo de `.env` do Google Gemini:**
```env
PLATFORM=gemini
API_KEY=AIza...   # do aistudio.google.com
MODEL=gemini-2.5-flash  # ou gemini-2.5-pro para maior capacidade
AGENT_NAME=Yukine
```

**Exemplo de `.env` do OpenRouter.ai:**
```env
PLATFORM=openai
BASE_URL=https://openrouter.ai/api/v1
API_KEY=sk-or-...   # do openrouter.ai
MODEL=mistralai/mistral-7b-instruct  # opcional: especifique o modelo
AGENT_NAME=Yukine
```

> **Nota:** Para desativar modelos locais/NVIDIA, simplesmente n√£o defina `BASE_URL` para um endpoint local como `http://localhost:11434/v1`. Use provedores de nuvem em vez disso.

**Exemplo de `.env` da ferramenta CLI:**
```env
PLATFORM=cli
MODEL=llm -m gemma3 {}        # llm CLI (https://llm.datasette.io) ‚Äî {} = argumento do prompt
# MODEL=ollama run gemma3:27b  # Ollama ‚Äî sem {}, o prompt vai via stdin
```

---

## Servidores MCP

familiar-ai pode se conectar a qualquer servidor [MCP (Model Context Protocol)](https://modelcontextprotocol.io). Isso permite que voc√™ integre mem√≥ria externa, acesso ao sistema de arquivos, pesquisa na web, ou qualquer outra ferramenta.

Configure os servidores em `~/.familiar-ai.json` (mesmo formato que o Claude Code):

```json
{
  "mcpServers": {
    "filesystem": {
      "type": "stdio",
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-filesystem", "/home/user"]
    },
    "memory": {
      "type": "sse",
      "url": "http://localhost:3000/sse"
    }
  }
}
```

Dois tipos de transporte s√£o suportados:
- **`stdio`**: lan√ßa um subprocesso local (`command` + `args`)
- **`sse`**: conecta a um servidor HTTP+SSE (`url`)

Substitua a localiza√ß√£o do arquivo de configura√ß√£o com `MCP_CONFIG=/caminho/para/config.json`.

---

## Hardware

familiar-ai funciona com qualquer hardware que voc√™ tenha ‚Äî ou nenhum.

| Parte | O que faz | Exemplo | Necess√°rio? |
|------|-------------|---------|-----------|
| C√¢mera PTZ Wi-Fi | Olhos + pesco√ßo | Tapo C220 (~$30) | **Recomendado** |
| Webcam USB | Olhos (fixos) | Qualquer c√¢mera UVC | **Recomendado** |
| Aspirador rob√¥ | Pernas | Qualquer modelo compat√≠vel com Tuya | N√£o |
| PC / Raspberry Pi | C√©rebro | Qualquer coisa que execute Python | **Sim** |

> **Uma c√¢mera √© fortemente recomendada.** Sem uma, a familiar-ai ainda pode falar ‚Äî mas n√£o pode ver o mundo, o que √© meio que o ponto principal.

### Configura√ß√£o m√≠nima (sem hardware)

S√≥ quer experimentar? Voc√™ s√≥ precisa de uma chave de API:

```env
PLATFORM=kimi
API_KEY=sk-...
```

Execute `./run.sh` (macOS/Linux/WSL2) ou `run.bat` (Windows) e comece a conversar. Adicione hardware conforme necess√°rio.

### C√¢mera PTZ Wi-Fi (Tapo C220)

1. No aplicativo Tapo: **Configura√ß√µes ‚Üí Avan√ßado ‚Üí Conta da C√¢mera** ‚Äî crie uma conta local (n√£o conta TP-Link)
2. Encontre o IP da c√¢mera na lista de dispositivos do seu roteador
3. Defina em `.env`:
   ```env
   CAMERA_HOST=192.168.1.xxx
   CAMERA_USER=seu-usuario-local
   CAMERA_PASS=sua-senha-local
   ```

### Voz (ElevenLabs)

1. Obtenha uma chave de API em [elevenlabs.io](https://elevenlabs.io/)
2. Defina em `.env`:
   ```env
   ELEVENLABS_API_KEY=sk_...
   ELEVENLABS_VOICE_ID=...   # opcional, usa a voz padr√£o se omitido
   ```

Existem dois destinos de reprodu√ß√£o, controlados por `TTS_OUTPUT`:

```env
TTS_OUTPUT=local    # alto-falante do PC (padr√£o)
TTS_OUTPUT=remote   # apenas alto-falante da c√¢mera
TTS_OUTPUT=both     # alto-falante da c√¢mera + alto-falante do PC simultaneamente
```

#### A) Alto-falante da c√¢mera (via go2rtc)

Defina `TTS_OUTPUT=remote` (ou `both`). Requer [go2rtc](https://github.com/AlexxIT/go2rtc/releases):

1. Baixe o bin√°rio da [p√°gina de lan√ßamentos](https://github.com/AlexxIT/go2rtc/releases):
   - Linux/macOS: `go2rtc_linux_amd64` / `go2rtc_darwin_amd64`
   - **Windows: `go2rtc_win64.exe`**

2. Coloque e renomeie:
   ```
   # Linux / macOS
   ~/.cache/embodied-claude/go2rtc/go2rtc          # chmod +x necess√°rio

   # Windows
   %USERPROFILE%\.cache\embodied-claude\go2rtc\go2rtc.exe
   ```

3. Crie `go2rtc.yaml` no mesmo diret√≥rio:
   ```yaml
   streams:
     tapo_cam:
       - rtsp://SEU_CAM_USER:SEU_CAM_PASS@SEU_CAM_IP/stream1
   ```
   Use as credenciais da conta local da c√¢mera (n√£o sua conta TP-Link cloud).

4. familiar-ai inicia automaticamente o go2rtc na inicializa√ß√£o. Se sua c√¢mera suporta √°udio bidirecional (canal de retorno), a voz √© reproduzida a partir do alto-falante da c√¢mera.

#### B) Alto-falante local do PC

O padr√£o (`TTS_OUTPUT=local`). Tenta reprodutores em ordem: **paplay** ‚Üí **mpv** ‚Üí **ffplay**. Tamb√©m √© utilizado como uma alternativa quando `TTS_OUTPUT=remote` e go2rtc n√£o est√° dispon√≠vel.

| SO | Instala√ß√£o |
|----|---------|
| macOS | `brew install mpv` |
| Ubuntu / Debian | `sudo apt install mpv` (ou `paplay` via `pulseaudio-utils`) |
| WSL2 / WSLg | `sudo apt install pulseaudio-utils` ‚Äî defina `PULSE_SERVER=unix:/mnt/wslg/PulseServer` em `.env` |
| Windows | [mpv.io/installation](https://mpv.io/installation/) ‚Äî fa√ßa o download e adicione ao PATH, **ou** `winget install ffmpeg` |

> Se nenhum reprodutor de √°udio estiver dispon√≠vel, a fala ainda √© gerada ‚Äî mas n√£o ser√° reproduzida.

### Entrada de voz (Realtime STT)

Defina `REALTIME_STT=true` em `.env` para entrada de voz sem as m√£os sempre ativa:

```env
REALTIME_STT=true
ELEVENLABS_API_KEY=sk_...   # mesma chave que para TTS
```

familiar-ai transmite √°udio do microfone para o ElevenLabs Scribe v2 e auto-confirma transcri√ß√µes quando voc√™ faz uma pausa ao falar. Nenhum pressionamento de bot√£o √© necess√°rio. Coexiste com o modo de pressionar para falar (Ctrl+T).

---

## TUI

familiar-ai inclui uma interface de terminal constru√≠da com [Textual](https://textual.textualize.io/):

- Hist√≥rico de conversa rol√°vel com texto em streaming ao vivo
- Completa√ß√£o de tabula√ß√£o para `/quit`, `/clear`
- Interrompa o agente no meio do turno digitando enquanto ele est√° pensando
- **Registro de conversa** auto-salvo em `~/.cache/familiar-ai/chat.log`

Para acompanhar o registro em outro terminal (√∫til para copiar e colar):
```bash
tail -f ~/.cache/familiar-ai/chat.log
```

---

## Persona (ME.md)

A personalidade do seu familiar vive em `ME.md`. Este arquivo √© ignorado pelo git ‚Äî √© s√≥ seu.

Veja [`persona-template/en.md`](./persona-template/en.md) para um exemplo, ou [`persona-template/ja.md`](./persona-template/ja.md) para uma vers√£o em japon√™s.

---

## FAQ

**Q: Funciona sem uma GPU?**
Sim. O modelo de embedding (multilingual-e5-small) roda bem na CPU. Uma GPU torna mais r√°pido, mas n√£o √© obrigat√≥ria.

**Q: Posso usar uma c√¢mera diferente da Tapo?**
Qualquer c√¢mera que suporte ONVIF + RTSP deve funcionar. Tapo C220 √© o que testamos.

**Q: Meus dados s√£o enviados para algum lugar?**
Imagens e textos s√£o enviados para a API do LLM escolhido para processamento. Mem√≥rias s√£o armazenadas localmente em `~/.familiar_ai/`.

**Q: Por que o agente escreve `Ôºà...Ôºâ` em vez de falar?**
Certifique-se de que `ELEVENLABS_API_KEY` est√° definido. Sem isso, a voz fica desativada e o agente volta ao texto.

## Contexto t√©cnico

Curioso sobre como funciona? Veja [docs/technical.md](./docs/technical.md) para as decis√µes de pesquisa e design por tr√°s do familiar-ai ‚Äî ReAct, SayCan, Reflexion, Voyager, o sistema de desejo e mais.

---

## Contribui√ß√µes

familiar-ai √© um experimento aberto. Se algo disso ressoa com voc√™ ‚Äî tecnicamente ou filosoficamente ‚Äî contribui√ß√µes s√£o muito bem-vindas.

**Boas √°reas para come√ßar:**

| √Årea | O que √© necess√°rio |
|------|---------------|
| Novo hardware | Suporte para mais c√¢meras (RTSP, Webcam IP), microfones, atuadores |
| Novas ferramentas | Pesquisa na web, automa√ß√£o residencial, calend√°rio, qualquer coisa via MCP |
| Novos backends | Qualquer LLM ou modelo local que se encaixe na interface `stream_turn` |
| Modelos de persona | Templates de ME.md para diferentes idiomas e personalidades |
| Pesquisa | Melhores modelos de desejo, recupera√ß√£o de mem√≥ria, prompting de teoria da mente |
| Documenta√ß√£o | Tutoriais, guias, tradu√ß√µes |

Veja [CONTRIBUTING.md](./CONTRIBUTING.md) para configura√ß√£o de desenvolvimento, estilo de c√≥digo e diretrizes de PR.

Se voc√™ n√£o souber por onde come√ßar, [abra um issue](https://github.com/lifemate-ai/familiar-ai/issues) ‚Äî feliz em apont√°-lo na dire√ß√£o certa.

---

## Licen√ßa

[MIT](./LICENSE)
