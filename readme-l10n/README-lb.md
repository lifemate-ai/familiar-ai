# familiar-ai ğŸ¾

**Eng AI dÃ©i neben dir lieft** â€” mat Aen, StÃ«mm, Been, a GedÃ¤chtnis.

[![Lint](https://github.com/kmizu/familiar-ai/actions/workflows/lint.yml/badge.svg)](https://github.com/kmizu/familiar-ai/actions/workflows/lint.yml)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](./LICENSE)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/)
[![GitHub Sponsors](https://img.shields.io/github/sponsors/kmizu?style=flat&logo=github&color=ea4aaa)](https://github.com/sponsors/kmizu)

ğŸŒ [Available in 74 languages](./SUPPORTED_LANGUAGES.md)

---

[![Demo video](https://img.youtube.com/vi/hiR9uWRnjt4/0.jpg)](https://youtube.com/shorts/hiR9uWRnjt4)

familiar-ai ass en AI Begleiter deen an dengem Heem lieft. 
Setz et an nÃ«mmen e puer Minutten. Kee Code nÃ©ideg.

Et erkennt d'Ã¤cht Welt duerch Kameras, bewegt sech op engem Roboterkierper, schwÃ¤tzt, an erÃ«nnert sech un wat et gesÃ¤it. GÃ«ff et e Numm, schreiw seng PersÃ©inlechkeet, an loosst et mat dir liewen.

## Wat et kann

- ğŸ‘ **Sehen** â€” fÃ¤nkt Biller vun enger Wi-Fi PTZ Kamera oder USB Webcam
- ğŸ”„ **RondrÃ«m kucken** â€” panoramÃ©iert an tilts d'Kamera fir seng Ã‹mfeld ze entdecken
- ğŸ¦¿ **Bewegen** â€” fÃ©iert e Roboter-StÃ«bsauger ronderÃ«m d'ZÃ«mmer
- ğŸ—£ **Sprechen** â€” schwÃ¤tzt iwwer ElevenLabs TTS
- ğŸ™ **HÃ©ieren** â€” freihÃ¤nschen Spriechinput iwwer ElevenLabs Realtime STT (op opt-in)
- ğŸ§  **ErÃ«nneren** â€” aktiv armazenÃ©iert a rÃ«ckruff GedÃ¤chtnisser mat semantescher Sich (SQLite + Embeddings)
- ğŸ«€ **Theory of Mind** â€” ass d'Perspektiv vun der anerer Persoun virun der Ã„ntwert
- ğŸ’­ **WÃ«nsch** â€” huet seng eegen intern DrÃ©it dÃ©i autonom Verhalen auslÃ©isen

## WÃ©i et funktionnÃ©iert

familiar-ai betreibt eng [ReAct](https://arxiv.org/abs/2210.03629) Schleife dÃ©i vun der gewielter LLM ugedriwwe gÃ«tt. Et erkennt d'Welt duerch Tools, denkt iwwer wat ze maachen, a handelt â€” just wÃ©i eng Persoun.

```
user input
  â†’ think â†’ act (camera / move / speak / remember) â†’ observe â†’ think â†’ ...
```

Wann et roueg ass, handelt et basÃ©iert op sengen eegenen WÃ«nsch: SÃ«nn fir Entdeckungen, wÃ«ll d'Welt vun der Dier ze gesin, vermÃ«sst d'Persoun dÃ©i mat et liewt.

## Ugefaangen

### 1. InstallÃ©iert uv

**macOS / Linux / WSL2:**
```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

**Windows (PowerShell):**
```powershell
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
```
Oder: `winget install astral-sh.uv`

### 2. InstallÃ©iert ffmpeg

ffmpeg ass **virdru** fir d'Fangung vun Kamera-Biller an Audio-Wiedergabe.

| OS | Command |
|----|---------|
| macOS | `brew install ffmpeg` |
| Ubuntu / Debian | `sudo apt install ffmpeg` |
| Fedora / RHEL | `sudo dnf install ffmpeg` |
| Arch Linux | `sudo pacman -S ffmpeg` |
| Windows | `winget install ffmpeg` â€” oder eroflueden vun [ffmpeg.org](https://ffmpeg.org/download.html) an zur PATH derbÃ¤i setzen |
| Raspberry Pi | `sudo apt install ffmpeg` |

VerifizÃ©ieren: `ffmpeg -version`

### 3. Klonen an InstallÃ©ieren

```bash
git clone https://github.com/lifemate-ai/familiar-ai
cd familiar-ai
uv sync
```

### 4. KonfigurÃ©ieren

```bash
cp .env.example .env
# Edit .env mat deinen Astellungen
```

**Minimum nÃ©ideg:**

| Variable | Beschreiwung |
|----------|--------------|
| `PLATFORM` | `anthropic` (default) \| `gemini` \| `openai` \| `kimi` \| `glm` |
| `API_KEY` | DÃ©i API SchlÃ¼ssel fir d'gewielte Plattform |

**Optional:**

| Variable | Beschreiwung |
|----------|--------------|
| `MODEL` | Modell Numm (sÃ«nnvoll Standards pro Plattform) |
| `AGENT_NAME` | E Display Numm am TUI (z.B. `Yukine`) |
| `CAMERA_HOST` | IP Adress vun der ONVIF/RTSP Kamera |
| `CAMERA_USER` / `CAMERA_PASS` | Kamera Credentials |
| `ELEVENLABS_API_KEY` | Fir d'Audio Ausgab â€” [elevenlabs.io](https://elevenlabs.io/) |
| `REALTIME_STT` | `true` fir Ã«mmer-op HÃ¤nde frÃ¤i StÃ«mm Input ze aktivÃ©ieren (requiert `ELEVENLABS_API_KEY`) |
| `TTS_OUTPUT` | Wou d'Audio spillen: `local` (PC Lautsprecher, standard) \| `remote` (Kamera Lautsprecher) \| `both` |
| `THINKING_MODE` | Antropic nÃ«mmen â€” `auto` (standard) \| `adaptive` \| `extended` \| `disabled` |
| `THINKING_EFFORT` | Adaptiv Gedankenaufwand: `high` (standard) \| `medium` \| `low` \| `max` (Opus 4.6 nÃ«mmen) |

### 5. KÃ©iert Ã„r Familiar

```bash
cp persona-template/en.md ME.md
# Edit ME.md â€” gitt et e Numm an PersÃ©inlechkeet
```

### 6. Lafen

**macOS / Linux / WSL2:**
```bash
./run.sh             # Textual TUI (recommandÃ©iert)
./run.sh --no-tui    # Plain REPL
```

**Windows:**
```bat
run.bat              # Textual TUI (recommandÃ©iert)
run.bat --no-tui     # Plain REPL
```

---

## Wielen eng LLM

> **RecommandÃ©iert: Kimi K2.5** â€” dÃ©i bescht agentesch Leeschtung bis elo getest. Erkannt Kontext, freet no, a handelt autonom op ManÃ©ieren dÃ©i aner Modeller net maachen. PrÃ¤is huet e Ã¤hnleche PrÃ¤is wÃ©i Claude Haiku.

| Plattform | `PLATFORM=` | Standard Modell | Wou den Key krÃ©ien |
|----------|------------|----------------|-------------------|
| **Moonshot Kimi K2.5** | `kimi` | `kimi-k2.5` | [platform.moonshot.ai](https://platform.moonshot.ai) |
| Z.AI GLM | `glm` | `glm-4.6v` | [api.z.ai](https://api.z.ai) |
| Anthropic Claude | `anthropic` | `claude-haiku-4-5-20251001` | [console.anthropic.com](https://console.anthropic.com) |
| Google Gemini | `gemini` | `gemini-2.5-flash` | [aistudio.google.com](https://aistudio.google.com) |
| OpenAI | `openai` | `gpt-4o-mini` | [platform.openai.com](https://platform.openai.com) |
| OpenAI-kompatibel (Ollama, vllmâ€¦) | `openai` + `BASE_URL=` | â€” | â€” |
| OpenRouter.ai (multi-provider) | `openai` + `BASE_URL=https://openrouter.ai/api/v1` | â€” | [openrouter.ai](https://openrouter.ai) |
| **CLI Tool** (claude -p, ollamaâ€¦) | `cli` | (de Befehl) | â€” |

**Kimi K2.5 `.env` Beispiel:**
```env
PLATFORM=kimi
API_KEY=sk-...   # vun platform.moonshot.ai
AGENT_NAME=Yukine
```

**Z.AI GLM `.env` Beispiel:**
```env
PLATFORM=glm
API_KEY=...   # vun api.z.ai
MODEL=glm-4.6v   # vision-enabled; glm-4.7 / glm-5 = text-only
AGENT_NAME=Yukine
```

**Google Gemini `.env` Beispiel:**
```env
PLATFORM=gemini
API_KEY=AIza...   # vun aistudio.google.com
MODEL=gemini-2.5-flash  # oder gemini-2.5-pro fir mÃ©i FÃ¤egkeet
AGENT_NAME=Yukine
```

**OpenRouter.ai `.env` Beispiel:**
```env
PLATFORM=openai
BASE_URL=https://openrouter.ai/api/v1
API_KEY=sk-or-...   # vun openrouter.ai
MODEL=mistralai/mistral-7b-instruct  # optional: spezifizÃ©ieren Modell
AGENT_NAME=Yukine
```

> **Bemierkung:** Fir lokal/NVIDIA Modeller ze deaktivÃ©ieren, setzt einfach net `BASE_URL` op eng lokal Adress wÃ©i `http://localhost:11434/v1`. Benotz lÃ©iwer Cloud-Provider.

**CLI Tool `.env` Beispiel:**
```env
PLATFORM=cli
MODEL=llm -m gemma3 {}        # llm CLI (https://llm.datasette.io) â€” {} = prompt arg
# MODEL=ollama run gemma3:27b  # Ollama â€” keen {}, prompt geet iwwer stdin
```

---

## MCP Server

familiar-ai kann sich mat all [MCP (Model Context Protocol)](https://modelcontextprotocol.io) Server verbannen. DÃ«st erlaabt dir extern GedÃ¤chtnis, Dateisystem AccÃ¨s, Web Sich, oder all aner Tools anzestellen.

KonfigurÃ©iert Serveren an `~/.familiar-ai.json` (selwecht Format wÃ©i Claude Code):

```json
{
  "mcpServers": {
    "filesystem": {
      "type": "stdio",
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-filesystem", "/home/user"]
    },
    "memory": {
      "type": "sse",
      "url": "http://localhost:3000/sse"
    }
  }
}
```

Zwee Transporttypen sinn Ã«nnerstÃ«tzt:
- **`stdio`**: Start eng lokal Subprozess (`command` + `args`)
- **`sse`**: VerbÃ«nnt mat engem HTTP+SSE Server (`url`)

D'Config Datei Plaz mat `MCP_CONFIG=/path/to/config.json` Ã¤nneren.

---

## Hardware

familiar-ai funktionnÃ©iert mat all Hardware dÃ©i Dir hutt â€” oder och keng.

| Deel | Wat et mÃ©cht | Beispill | NÃ©ideg? |
|------|--------------|----------|---------|
| Wi-Fi PTZ Kamera | Aen + Hals | Tapo C220 (~$30) | **RecommandÃ©iert** |
| USB Webcam | Aen (fest) | All UVC Kamera | **RecommandÃ©iert** |
| Roboter-StÃ«bsauger | Been | All Tuya-kompatibel Modell | Nee |
| PC / Raspberry Pi | Gehier | Alles wat Python Ã«nnerstÃ«tzt | **Jo** |

> **Eng Kamera ass staark recommandÃ©iert.** Ouni eng, kann familiar-ai nach Ã«mmer schwÃ¤tzen â€” mÃ¤ et kann d'Welt net gesin, firwat et tatsÃ¤chlech enges do ass.

### Minimal Setup (keine Hardware)

WÃ«lls de just probÃ©ieren? Du braucht nÃ«mmen eng API SchlÃ¼ssel:

```env
PLATFORM=kimi
API_KEY=sk-...
```

FÃ¤nken `./run.sh` (macOS/Linux/WSL2) oder `run.bat` (Windows) un an ufÃ¤nken ze schwÃ¤tzen. Add Hardware wa's de gees.

### Wi-Fi PTZ Kamera (Tapo C220)

1. An der Tapo App: **Settings â†’ Advanced â†’ Camera Account** â€” eng lokal Kont erstell (net TP-Link Kont)
2. Fann d'IP vun der Kamera an der GerÃ¤telÃ«scht vu sengem Router
3. Setz an `.env`:
   ```env
   CAMERA_HOST=192.168.1.xxx
   CAMERA_USER=your-local-user
   CAMERA_PASS=your-local-pass
   ```

### StÃ«mm (ElevenLabs)

1. KrÃ©ie eng API SchlÃ¼ssel op [elevenlabs.io](https://elevenlabs.io/)
2. Setz an `.env`:
   ```env
   ELEVENLABS_API_KEY=sk_...
   ELEVENLABS_VOICE_ID=...   # optional, benotzt StandardstÃ«mm wann et ausgelass ass
   ```

Et ginn zwou Playback Destinatiounen, kontrollÃ©iert duerch `TTS_OUTPUT`:

```env
TTS_OUTPUT=local    # PC Lautsprecher (standard)
TTS_OUTPUT=remote   # Kamera Lautsprecher vun der LÃ¤sch
TTS_OUTPUT=both     # Kamera Lautsprecher + PC Lautsprecher glÃ¤ichzÃ¤iteg
```

#### A) Kamera-Lautsprecher (via go2rtc)

Setz `TTS_OUTPUT=remote` (oder `both`). Requiert [go2rtc](https://github.com/AlexxIT/go2rtc/releases):

1. Lued d'binary vun der [Releases Seite](https://github.com/AlexxIT/go2rtc/releases):
   - Linux/macOS: `go2rtc_linux_amd64` / `go2rtc_darwin_amd64`
   - **Windows: `go2rtc_win64.exe`**

2. PlazÃ©ieren a umbenannt:
   ```
   # Linux / macOS
   ~/.cache/embodied-claude/go2rtc/go2rtc          # chmod +x nÃ©ideg

   # Windows
   %USERPROFILE%\.cache\embodied-claude\go2rtc\go2rtc.exe
   ```

3. KreÃ©iert `go2rtc.yaml` an der selwechter DossÃ©ier:
   ```yaml
   streams:
     tapo_cam:
       - rtsp://YOUR_CAM_USER:YOUR_CAM_PASS@YOUR_CAM_IP/stream1
   ```
   Benotzt d'lokale Kamera Kont Credentials (net Ã¤r TP-Link Cloud Kont).

4. familiar-ai startet go2rtc automatesch beim Start. Wann d'Kamera zwee-Wee Audio (Backchannel) Ã«nnerstÃ«tzt, spillt d'Audio vum Kamera Lautsprecher.

#### B) Lokalen PC Lautsprecher

Den Standard (`TTS_OUTPUT=local`). ProbÃ©iert Spiller an der Rei no: **paplay** â†’ **mpv** â†’ **ffplay**. Och als Fallback wann `TTS_OUTPUT=remote` an go2rtc net verfÃ¼gbar ass.

| OS | InstallÃ©ieren |
|----|---------------|
| macOS | `brew install mpv` |
| Ubuntu / Debian | `sudo apt install mpv` (oder `paplay` iwwer `pulseaudio-utils`) |
| WSL2 / WSLg | `sudo apt install pulseaudio-utils` â€” setzt `PULSE_SERVER=unix:/mnt/wslg/PulseServer` an `.env` |
| Windows | [mpv.io/installation](https://mpv.io/installation/) â€” eroflueden an zur PATH derbÃ¤i setzen, **oder** `winget install ffmpeg` |

> Wann keen Audio Spiller verfÃ¼gbar ass, gÃ«tt d'Sprooch nach Ã«mmer generÃ©iert â€” et spilliicht se just net.

### StÃ«mm Input (Realtime STT)

Setz `REALTIME_STT=true` an `.env` fir Ã«mmer-op, HÃ¤nde frÃ¤i StÃ«mm Input:

```env
REALTIME_STT=true
ELEVENLABS_API_KEY=sk_...   # dÃ©iselwecht Key wÃ©i TTS
```

familiar-ai streamt Mikrofon Audio zu ElevenLabs Scribe v2 an auto-committed Transkriptiounen wanns de stopt ze schwÃ¤tzen. Keen KnÃ¤ppchen drÃ©cke gebraucht. KoexistÃ©iert mat der Push-to-Talk Modus (Ctrl+T).

---

## TUI

familiar-ai enthÃ¤lt eng Terminal UI gebaut mat [Textual](https://textual.textualize.io/):

- Scrollable GesprÃ©chsverlauf mat live Streaming Text
- Tab-Completing fir `/quit`, `/clear`
- Unterbriech den Agent MÃ«d-Turn andeems de schreift wann et denkt
- **GesprÃ¤chslog** automatesch gespÃ¤ichert an `~/.cache/familiar-ai/chat.log`

Fir de Log an engem anere Terminal ze verfollegen (nÃ«tzlech fir KopiÃ©iere-Paste):
```bash
tail -f ~/.cache/familiar-ai/chat.log
```

---

## Persona (ME.md)

D'PersÃ©inlechkeet vun dengem Familiar lieft an `ME.md`. DÃ«se File ass gitignored â€” et ass nÃ«mme fir dech.

Kuck [`persona-template/en.md`](./persona-template/en.md) fir e Beispill, oder [`persona-template/ja.md`](./persona-template/ja.md) fir eng japanesch Versioun.

---

## FAQ

**Q: FunktionÃ©iert et ouni GPU?**
Jo. D'Embedding Modell (multilingual-e5-small) fonctionnÃ©iert gutt um CPU. E GPU mÃ©cht et mÃ©i sÃ©ier, ass awer net nÃ©ideg.

**Q: Kann ech eng Kamera benotzen dÃ©i net Tapo ass?**
Jede Kamera dÃ©i ONVIF + RTSP Ã«nnerstÃ«tzt soll funktionnÃ©ieren. Tapo C220 ass dÃ©i dÃ©i mir getestet hunn.

**Q: GÃ«tt meng Daten irgendsou geschÃ©ckt?**
Biller an Text ginn un deng gewielt LLM API fir Verarbetung geschÃ©ckt. GedÃ¤chtnisser ginn lokal an `~/.familiar_ai/` armazenÃ©iert.

**Q: Firwat schreift den Agent `ï¼ˆ...ï¼‰` amplaz ze schwÃ¤tzen?**
AnerstÃ©cht sÃ©cher datt `ELEVENLABS_API_KEY` gesetzt ass. Ouni dat ass d'Audio deaktivÃ©iert a den Agent geet zrÃ©ck op Text.

## Technesch Hannergrond

InteressÃ©iert fir wÃ©i et funktionnÃ©iert? Kuck [docs/technical.md](./docs/technical.md) fir d'Recherche a Design-Entscheedungen dÃ©i hannert familiar-ai steet â€” ReAct, SayCan, Reflexion, Voyager, d'WÃ«nschsystem, an mÃ©i.

---

## Contributing

familiar-ai ass e offenen Experiment. Wann eppes dovun mat dir ressonÃ©iert â€” technesch oder philosophesch â€” sinn d'Contributiounen ganz wÃ«llkomm.

**Gudde Plazen fir unzefÃ¤nken:**

| BerÃ¤ich | Wat nÃ©ideg ass |
|------|----------------|
| New Hardware | Ã‹nnerstÃ«tzung fir mÃ©i Kameraen (RTSP, IP Webcam), Mikrofone, Aktuatoren |
| New Tools | Web Sich, Heem Automatioun, Kalenner, alles iwwer MCP |
| New Backends | All LLM oder lokal Modell dat der `stream_turn` Interface passt |
| Persona Templates | ME.md Templates fir verschidde Sproochen a PersÃ©inlechkeeten |
| Recherche | Besser WÃ«nsch Modeller, GedÃ¤chtnisretrieval, Theory-of-Mind Prompting |
| Dokumentatioun | Tutorials, Walkthroughs, Iwwersetzungen |

Kuck [CONTRIBUTING.md](./CONTRIBUTING.md) fir Dev Setup, Code Style, a PR Richtlinnen.

Wanns de net sÃ©cher bis, wou unzefÃ¤nken, [maach eng Problematik op](https://github.com/lifemate-ai/familiar-ai/issues) â€” ech sinn zougestÃ«mmen fir dech an dÃ©i richteg Richtung ze weisen.

---

## Lizenz

[MIT](./LICENSE)
