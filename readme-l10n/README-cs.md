```markdown
# familiar-ai üêæ

**AI, kter√Ω ≈æije vedle v√°s** ‚Äî s oƒçima, hlasem, nohama a pamƒõt√≠.

[![Lint](https://github.com/kmizu/familiar-ai/actions/workflows/lint.yml/badge.svg)](https://github.com/kmizu/familiar-ai/actions/workflows/lint.yml)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](./LICENSE)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/)
[![GitHub Sponsors](https://img.shields.io/github/sponsors/kmizu?style=flat&logo=github&color=ea4aaa)](https://github.com/sponsors/kmizu)

üåç [Dostupn√© ve 74 jazyc√≠ch](./SUPPORTED_LANGUAGES.md)

---

[![Demo video](https://img.youtube.com/vi/hiR9uWRnjt4/0.jpg)](https://youtube.com/shorts/hiR9uWRnjt4)

familiar-ai je AI spoleƒçn√≠k, kter√Ω ≈æije ve va≈°em domƒõ. 
Nastavte ho za p√°r minut. Nepot≈ôebujete ≈æ√°dn√© k√≥dov√°n√≠.

Vn√≠m√° re√°ln√Ω svƒõt prost≈ôednictv√≠m kamer, pohybuje se na robotick√©m tƒõle, mluv√≠ nahlas a pamatuje si, co vid√≠. Dejte mu jm√©no, napi≈°te jeho osobnost a nechte ho ≈æ√≠t s v√°mi.

## Co dok√°≈æe

- üëÅ **Vidƒõt** ‚Äî zachycuje obr√°zky z Wi-Fi PTZ kamery nebo USB webov√© kamery
- üîÑ **Ohl√©dnout se** ‚Äî nat√°ƒç√≠ a nakl√°n√≠ kameru, aby prozkoumala sv√© okol√≠
- ü¶ø **Pohybovat se** ‚Äî ovl√°d√° robotick√Ω vysavaƒç, aby se pohyboval po m√≠stnosti
- üó£ **Mluvit** ‚Äî mluv√≠ pomoc√≠ ElevenLabs TTS
- üéô **Poslouchat** ‚Äî bezdr√°tov√Ω hlasov√Ω vstup pomoc√≠ ElevenLabs Realtime STT (opt-in)
- üß† **Pamatovat** ‚Äî aktivnƒõ ukl√°d√° a vybavuje si vzpom√≠nky s pou≈æit√≠m s√©mantick√©ho vyhled√°v√°n√≠ (SQLite + embeddings)
- ü´Ä **Teorie mysli** ‚Äî p≈ôej√≠m√° perspektivu druh√© osoby p≈ôed odpovƒõd√≠
- üí≠ **Touha** ‚Äî m√° sv√© vlastn√≠ vnit≈ôn√≠ pohony, kter√© vyvol√°vaj√≠ autonomn√≠ chov√°n√≠

## Jak to funguje

familiar-ai bƒõ≈æ√≠ na [ReAct](https://arxiv.org/abs/2210.03629) smyƒçce nap√°jen√©m va≈°√≠ volbou LLM. Vn√≠m√° svƒõt prost≈ôednictv√≠m n√°stroj≈Ø, p≈ôem√Ω≈°l√≠, co dƒõlat d√°l, a jedn√° ‚Äî p≈ôesnƒõ jako by to udƒõlal ƒçlovƒõk.

```
user input
  ‚Üí think ‚Üí act (camera / move / speak / remember) ‚Üí observe ‚Üí think ‚Üí ...
```

Kdy≈æ je neƒçinn√Ω, jedn√° podle sv√Ωch vlastn√≠ch touh: zvƒõdavost, chtƒõn√≠ pod√≠vat se ven, st√Ωsk√°n√≠ si po osobƒõ, se kterou ≈æije.

## Zaƒç√≠n√°me

### 1. Nainstalujte uv

**macOS / Linux / WSL2:**
```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

**Windows (PowerShell):**
```powershell
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
```
Nebo: `winget install astral-sh.uv`

### 2. Nainstalujte ffmpeg

ffmpeg je **po≈æadov√°n** pro zachycen√≠ obr√°zk≈Ø z kamery a p≈ôehr√°v√°n√≠ zvuku.

| OS | P≈ô√≠kaz |
|----|--------|
| macOS | `brew install ffmpeg` |
| Ubuntu / Debian | `sudo apt install ffmpeg` |
| Fedora / RHEL | `sudo dnf install ffmpeg` |
| Arch Linux | `sudo pacman -S ffmpeg` |
| Windows | `winget install ffmpeg` ‚Äî nebo st√°hnƒõte z [ffmpeg.org](https://ffmpeg.org/download.html) a p≈ôidejte do PATH |
| Raspberry Pi | `sudo apt install ffmpeg` |

Ovƒõ≈ôte: `ffmpeg -version`

### 3. Klonujte a nainstalujte

```bash
git clone https://github.com/lifemate-ai/familiar-ai
cd familiar-ai
uv sync
```

### 4. Konfigurujte

```bash
cp .env.example .env
# Upravte .env se sv√Ωmi nastaven√≠mi
```

**Minim√°ln√≠ po≈æadavky:**

| Promƒõnn√° | Popis |
|----------|-------|
| `PLATFORM` | `anthropic` (v√Ωchoz√≠) \| `gemini` \| `openai` \| `kimi` \| `glm` |
| `API_KEY` | V√°≈° API kl√≠ƒç pro zvolenou platformu |

**Voliteln√©:**

| Promƒõnn√° | Popis |
|----------|-------|
| `MODEL` | N√°zev modelu (rozumn√© v√Ωchoz√≠ hodnoty podle platformy) |
| `AGENT_NAME` | Zobrazovan√© jm√©no ve TUI (nap≈ô. `Yukine`) |
| `CAMERA_HOST` | IP adresa va≈°√≠ ONVIF/RTSP kamery |
| `CAMERA_USER` / `CAMERA_PASS` | P≈ôihla≈°ovac√≠ √∫daje kamery |
| `ELEVENLABS_API_KEY` | Pro v√Ωstup hlasu ‚Äî [elevenlabs.io](https://elevenlabs.io/) |
| `REALTIME_STT` | `true` pro povolen√≠ hlasov√©ho vstupu bez pou≈æit√≠ rukou (vy≈æaduje `ELEVENLABS_API_KEY`) |
| `TTS_OUTPUT` | Kde p≈ôehr√°vat zvuk: `local` (reproduktor PC, v√Ωchoz√≠) \| `remote` (reproduktor kamery) \| `both` |
| `THINKING_MODE` | Pouze Anthropic ‚Äî `auto` (v√Ωchoz√≠) \| `adaptive` \| `extended` \| `disabled` |
| `THINKING_EFFORT` | Adaptivn√≠ m√≠ra √∫sil√≠ o p≈ôem√Ω≈°len√≠: `high` (v√Ωchoz√≠) \| `medium` \| `low` \| `max` (pouze Opus 4.6) |

### 5. Vytvo≈ôte sv√©ho zn√°m√©ho

```bash
cp persona-template/en.md ME.md
# Upravte ME.md ‚Äî dejte mu jm√©no a osobnost
```

### 6. Spus≈•te

**macOS / Linux / WSL2:**
```bash
./run.sh             # Textov√© TUI (doporuƒçeno)
./run.sh --no-tui    # Prost√Ω REPL
```

**Windows:**
```bat
run.bat              # Textov√© TUI (doporuƒçeno)
run.bat --no-tui     # Prost√Ω REPL
```

---

## V√Ωbƒõr LLM

> **Doporuƒçeno: Kimi K2.5** ‚Äî nejlep≈°√≠ agentn√≠ v√Ωkon, kter√Ω byl dosud testov√°n. V≈°√≠m√° si kontextu, klade dopl≈àuj√≠c√≠ ot√°zky a jedn√° autonomnƒõ zp≈Øsoby, kter√© jin√© modely nedƒõlaj√≠. Cenovƒõ srovnateln√© s Claude Haiku.

| Platforma | `PLATFORM=` | V√Ωchoz√≠ model | Kde z√≠skat kl√≠ƒç |
|-----------|------------|---------------|-----------------|
| **Moonshot Kimi K2.5** | `kimi` | `kimi-k2.5` | [platform.moonshot.ai](https://platform.moonshot.ai) |
| Z.AI GLM | `glm` | `glm-4.6v` | [api.z.ai](https://api.z.ai) |
| Anthropic Claude | `anthropic` | `claude-haiku-4-5-20251001` | [console.anthropic.com](https://console.anthropic.com) |
| Google Gemini | `gemini` | `gemini-2.5-flash` | [aistudio.google.com](https://aistudio.google.com) |
| OpenAI | `openai` | `gpt-4o-mini` | [platform.openai.com](https://platform.openai.com) |
| OpenAI-kompatibiln√≠ (Ollama, vllm‚Ä¶) | `openai` + `BASE_URL=` | ‚Äî | ‚Äî |
| OpenRouter.ai (multi-provider) | `openai` + `BASE_URL=https://openrouter.ai/api/v1` | ‚Äî | [openrouter.ai](https://openrouter.ai) |
| **CLI n√°stroj** (claude -p, ollama‚Ä¶) | `cli` | (p≈ô√≠kaz) | ‚Äî |

**P≈ô√≠klad `.env` pro Kimi K2.5:**
```env
PLATFORM=kimi
API_KEY=sk-...   # z platform.moonshot.ai
AGENT_NAME=Yukine
```

**P≈ô√≠klad `.env` pro Z.AI GLM:**
```env
PLATFORM=glm
API_KEY=...   # z api.z.ai
MODEL=glm-4.6v   # s vidƒõn√≠m; glm-4.7 / glm-5 = pouze text
AGENT_NAME=Yukine
```

**P≈ô√≠klad `.env` pro Google Gemini:**
```env
PLATFORM=gemini
API_KEY=AIza...   # z aistudio.google.com
MODEL=gemini-2.5-flash  # nebo gemini-2.5-pro pro vy≈°≈°√≠ schopnosti
AGENT_NAME=Yukine
```

**P≈ô√≠klad `.env` pro OpenRouter.ai:**
```env
PLATFORM=openai
BASE_URL=https://openrouter.ai/api/v1
API_KEY=sk-or-...   # z openrouter.ai
MODEL=mistralai/mistral-7b-instruct  # voliteln√©: zadejte model
AGENT_NAME=Yukine
```

> **Pozor:** Pro zak√°z√°n√≠ m√≠stn√≠ch/NVIDIA model≈Ø jednodu≈°e nenastavujte `BASE_URL` na m√≠stn√≠ koncov√Ω bod jako `http://localhost:11434/v1`. M√≠sto toho pou≈æijte cloudov√© poskytovatele.

**P≈ô√≠klad `.env` pro CLI n√°stroj:**
```env
PLATFORM=cli
MODEL=llm -m gemma3 {}        # llm CLI (https://llm.datasette.io) ‚Äî {} = argument prompt
# MODEL=ollama run gemma3:27b  # Ollama ‚Äî bez {}, prompt jde p≈ôes stdin
```

---

## MCP Servery

familiar-ai se mo≈æe p≈ôipojit k jak√©mukoli [MCP (Model Context Protocol)](https://modelcontextprotocol.io) serveru. To v√°m umo≈æ≈àuje zapojit extern√≠ pamƒõ≈•, p≈ô√≠stup k souborov√©mu syst√©mu, webov√© vyhled√°v√°n√≠ nebo jak√Ωkoli jin√Ω n√°stroj.

Nakonfigurujte servery v `~/.familiar-ai.json` (stejn√Ω form√°t jako Claude Code):

```json
{
  "mcpServers": {
    "filesystem": {
      "type": "stdio",
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-filesystem", "/home/user"]
    },
    "memory": {
      "type": "sse",
      "url": "http://localhost:3000/sse"
    }
  }
}
```

Podporovan√© jsou dva typy p≈ôenosu:
- **`stdio`**: spustit m√≠stn√≠ podproces (`command` + `args`)
- **`sse`**: p≈ôipojit se k HTTP+SSE serveru (`url`)

P≈ôepi≈°te um√≠stƒõn√≠ konfiguraƒçn√≠ho souboru pomoc√≠ `MCP_CONFIG=/path/to/config.json`.

---

## Hardware

familiar-ai funguje s jak√Ωmkoli hardwarem, kter√Ω m√°te ‚Äî nebo ani s jedn√≠m.

| ƒå√°st | Co dƒõl√° | P≈ô√≠klad | Po≈æadov√°no? |
|------|---------|---------|-------------|
| Wi-Fi PTZ kamera | Oƒçi + krk | Tapo C220 (~$30) | **Doporuƒçeno** |
| USB webov√° kamera | Oƒçi (pevn√©) | Jak√°koli UVC kamera | **Doporuƒçeno** |
| Robotick√Ω vysavaƒç | Nohy | Jak√Ωkoli model kompatibiln√≠ s Tuya | Ne |
| PC / Raspberry Pi | Mozek | Cokoli, co spu≈°t√≠ Python | **Ano** |

> **Kamera je velmi doporuƒçena.** Bez n√≠ m≈Ø≈æe familiar-ai st√°le mluvit ‚Äî ale nem≈Ø≈æe vidƒõt svƒõt, co≈æ je vlastnƒõ cel√© to, o co jde.

### Minim√°ln√≠ nastaven√≠ (bez hardwaru)

Chcete to jen vyzkou≈°et? Pot≈ôebujete jen API kl√≠ƒç:

```env
PLATFORM=kimi
API_KEY=sk-...
```

Spus≈•te `./run.sh` (macOS/Linux/WSL2) nebo `run.bat` (Windows) a zaƒçnƒõte chatovat. P≈ôidejte hardware, jak budete pokraƒçovat.

### Wi-Fi PTZ kamera (Tapo C220)

1. V aplikaci Tapo: **Nastaven√≠ ‚Üí Pokroƒçil√© ‚Üí √öƒçet kamery** ‚Äî vytvo≈ôte m√≠stn√≠ √∫ƒçet (ne TP-Link √∫ƒçet)
2. Najdƒõte IP adresu kamery v seznamu za≈ô√≠zen√≠ va≈°eho routeru
3. Nastavte v `.env`:
   ```env
   CAMERA_HOST=192.168.1.xxx
   CAMERA_USER=your-local-user
   CAMERA_PASS=your-local-pass
   ```

### Hlas (ElevenLabs)

1. Z√≠skejte API kl√≠ƒç na [elevenlabs.io](https://elevenlabs.io/)
2. Nastavte v `.env`:
   ```env
   ELEVENLABS_API_KEY=sk_...
   ELEVENLABS_VOICE_ID=...   # voliteln√©, pou≈æ√≠v√° v√Ωchoz√≠ hlas, pokud je vynech√°no
   ```

Jsou zde dvƒõ destinace p≈ôehr√°v√°n√≠, ovl√°dan√© `TTS_OUTPUT`:

```env
TTS_OUTPUT=local    # reproduktor PC (v√Ωchoz√≠)
TTS_OUTPUT=remote   # pouze reproduktor kamery
TTS_OUTPUT=both     # reproduktor kamery + reproduktor PC souƒçasnƒõ
```

#### A) Reproduktor kamery (p≈ôes go2rtc)

Nastavte `TTS_OUTPUT=remote` (nebo `both`). Vy≈æaduje [go2rtc](https://github.com/AlexxIT/go2rtc/releases):

1. St√°hnƒõte bin√°rn√≠ soubor z [str√°nky vyd√°n√≠](https://github.com/AlexxIT/go2rtc/releases):
   - Linux/macOS: `go2rtc_linux_amd64` / `go2rtc_darwin_amd64`
   - **Windows: `go2rtc_win64.exe`**

2. Um√≠stƒõte a p≈ôejmenujte jej:
   ```
   # Linux / macOS
   ~/.cache/embodied-claude/go2rtc/go2rtc          # chmod +x je po≈æadov√°no

   # Windows
   %USERPROFILE%\.cache\embodied-claude\go2rtc\go2rtc.exe
   ```

3. Vytvo≈ôte `go2rtc.yaml` ve stejn√©m adres√°≈ôi:
   ```yaml
   streams:
     tapo_cam:
       - rtsp://YOUR_CAM_USER:YOUR_CAM_PASS@YOUR_CAM_IP/stream1
   ```
   Pou≈æijte p≈ôihla≈°ovac√≠ √∫daje m√≠stn√≠ho √∫ƒçtu kamery (ne sv≈Øj TP-Link cloud √∫ƒçet).

4. familiar-ai automaticky spou≈°t√≠ go2rtc p≈ôi spu≈°tƒõn√≠. Pokud va≈°e kamera podporuje obousmƒõrn√Ω audio (zpƒõtn√Ω kan√°l), hlas se p≈ôehr√°v√° z reproduktoru kamery.

#### B) Lok√°ln√≠ reproduktor PC

V√Ωchoz√≠ (`TTS_OUTPUT=local`). Zkou≈°√≠ p≈ôehr√°vaƒçe v po≈ôad√≠: **paplay** ‚Üí **mpv** ‚Üí **ffplay**. Tak√© pou≈æ√≠v√°n jako z√°loha, kdy≈æ je `TTS_OUTPUT=remote` a go2rtc nen√≠ k dispozici.

| OS | Instalace |
|----|-----------|
| macOS | `brew install mpv` |
| Ubuntu / Debian | `sudo apt install mpv` (nebo `paplay` p≈ôes `pulseaudio-utils`) |
| WSL2 / WSLg | `sudo apt install pulseaudio-utils` ‚Äî nastavte `PULSE_SERVER=unix:/mnt/wslg/PulseServer` v `.env` |
| Windows | [mpv.io/installation](https://mpv.io/installation/) ‚Äî st√°hnƒõte a p≈ôidejte do PATH, **nebo** `winget install ffmpeg` |

> Pokud ≈æ√°dn√Ω audio p≈ôehr√°vaƒç nen√≠ k dispozici, ≈ôeƒç je st√°le generov√°na ‚Äî jen se nebude p≈ôehr√°vat.

### Hlasov√Ω vstup (Realtime STT)

Nastavte `REALTIME_STT=true` v `.env` pro st√°le aktivn√≠, bezdr√°tov√Ω hlasov√Ω vstup:

```env
REALTIME_STT=true
ELEVENLABS_API_KEY=sk_...   # stejn√Ω kl√≠ƒç jako pro TTS
```

familiar-ai streamuje zvuk mikrofonu do ElevenLabs Scribe v2 a automaticky ukl√°d√° p≈ôepisy, kdy≈æ p≈ôestanete mluvit. Nen√≠ pot≈ôebn√© tisknut√≠ tlaƒç√≠tka. Koexistuje s re≈æimem stisknut√≠ pro mluven√≠ (Ctrl+T).

---

## TUI

familiar-ai obsahuje termin√°lov√© UI postaven√© s [Textual](https://textual.textualize.io/):

- Posouvateln√° historie konverzace s ≈æiv√Ωm textem
- Automatick√© dopl≈àov√°n√≠ pro `/quit`, `/clear`
- P≈ôeru≈°te agenta uprost≈ôed my≈°len√≠ t√≠m, ≈æe zaƒçnete ps√°t
- **Historie konverzace** automaticky ukl√°d√°na do `~/.cache/familiar-ai/chat.log`

Chcete-li sledovat log v jin√©m termin√°lu (u≈æiteƒçn√© pro kop√≠rov√°n√≠ a vkl√°d√°n√≠):
```bash
tail -f ~/.cache/familiar-ai/chat.log
```

---

## Osobnost (ME.md)

Osobnost va≈°eho zn√°m√©ho ≈æije v `ME.md`. Tento soubor je gitignored ‚Äî je jen v√°≈°.

Pod√≠vejte se na [`persona-template/en.md`](./persona-template/en.md) pro p≈ô√≠klad, nebo [`persona-template/ja.md`](./persona-template/ja.md) pro verzi v japon≈°tinƒõ.

---

## FAQ

**Q: Funguje to bez GPU?**
Ano. Model embedding (multilingual-e5-small) funguje dob≈ôe na CPU. GPU to zrychluje, ale nen√≠ vy≈æadov√°n.

**Q: Mohu pou≈æ√≠t jinou kameru ne≈æ Tapo?**
Jak√°koli kamera, kter√° podporuje ONVIF + RTSP, by mƒõla fungovat. Tapo C220 je to, co jsme testovali.

**Q: Odes√≠laj√≠ se nƒõjak√° m√° data nƒõkam?**
Obr√°zky a texty jsou odes√≠l√°ny na vybranou LLM API k zpracov√°n√≠. Vzpom√≠nky jsou ukl√°d√°ny lok√°lnƒõ v `~/.familiar_ai/`.

**Q: Proƒç agent p√≠≈°e `Ôºà...Ôºâ` m√≠sto mluven√≠?**
Ujistƒõte se, ≈æe je nastaveno `ELEVENLABS_API_KEY`. Bez nƒõj je hlas deaktivov√°n a agent se vr√°t√≠ k textu.

## Technick√© pozad√≠

Zaj√≠m√° v√°s, jak to funguje? Pod√≠vejte se na [docs/technical.md](./docs/technical.md) pro v√Ωzkum a rozhodov√°n√≠ o designu za familiar-ai ‚Äî ReAct, SayCan, Reflexion, Voyager, syst√©m touh a dal≈°√≠.

---

## P≈ôisp√≠v√°n√≠

familiar-ai je otev≈ôen√Ω experiment. Pokud v√°s nƒõco z toho oslovuje ‚Äî technicky nebo filozoficky ‚Äî p≈ô√≠spƒõvky jsou velmi v√≠t√°ny.

**Dobr√Ωm m√≠stem pro zaƒç√°tek:**

| Oblast | Co je pot≈ôeba |
|--------|---------------|
| Nov√Ω hardware | Podpora pro v√≠ce kamer (RTSP, IP Webcam), mikrofony, aktuatory |
| Nov√© n√°stroje | Webov√© vyhled√°v√°n√≠, dom√°c√≠ automatizace, kalend√°≈ô, cokoliv p≈ôes MCP |
| Nov√© backendy | Jak√Ωkoli LLM nebo lok√°ln√≠ model, kter√Ω vyhovuje rozhran√≠ `stream_turn` |
| ≈†ablony osobnosti | ≈†ablony ME.md pro r≈Øzn√© jazyky a osobnosti |
| V√Ωzkum | Lep≈°√≠ modely touh, z√≠sk√°v√°n√≠ pamƒõti, vyvol√°v√°n√≠ teorie mysli |
| Dokumentace | Tutori√°ly, pr≈Øvodce, p≈ôeklady |

Pod√≠vejte se na [CONTRIBUTING.md](./CONTRIBUTING.md) pro nastaven√≠ v√Ωvoje, styl k√≥du a pokyny k PR.

Pokud si nejste jisti, kde zaƒç√≠t, [otev≈ôete issue](https://github.com/lifemate-ai/familiar-ai/issues) ‚Äî r√°di v√°m uk√°≈æeme spr√°vn√Ω smƒõr.

---

## Licence

[MIT](./LICENSE)
```
