# familiar-ai üêæ

**Una IA que vive a tu lado** ‚Äî con ojos, voz, patas y memoria.

[![Lint](https://github.com/kmizu/familiar-ai/actions/workflows/lint.yml/badge.svg)](https://github.com/kmizu/familiar-ai/actions/workflows/lint.yml)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](./LICENSE)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/)
[![GitHub Sponsors](https://img.shields.io/github/sponsors/kmizu?style=flat&logo=github&color=ea4aaa)](https://github.com/sponsors/kmizu)

üåç [Disponible en 74 idiomas](./SUPPORTED_LANGUAGES.md)

---

[![Demo video](https://img.youtube.com/vi/hiR9uWRnjt4/0.jpg)](https://youtube.com/shorts/hiR9uWRnjt4)

familiar-ai es un compa√±ero de IA que vive en tu hogar. Config√∫ralo en minutos. No se requiere programaci√≥n.

Percibe el mundo real a trav√©s de c√°maras, se mueve en un cuerpo rob√≥tico, habla en voz alta y recuerda lo que ve. Dale un nombre, escribe su personalidad y d√©jalo vivir contigo.

## Lo que puede hacer

- üëÅ **Ver** ‚Äî captura im√°genes de una c√°mara PTZ Wi-Fi o webcam USB
- üîÑ **Mirar alrededor** ‚Äî gira y inclina la c√°mara para explorar su entorno
- ü¶ø **Moverse** ‚Äî conduce una aspiradora rob√≥tica para recorrer la habitaci√≥n
- üó£ **Hablar** ‚Äî habla a trav√©s de ElevenLabs TTS
- üéô **Escuchar** ‚Äî entrada de voz manos libres a trav√©s de ElevenLabs Realtime STT (opcional)
- üß† **Recordar** ‚Äî almacena y recuerda activamente recuerdos con b√∫squeda sem√°ntica (SQLite + embeddings)
- ü´Ä **Teor√≠a de la Mente** ‚Äî adopta la perspectiva de la otra persona antes de responder
- üí≠ **Deseo** ‚Äî tiene sus propios impulsos internos que desencadenan un comportamiento aut√≥nomo

## C√≥mo funciona

familiar-ai ejecuta un bucle [ReAct](https://arxiv.org/abs/2210.03629) impulsado por tu elecci√≥n de LLM. Percibe el mundo a trav√©s de herramientas, piensa en qu√© hacer a continuaci√≥n y act√∫a, como lo har√≠a una persona.

```
entrada del usuario
  ‚Üí pensar ‚Üí actuar (c√°mara / mover / hablar / recordar) ‚Üí observar ‚Üí pensar ‚Üí ...
```

Cuando est√° inactivo, act√∫a seg√∫n sus propios deseos: curiosidad, querer mirar afuera, extra√±ar a la persona con la que vive.

## Comenzando

### 1. Instala uv

**macOS / Linux / WSL2:**
```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

**Windows (PowerShell):**
```powershell
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
```
O: `winget install astral-sh.uv`

### 2. Instala ffmpeg

ffmpeg es **requerido** para la captura de im√°genes de la c√°mara y la reproducci√≥n de audio.

| OS | Comando |
|----|---------|
| macOS | `brew install ffmpeg` |
| Ubuntu / Debian | `sudo apt install ffmpeg` |
| Fedora / RHEL | `sudo dnf install ffmpeg` |
| Arch Linux | `sudo pacman -S ffmpeg` |
| Windows | `winget install ffmpeg` ‚Äî o descarga desde [ffmpeg.org](https://ffmpeg.org/download.html) y a√±ade a PATH |
| Raspberry Pi | `sudo apt install ffmpeg` |

Verifica: `ffmpeg -version`

### 3. Clona e instala

```bash
git clone https://github.com/lifemate-ai/familiar-ai
cd familiar-ai
uv sync
```

### 4. Configura

```bash
cp .env.example .env
# Edita .env con tu configuraci√≥n
```

**M√≠nimo requerido:**

| Variable | Descripci√≥n |
|----------|-------------|
| `PLATFORM` | `anthropic` (predeterminado) \| `gemini` \| `openai` \| `kimi` \| `glm` |
| `API_KEY` | Tu clave API para la plataforma elegida |

**Opcional:**

| Variable | Descripci√≥n |
|----------|-------------|
| `MODEL` | Nombre del modelo (valores predeterminados sensatos por plataforma) |
| `AGENT_NAME` | Nombre de visualizaci√≥n en el TUI (ej. `Yukine`) |
| `CAMERA_HOST` | Direcci√≥n IP de tu c√°mara ONVIF/RTSP |
| `CAMERA_USER` / `CAMERA_PASS` | Credenciales de la c√°mara |
| `ELEVENLABS_API_KEY` | Para salida de voz ‚Äî [elevenlabs.io](https://elevenlabs.io/) |
| `REALTIME_STT` | `true` para habilitar la entrada de voz manos libres siempre activa (requiere `ELEVENLABS_API_KEY`) |
| `TTS_OUTPUT` | Donde reproducir audio: `local` (altavoz del PC, predeterminado) \| `remote` (altavoz de la c√°mara) \| `both` |
| `THINKING_MODE` | Solo Anthropic ‚Äî `auto` (predeterminado) \| `adaptive` \| `extended` \| `disabled` |
| `THINKING_EFFORT` | Esfuerzo de pensamiento adaptativo: `high` (predeterminado) \| `medium` \| `low` \| `max` (solo Opus 4.6) |

### 5. Crea tu familiar

```bash
cp persona-template/en.md ME.md
# Edita ME.md ‚Äî dale un nombre y personalidad
```

### 6. Ejecuta

**macOS / Linux / WSL2:**
```bash
./run.sh             # TUI textual (recomendado)
./run.sh --no-tui    # REPL simple
```

**Windows:**
```bat
run.bat              # TUI textual (recomendado)
run.bat --no-tui     # REPL simple
```

---

## Elegir un LLM

> **Recomendado: Kimi K2.5** ‚Äî mejor rendimiento agentico probado hasta ahora. Nota contexto, hace preguntas de seguimiento y act√∫a de manera aut√≥noma en formas que otros modelos no lo hacen. Precios similares a Claude Haiku.

| Plataforma | `PLATFORM=` | Modelo predeterminado | D√≥nde obtener la clave |
|------------|-------------|-----------------------|------------------------|
| **Moonshot Kimi K2.5** | `kimi` | `kimi-k2.5` | [platform.moonshot.ai](https://platform.moonshot.ai) |
| Z.AI GLM | `glm` | `glm-4.6v` | [api.z.ai](https://api.z.ai) |
| Anthropic Claude | `anthropic` | `claude-haiku-4-5-20251001` | [console.anthropic.com](https://console.anthropic.com) |
| Google Gemini | `gemini` | `gemini-2.5-flash` | [aistudio.google.com](https://aistudio.google.com) |
| OpenAI | `openai` | `gpt-4o-mini` | [platform.openai.com](https://platform.openai.com) |
| OpenAI-compatible (Ollama, vllm‚Ä¶) | `openai` + `BASE_URL=` | ‚Äî | ‚Äî |
| OpenRouter.ai (multi-proveedor) | `openai` + `BASE_URL=https://openrouter.ai/api/v1` | ‚Äî | [openrouter.ai](https://openrouter.ai) |
| **Herramienta CLI** (claude -p, ollama‚Ä¶) | `cli` | (el comando) | ‚Äî |

**Ejemplo de `.env` de Kimi K2.5:**
```env
PLATFORM=kimi
API_KEY=sk-...   # de platform.moonshot.ai
AGENT_NAME=Yukine
```

**Ejemplo de `.env` de Z.AI GLM:**
```env
PLATFORM=glm
API_KEY=...   # de api.z.ai
MODEL=glm-4.6v   # habilitado para visi√≥n; glm-4.7 / glm-5 = solo texto
AGENT_NAME=Yukine
```

**Ejemplo de `.env` de Google Gemini:**
```env
PLATFORM=gemini
API_KEY=AIza...   # de aistudio.google.com
MODEL=gemini-2.5-flash  # o gemini-2.5-pro para mayor capacidad
AGENT_NAME=Yukine
```

**Ejemplo de `.env` de OpenRouter.ai:**
```env
PLATFORM=openai
BASE_URL=https://openrouter.ai/api/v1
API_KEY=sk-or-...   # de openrouter.ai
MODEL=mistralai/mistral-7b-instruct  # opcional: especificar modelo
AGENT_NAME=Yukine
```

> **Nota:** Para deshabilitar modelos locales/NVIDIA, simplemente no establezcas `BASE_URL` en un punto final local como `http://localhost:11434/v1`. Utiliza proveedores en la nube en su lugar.

**Ejemplo de `.env` de herramienta CLI:**
```env
PLATFORM=cli
MODEL=llm -m gemma3 {}        # llm CLI (https://llm.datasette.io) ‚Äî {} = argumento de prompt
# MODEL=ollama run gemma3:27b  # Ollama ‚Äî sin {}, el prompt pasa por stdin
```

---

## Servidores MCP

familiar-ai puede conectarse a cualquier servidor [MCP (Modelo Contexto Protocolo)](https://modelcontextprotocol.io). Esto te permite conectar memoria externa, acceso a sistemas de archivos, b√∫squeda en la web o cualquier otra herramienta.

Configura servidores en `~/.familiar-ai.json` (mismo formato que Claude Code):

```json
{
  "mcpServers": {
    "filesystem": {
      "type": "stdio",
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-filesystem", "/home/user"]
    },
    "memory": {
      "type": "sse",
      "url": "http://localhost:3000/sse"
    }
  }
}
```

Se admiten dos tipos de transporte:
- **`stdio`**: lanza un subprocesso local (`command` + `args`)
- **`sse`**: conecta a un servidor HTTP+SSE (`url`)

Sobrescribe la ubicaci√≥n del archivo de configuraci√≥n con `MCP_CONFIG=/ruta/a/config.json`.

---

## Hardware

familiar-ai funciona con el hardware que tengas, o incluso sin ninguno.

| Parte | Lo que hace | Ejemplo | ¬øRequerido? |
|-------|-------------|---------|-------------|
| C√°mara PTZ Wi-Fi | Ojos + cuello | Tapo C220 (~$30) | **Recomendado** |
| Webcam USB | Ojos (fijos) | Cualquier c√°mara UVC | **Recomendado** |
| Aspiradora rob√≥tica | Patas | Cualquier modelo compatible con Tuya | No |
| PC / Raspberry Pi | Cerebro | Cualquier cosa que ejecute Python | **S√≠** |

> **Se recomienda encarecidamente una c√°mara.** Sin una, familiar-ai a√∫n puede hablar, pero no puede ver el mundo, que es en parte el objetivo.

### Configuraci√≥n m√≠nima (sin hardware)

¬øSolo quieres intentarlo? Solo necesitas una clave API:

```env
PLATFORM=kimi
API_KEY=sk-...
```

Ejecuta `./run.sh` (macOS/Linux/WSL2) o `run.bat` (Windows) y comienza a chatear. Agrega hardware mientras avanzas.

### C√°mara PTZ Wi-Fi (Tapo C220)

1. En la aplicaci√≥n Tapo: **Configuraci√≥n ‚Üí Avanzado ‚Üí Cuenta de C√°mara** ‚Äî crea una cuenta local (no de TP-Link)
2. Encuentra la IP de la c√°mara en la lista de dispositivos de tu router
3. Establece en `.env`:
   ```env
   CAMERA_HOST=192.168.1.xxx
   CAMERA_USER=tu-usuario-local
   CAMERA_PASS=tu-contrase√±a-local
   ```

### Voz (ElevenLabs)

1. Obt√©n una clave API en [elevenlabs.io](https://elevenlabs.io/)
2. Establece en `.env`:
   ```env
   ELEVENLABS_API_KEY=sk_...
   ELEVENLABS_VOICE_ID=...   # opcional, utiliza la voz predeterminada si se omite
   ```

Hay dos destinos de reproducci√≥n, controlados por `TTS_OUTPUT`:

```env
TTS_OUTPUT=local    # altavoz del PC (predeterminado)
TTS_OUTPUT=remote   # solo altavoz de la c√°mara
TTS_OUTPUT=both     # altavoz de la c√°mara + altavoz del PC simult√°neamente
```

#### A) Altavoz de la c√°mara (a trav√©s de go2rtc)

Establece `TTS_OUTPUT=remote` (o `both`). Requiere [go2rtc](https://github.com/AlexxIT/go2rtc/releases):

1. Descarga el binario desde la [p√°gina de lanzamientos](https://github.com/AlexxIT/go2rtc/releases):
   - Linux/macOS: `go2rtc_linux_amd64` / `go2rtc_darwin_amd64`
   - **Windows: `go2rtc_win64.exe`**

2. Col√≥calo y ren√≥mbrelo:
   ```
   # Linux / macOS
   ~/.cache/embodied-claude/go2rtc/go2rtc          # chmod +x requerido

   # Windows
   %USERPROFILE%\.cache\embodied-claude\go2rtc\go2rtc.exe
   ```

3. Crea `go2rtc.yaml` en el mismo directorio:
   ```yaml
   streams:
     tapo_cam:
       - rtsp://TU_USUARIO_CAMARA:TU_CONTRASE√ëA_CAMARA@TU_IP_CAMARA/stream1
   ```
   Usa las credenciales de cuenta de c√°mara local (no tu cuenta TP-Link en la nube).

4. familiar-ai inicia go2rtc autom√°ticamente al iniciar. Si tu c√°mara admite audio bidireccional (canal de retorno), la voz se reproduce desde el altavoz de la c√°mara.

#### B) Altavoz local del PC

El predeterminado (`TTS_OUTPUT=local`). Intenta reproductores en orden: **paplay** ‚Üí **mpv** ‚Üí **ffplay**. Tambi√©n se utiliza como respaldo cuando `TTS_OUTPUT=remote` y go2rtc no est√° disponible.

| OS | Instalaci√≥n |
|----|-------------|
| macOS | `brew install mpv` |
| Ubuntu / Debian | `sudo apt install mpv` (o `paplay` a trav√©s de `pulseaudio-utils`) |
| WSL2 / WSLg | `sudo apt install pulseaudio-utils` ‚Äî establece `PULSE_SERVER=unix:/mnt/wslg/PulseServer` en `.env` |
| Windows | [mpv.io/installation](https://mpv.io/installation/) ‚Äî descarga y a√±ade a PATH, **o** `winget install ffmpeg` |

> Si no hay disponible reproductor de audio, se generar√° el discurso ‚Äî simplemente no se reproducir√°.

### Entrada de voz (Realtime STT)

Establece `REALTIME_STT=true` en `.env` para entrada de voz siempre activa y manos libres:

```env
REALTIME_STT=true
ELEVENLABS_API_KEY=sk_...   # misma clave que TTS
```

familiar-ai transmite audio del micr√≥fono a ElevenLabs Scribe v2 y guarda autom√°ticamente las transcripciones cuando dejas de hablar. No se requiere presi√≥n de bot√≥n. Coexiste con el modo de pulsar para hablar (Ctrl+T).

---

## TUI

familiar-ai incluye una interfaz de terminal construida con [Textual](https://textual.textualize.io/):

- Historial de conversaci√≥n desplazable con texto en vivo
- Autocompletado para `/quit`, `/clear`
- Interrumpe al agente a mitad de turno escribiendo mientras est√° pensando
- **Registro de conversaci√≥n** guardado autom√°ticamente en `~/.cache/familiar-ai/chat.log`

Para seguir el registro en otra terminal (√∫til para copiar y pegar):
```bash
tail -f ~/.cache/familiar-ai/chat.log
```

---

## Persona (ME.md)

La personalidad de tu familiar vive en `ME.md`. Este archivo est√° ignorado por git ‚Äî es solo tuyo.

Consulta [`persona-template/en.md`](./persona-template/en.md) para un ejemplo, o [`persona-template/ja.md`](./persona-template/ja.md) para una versi√≥n en japon√©s.

---

## Preguntas Frecuentes

**Q: ¬øFunciona sin GPU?**
S√≠. El modelo de embedding (multilingual-e5-small) funciona bien en CPU. Una GPU lo hace m√°s r√°pido, pero no es necesaria.

**Q: ¬øPuedo usar una c√°mara que no sea Tapo?**
Cualquier c√°mara que soporte ONVIF + RTSP deber√≠a funcionar. La Tapo C220 es con la que hemos probado.

**Q: ¬øSe env√≠an mis datos a alguna parte?**
Las im√°genes y textos se env√≠an a tu API de LLM elegida para su procesamiento. Los recuerdos se guardan localmente en `~/.familiar_ai/`.

**Q: ¬øPor qu√© el agente escribe `Ôºà...Ôºâ` en lugar de hablar?**
Aseg√∫rate de que `ELEVENLABS_API_KEY` est√© establecido. Sin ello, la voz est√° deshabilitada y el agente vuelve al texto.

## Antecedentes t√©cnicos

¬øTienes curiosidad sobre c√≥mo funciona? Consulta [docs/technical.md](./docs/technical.md) para ver la investigaci√≥n y decisiones de dise√±o detr√°s de familiar-ai ‚Äî ReAct, SayCan, Reflexion, Voyager, el sistema de deseos, y m√°s.

---

## Contribuyendo

familiar-ai es un experimento abierto. Si algo de esto resuena contigo ‚Äî t√©cnica o filos√≥ficamente ‚Äî las contribuciones son muy bienvenidas.

**Buenos lugares para comenzar:**

| √Årea | Qu√© se necesita |
|------|-----------------|
| Nuevo hardware | Soporte para m√°s c√°maras (RTSP, Webcam IP), micr√≥fonos, actuadores |
| Nuevas herramientas | B√∫squeda en la web, automatizaci√≥n del hogar, calendario, cualquier cosa a trav√©s de MCP |
| Nuevos backends | Cualquier LLM o modelo local que se ajuste a la interfaz `stream_turn` |
| Plantillas de personalidad | Plantillas ME.md para diferentes idiomas y personalidades |
| Investigaci√≥n | Mejores modelos de deseos, recuperaci√≥n de recuerdos, prompts de teor√≠a de la mente |
| Documentaci√≥n | Tutoriales, gu√≠as, traducciones |

Consulta [CONTRIBUTING.md](./CONTRIBUTING.md) para configuraci√≥n de desarrollo, estilo de c√≥digo y pautas de PR.

Si no est√°s seguro de por d√≥nde comenzar, [abre un issue](https://github.com/lifemate-ai/familiar-ai/issues) ‚Äî estar√© encantado de orientarte en la direcci√≥n correcta.

---

## Licencia

[MIT](./LICENSE)
