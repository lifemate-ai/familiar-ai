# familiar-ai üêæ

**Una IA que vive junto a ti** ‚Äî con ojos, voz, piernas y memoria.

[![Lint](https://github.com/kmizu/familiar-ai/actions/workflows/lint.yml/badge.svg)](https://github.com/kmizu/familiar-ai/actions/workflows/lint.yml)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](./LICENSE)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/)
[![GitHub Sponsors](https://img.shields.io/github/sponsors/kmizu?style=flat&logo=github&color=ea4aaa)](https://github.com/sponsors/kmizu)

[‚Üí English README](../README.md)

---

[![Demo video](https://img.youtube.com/vi/hiR9uWRnjt4/0.jpg)](https://youtube.com/shorts/hiR9uWRnjt4)

familiar-ai es un compa√±ero de IA que vive en tu hogar.
Config√∫ralo en minutos. No se requiere codificaci√≥n.

Percibe el mundo real a trav√©s de c√°maras, se mueve en un cuerpo rob√≥tico, habla en voz alta y recuerda lo que ve. Dale un nombre, escribe su personalidad y d√©jalo vivir contigo.

## Lo que puede hacer

- üëÅ **Ver** ‚Äî captura im√°genes de una c√°mara PTZ Wi-Fi o webcam USB
- üîÑ **Mirar alrededor** ‚Äî barra y inclina la c√°mara para explorar su entorno
- ü¶ø **Mover** ‚Äî conduce una aspiradora robot para deambular por la habitaci√≥n
- üó£ **Hablar** ‚Äî habla a trav√©s de ElevenLabs TTS
- üéô **Escuchar** ‚Äî entrada de voz manos libres a trav√©s de ElevenLabs Realtime STT (opcional)
- üß† **Recordar** ‚Äî almacena y recuerda activamente recuerdos con b√∫squeda sem√°ntica (SQLite + embeddings)
- ü´Ä **Teor√≠a de la mente** ‚Äî toma la perspectiva de la otra persona antes de responder
- üí≠ **Deseo** ‚Äî tiene sus propios impulsos internos que desencadenan comportamiento aut√≥nomo

## C√≥mo funciona

familiar-ai ejecuta un bucle [ReAct](https://arxiv.org/abs/2210.03629) alimentado por tu elecci√≥n de LLM. Percibe el mundo a trav√©s de herramientas, piensa en qu√© hacer a continuaci√≥n y act√∫a, tal como lo har√≠a una persona.

```
user input
  ‚Üí think ‚Üí act (camera / move / speak / remember) ‚Üí observe ‚Üí think ‚Üí ...
```

Cuando est√° inactivo, act√∫a seg√∫n sus propios deseos: curiosidad, querer mirar afuera, extra√±ar a la persona con la que vive.

## Comenzando

### 1. Instala uv

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

### 2. Instala ffmpeg

ffmpeg es **requerido** para la captura de im√°genes de c√°mara y la reproducci√≥n de audio.

| OS | Comando |
|----|---------|
| macOS | `brew install ffmpeg` |
| Ubuntu / Debian | `sudo apt install ffmpeg` |
| Fedora / RHEL | `sudo dnf install ffmpeg` |
| Arch Linux | `sudo pacman -S ffmpeg` |
| Windows | `winget install ffmpeg` ‚Äî o desc√°rgalo de [ffmpeg.org](https://ffmpeg.org/download.html) y agr√©galo a PATH |
| Raspberry Pi | `sudo apt install ffmpeg` |

Verifica: `ffmpeg -version`

### 3. Clona e instala

```bash
git clone https://github.com/lifemate-ai/familiar-ai
cd familiar-ai
uv sync
```

### 4. Configura

```bash
cp .env.example .env
# Edita .env con tu configuraci√≥n
```

**M√≠nimo requerido:**

| Variable | Descripci√≥n |
|----------|-------------|
| `PLATFORM` | `anthropic` (por defecto) \| `gemini` \| `openai` \| `kimi` \| `glm` |
| `API_KEY` | Tu clave API para la plataforma elegida |

**Opcional:**

| Variable | Descripci√≥n |
|----------|-------------|
| `MODEL` | Nombre del modelo (valores por defecto sensatos por plataforma) |
| `AGENT_NAME` | Nombre que se muestra en la TUI (ej., `Yukine`) |
| `CAMERA_HOST` | Direcci√≥n IP de tu c√°mara ONVIF/RTSP |
| `CAMERA_USER` / `CAMERA_PASS` | Credenciales de la c√°mara |
| `ELEVENLABS_API_KEY` | Para salida de voz ‚Äî [elevenlabs.io](https://elevenlabs.io/) |
| `REALTIME_STT` | `true` para habilitar la entrada de voz manos libres siempre activa (requiere `ELEVENLABS_API_KEY`) |
| `TTS_OUTPUT` | D√≥nde reproducir audio: `local` (altavoz de PC, por defecto) \| `remote` (altavoz de la c√°mara) \| `both` |
| `THINKING_MODE` | Solo Anthropic ‚Äî `auto` (por defecto) \| `adaptive` \| `extended` \| `disabled` |
| `THINKING_EFFORT` | Esfuerzo de pensamiento adaptativo: `high` (por defecto) \| `medium` \| `low` \| `max` (solo Opus 4.6) |

### 5. Crea tu familiar

```bash
cp persona-template/en.md ME.md
# Edita ME.md ‚Äî dale un nombre y personalidad
```

### 6. Ejecuta

```bash
./run.sh             # TUI textual (recomendado)
./run.sh --no-tui    # REPL simple
```

---

## Elegir un LLM

> **Recomendado: Kimi K2.5** ‚Äî mejor rendimiento agente probado hasta ahora. Nota el contexto, hace preguntas de seguimiento y act√∫a de forma aut√≥noma en maneras que otros modelos no lo hacen. Precios similares a Claude Haiku.

| Plataforma | `PLATFORM=` | Modelo por defecto | D√≥nde obtener la clave |
|------------|------------|--------------------|-----------------------|
| **Moonshot Kimi K2.5** | `kimi` | `kimi-k2.5` | [platform.moonshot.ai](https://platform.moonshot.ai) |
| Z.AI GLM  | `glm` | `glm-4.6v` | [api.z.ai](https://api.z.ai) |
| Anthropic Claude | `anthropic` | `claude-haiku-4-5-20251001` | [console.anthropic.com](https://console.anthropic.com) |
| Google Gemini | `gemini` | `gemini-2.5-flash` | [aistudio.google.com](https://aistudio.google.com) |
| OpenAI | `openai` | `gpt-4o-mini` | [platform.openai.com](https://platform.openai.com) |
| OpenAI-compatible (Ollama, vllm‚Ä¶) | `openai` + `BASE_URL=` | ‚Äî | ‚Äî |
| OpenRouter.ai (multi-proveedor) | `openai` + `BASE_URL=https://openrouter.ai/api/v1` | ‚Äî | [openrouter.ai](https://openrouter.ai) |
| **Herramienta CLI** (claude -p, ollama‚Ä¶) | `cli` | (el comando) | ‚Äî |

**Ejemplo de `.env` de Kimi K2.5:**
```env
PLATFORM=kimi
API_KEY=sk-...   # de platform.moonshot.ai
AGENT_NAME=Yukine
```

**Ejemplo de `.env` de Z.AI GLM:**
```env
PLATFORM=glm
API_KEY=...   # de api.z.ai
MODEL=glm-4.6v   # habilitado para visi√≥n; glm-4.7 / glm-5 = solo texto
AGENT_NAME=Yukine
```

**Ejemplo de `.env` de Google Gemini:**
```env
PLATFORM=gemini
API_KEY=AIza...   # de aistudio.google.com
MODEL=gemini-2.5-flash  # o gemini-2.5-pro para mayor capacidad
AGENT_NAME=Yukine
```

**Ejemplo de `.env` de OpenRouter.ai:**
```env
PLATFORM=openai
BASE_URL=https://openrouter.ai/api/v1
API_KEY=sk-or-...   # de openrouter.ai
MODEL=mistralai/mistral-7b-instruct  # opcional: especificar modelo
AGENT_NAME=Yukine
```

> **Nota:** Para deshabilitar modelos locales/NVIDIA, simplemente no establezcas `BASE_URL` como un endpoint local como `http://localhost:11434/v1`. Usa proveedores de la nube en su lugar.

**Ejemplo de `.env` de herramienta CLI:**
```env
PLATFORM=cli
MODEL=llm -m gemma3 {}        # llm CLI (https://llm.datasette.io) ‚Äî {} = argumento de prompt
# MODEL=ollama run gemma3:27b  # Ollama ‚Äî sin {}, el prompt va por stdin
```

---

## Servidores MCP

familiar-ai puede conectarse a cualquier servidor [MCP (Modelo Context Protocol)](https://modelcontextprotocol.io). Esto te permite integrar memoria externa, acceso al sistema de archivos, b√∫squeda en la web u otra herramienta.

Configura servidores en `~/.familiar-ai.json` (mismo formato que Claude Code):

```json
{
  "mcpServers": {
    "filesystem": {
      "type": "stdio",
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-filesystem", "/home/user"]
    },
    "memory": {
      "type": "sse",
      "url": "http://localhost:3000/sse"
    }
  }
}
```

Se admiten dos tipos de transporte:
- **`stdio`**: lanza un subproceso local (`command` + `args`)
- **`sse`**: conecta a un servidor HTTP+SSE (`url`)

Anula la ubicaci√≥n del archivo de configuraci√≥n con `MCP_CONFIG=/ruta/al/config.json`.

---

## Hardware

familiar-ai funciona con el hardware que tengas ‚Äî o con ninguno.

| Parte | Lo que hace | Ejemplo | ¬øRequerido? |
|-------|-------------|---------|-------------|
| C√°mara PTZ Wi-Fi | Ojos + cuello | Tapo C220 (~$30) | **Recomendado** |
| Webcam USB | Ojos (fijos) | Cualquier c√°mara UVC | **Recomendado** |
| Aspiradora rob√≥tica | Piernas | Cualquier modelo compatible con Tuya | No |
| PC / Raspberry Pi | Cerebro | Cualquier cosa que ejecute Python | **S√≠** |

> **Se recomienda encarecidamente una c√°mara.** Sin ella, familiar-ai a√∫n puede hablar, pero no puede ver el mundo, que es un poco el objetivo.

### Configuraci√≥n m√≠nima (sin hardware)

¬øSolo quieres probarlo? Solo necesitas una clave API:

```env
PLATFORM=kimi
API_KEY=sk-...
```

Ejecuta `./run.sh` y comienza a chatear. Agrega hardware a medida que avanzas.

### C√°mara PTZ Wi-Fi (Tapo C220)

1. En la aplicaci√≥n Tapo: **Configuraci√≥n ‚Üí Avanzado ‚Üí Cuenta de C√°mara** ‚Äî crea una cuenta local (no cuenta TP-Link)
2. Encuentra la IP de la c√°mara en la lista de dispositivos de tu enrutador
3. Establece en `.env`:
   ```env
   CAMERA_HOST=192.168.1.xxx
   CAMERA_USER=tu-usuario-local
   CAMERA_PASS=tu-contrasena-local
   ```

### Voz (ElevenLabs)

1. Obt√©n una clave API en [elevenlabs.io](https://elevenlabs.io/)
2. Establece en `.env`:
   ```env
   ELEVENLABS_API_KEY=sk_...
   ELEVENLABS_VOICE_ID=...   # opcional, usa la voz por defecto si se omite
   ```

Hay dos destinos de reproducci√≥n, controlados por `TTS_OUTPUT`:

```env
TTS_OUTPUT=local    # altavoz de PC (por defecto)
TTS_OUTPUT=remote   # solo altavoz de la c√°mara
TTS_OUTPUT=both     # altavoz de la c√°mara + altavoz de PC simult√°neamente
```

#### A) Altavoz de la c√°mara (a trav√©s de go2rtc)

Establece `TTS_OUTPUT=remote` (o `both`). Requiere [go2rtc](https://github.com/AlexxIT/go2rtc/releases):

1. Descarga el binario de la [p√°gina de lanzamientos](https://github.com/AlexxIT/go2rtc/releases):
   - Linux/macOS: `go2rtc_linux_amd64` / `go2rtc_darwin_amd64`
   - **Windows: `go2rtc_win64.exe`**

2. Coloca y ren√≥mbralo:
   ```
   # Linux / macOS
   ~/.cache/embodied-claude/go2rtc/go2rtc          # chmod +x requerido

   # Windows
   %USERPROFILE%\.cache\embodied-claude\go2rtc\go2rtc.exe
   ```

3. Crea `go2rtc.yaml` en el mismo directorio:
   ```yaml
   streams:
     tapo_cam:
       - rtsp://YOUR_CAM_USER:YOUR_CAM_PASS@YOUR_CAM_IP/stream1
   ```
   Usa las credenciales de la cuenta local de la c√°mara (no tu cuenta de nube TP-Link).

4. familiar-ai inicia go2rtc autom√°ticamente al iniciar. Si tu c√°mara admite audio bidireccional (canal de regreso), la voz se reproduce desde el altavoz de la c√°mara.

#### B) Altavoz local de PC

El predeterminado (`TTS_OUTPUT=local`). Intenta reproductores en orden: **paplay** ‚Üí **mpv** ‚Üí **ffplay**. Tambi√©n se usa como respaldo cuando `TTS_OUTPUT=remote` y go2rtc no est√° disponible.

| OS | Instalar |
|----|---------|
| macOS | `brew install mpv` |
| Ubuntu / Debian | `sudo apt install mpv` (o `paplay` a trav√©s de `pulseaudio-utils`) |
| WSL2 / WSLg | `sudo apt install pulseaudio-utils` ‚Äî establece `PULSE_SERVER=unix:/mnt/wslg/PulseServer` en `.env` |
| Windows | [mpv.io/installation](https://mpv.io/installation/) ‚Äî descarga y agr√©galo a PATH, **o** `winget install ffmpeg` |

> Si no hay un reproductor de audio disponible, la voz sigue gener√°ndose ‚Äî simplemente no se reproducir√°.

### Entrada de voz (Realtime STT)

Establece `REALTIME_STT=true` en `.env` para entrada de voz manos libres siempre activa:

```env
REALTIME_STT=true
ELEVENLABS_API_KEY=sk_...   # misma clave que para TTS
```

familiar-ai transmite audio del micr√≥fono a ElevenLabs Scribe v2 y auto-compromete transcripciones cuando dejas de hablar. No se requiere pulsar ning√∫n bot√≥n. Coexiste con el modo de pulsar para hablar (Ctrl+T).

---

## TUI

familiar-ai incluye una interfaz de terminal construida con [Textual](https://textual.textualize.io/):

- Historial de conversaci√≥n desplazable con texto en streaming en vivo
- Completado de tabulador para `/quit`, `/clear`
- Interrumpe al agente en medio de un turno escribiendo mientras est√° pensando
- **Registro de conversaci√≥n** guardado autom√°ticamente en `~/.cache/familiar-ai/chat.log`

Para seguir el registro en otra terminal (√∫til para copiar-pegar):
```bash
tail -f ~/.cache/familiar-ai/chat.log
```

---

## Persona (ME.md)

La personalidad de tu familiar vive en `ME.md`. Este archivo est√° ignorado por Git ‚Äî es solo tuyo.

Consulta [`persona-template/en.md`](./persona-template/en.md) para un ejemplo, o [`persona-template/ja.md`](./persona-template/ja.md) para una versi√≥n en japon√©s.

---

## Preguntas frecuentes

**Q: ¬øFunciona sin GPU?**
S√≠. El modelo de embeddings (multilingual-e5-small) funciona bien en CPU. Una GPU lo hace m√°s r√°pido, pero no es necesaria.

**Q: ¬øPuedo usar una c√°mara diferente a la Tapo?**
Cualquier c√°mara que soporte ONVIF + RTSP deber√≠a funcionar. La Tapo C220 es con la que hemos probado.

**Q: ¬øSe env√≠an mis datos a alg√∫n lado?**
Las im√°genes y el texto se env√≠an a la API de LLM que elijas para su procesamiento. Los recuerdos se almacenan localmente en `~/.familiar_ai/`.

**Q: ¬øPor qu√© el agente escribe `Ôºà...Ôºâ` en lugar de hablar?**
Aseg√∫rate de que `ELEVENLABS_API_KEY` est√© configurado. Sin √©l, la voz est√° deshabilitada y el agente recurre al texto.

## Antecedentes t√©cnicos

¬øTienes curiosidad sobre c√≥mo funciona? Consulta [docs/technical.md](./docs/technical.md) para conocer las decisiones de investigaci√≥n y dise√±o detr√°s de familiar-ai ‚Äî ReAct, SayCan, Reflexion, Voyager, el sistema de deseos y m√°s.

---

## Contribuyendo

familiar-ai es un experimento abierto. Si alguna de esto resuena contigo ‚Äît√©cnicamente o filos√≥ficamente‚Äî las contribuciones son muy bienvenidas.

**Buenos lugares para comenzar:**

| √Årea | Lo que se necesita |
|------|--------------------|
| Nuevo hardware | Soporte para m√°s c√°maras (RTSP, Webcam IP), micr√≥fonos, actuadores |
| Nuevas herramientas | B√∫squeda web, automatizaci√≥n del hogar, calendario, cualquier cosa a trav√©s de MCP |
| Nuevos backends | Cualquier LLM o modelo local que se ajuste a la interfaz `stream_turn` |
| Plantillas de persona | Plantillas de ME.md para diferentes idiomas y personalidades |
| Investigaci√≥n | Mejores modelos de deseos, recuperaci√≥n de memoria, indicaciones de teor√≠a de la mente |
| Documentaci√≥n | Tutoriales, gu√≠as, traducciones |

Consulta [CONTRIBUTING.md](./CONTRIBUTING.md) para la configuraci√≥n de desarrollo, estilo de c√≥digo y pautas de PR.

Si no est√°s seguro de por d√≥nde empezar, [abre un problema](https://github.com/lifemate-ai/familiar-ai/issues) ‚Äî estar√© encantado de indicarte la direcci√≥n correcta.

---

## Licencia

[MIT](./LICENSE)
